{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.facebook.com/groups/deep.learning.edu/permalink/608757449485792/\n",
    "import numpy\n",
    "import pandas\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "numpy.random.seed(seed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load dataset\n",
    "dataframe = pandas.read_csv(\"iris.csv\", header=None)\n",
    "dataset = dataframe.values\n",
    "X = dataset[:,0:4].astype(float)\n",
    "Y = dataset[:,4]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
      " 2 2]\n",
      "Seperate\n",
      "[[1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [1. 0. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 1. 0.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]\n",
      " [0. 0. 1.]]\n"
     ]
    }
   ],
   "source": [
    "# encode class values as integers\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "encoded_Y = encoder.transform(Y)\n",
    "print(encoded_Y)\n",
    "print(\"Seperate\")\n",
    "# convert integers to dummy variables (i.e. one hot encoded)\n",
    "dummy_y = np_utils.to_categorical(encoded_Y)\n",
    "print(dummy_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define baseline model\n",
    "def baseline_model():\n",
    "\t# create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8, activation='relu', input_shape=(4,)))\n",
    "    #model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(2, activation='softmax')) #probablity for softmax\n",
    "\n",
    "\t# Compile model\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking target: expected dense_670 to have shape (2,) but got array with shape (3,)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-95-3d7fb5694ad0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mestimator\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKerasClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuild_fn\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbaseline_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m200\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKFold\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_splits\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdummy_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mkfold\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Baseline: %.2f%% (%.2f%%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch)\u001b[0m\n\u001b[0;32m    138\u001b[0m                                               \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m                                               fit_params)\n\u001b[1;32m--> 140\u001b[1;33m                       for train, test in cv_iter)\n\u001b[0m\u001b[0;32m    141\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    757\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 758\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    759\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    760\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    606\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    607\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 608\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    609\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    610\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    569\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 571\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    572\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    107\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    108\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 109\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    110\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    111\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    324\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    325\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 326\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    237\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 238\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    239\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    240\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, sample_weight, **kwargs)\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'sample_weight'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mKerasClassifier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\wrappers\\scikit_learn.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[0;32m    149\u001b[0m         \u001b[0mfit_args\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    150\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 151\u001b[1;33m         \u001b[0mhistory\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    152\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mhistory\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1000\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1001\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1002\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1003\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1004\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1628\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1629\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1630\u001b[1;33m             batch_size=batch_size)\n\u001b[0m\u001b[0;32m   1631\u001b[0m         \u001b[1;31m# Prepare validation data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1632\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[1;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[0;32m   1478\u001b[0m                                     \u001b[0moutput_shapes\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1479\u001b[0m                                     \u001b[0mcheck_batch_axis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1480\u001b[1;33m                                     exception_prefix='target')\n\u001b[0m\u001b[0;32m   1481\u001b[0m         sample_weights = _standardize_sample_weights(sample_weight,\n\u001b[0;32m   1482\u001b[0m                                                      self._feed_output_names)\n",
      "\u001b[1;32mD:\\anaconda\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_standardize_input_data\u001b[1;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[0;32m    121\u001b[0m                             \u001b[1;34m': expected '\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' to have shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m' but got array with shape '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                             str(data_shape))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Error when checking target: expected dense_670 to have shape (2,) but got array with shape (3,)"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=baseline_model, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Baseline: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 94.00% (10.09%)\n"
     ]
    }
   ],
   "source": [
    "# smaller model\n",
    "def create_smaller():\n",
    "\t# create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(4, activation='relu', input_shape=(4,)))\n",
    "    #model.add(Dense(4, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "\n",
    "estimator = KerasClassifier(build_fn=create_smaller, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 6s 48ms/step - loss: 1.2204 - acc: 0.3333 - val_loss: 1.2972 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1142 - acc: 0.4741 - val_loss: 1.2083 - val_acc: 0.4667\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0352 - acc: 0.6815 - val_loss: 1.1471 - val_acc: 0.4667\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9966 - acc: 0.6815 - val_loss: 1.1018 - val_acc: 0.4667\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9662 - acc: 0.6815 - val_loss: 1.0726 - val_acc: 0.4667\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9362 - acc: 0.6815 - val_loss: 1.0365 - val_acc: 0.4667\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9079 - acc: 0.6815 - val_loss: 1.0033 - val_acc: 0.4667\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8792 - acc: 0.6815 - val_loss: 0.9790 - val_acc: 0.5333\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8515 - acc: 0.6815 - val_loss: 0.9500 - val_acc: 0.5333\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8254 - acc: 0.6815 - val_loss: 0.9260 - val_acc: 0.5333\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7947 - acc: 0.6815 - val_loss: 0.8990 - val_acc: 0.5333\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7688 - acc: 0.6815 - val_loss: 0.8639 - val_acc: 0.5333\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7406 - acc: 0.6815 - val_loss: 0.8414 - val_acc: 0.5333\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7164 - acc: 0.6815 - val_loss: 0.8165 - val_acc: 0.5333\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6924 - acc: 0.6815 - val_loss: 0.7866 - val_acc: 0.5333\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6688 - acc: 0.6815 - val_loss: 0.7650 - val_acc: 0.5333\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6475 - acc: 0.6815 - val_loss: 0.7425 - val_acc: 0.5333\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6281 - acc: 0.6815 - val_loss: 0.7219 - val_acc: 0.5333\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6118 - acc: 0.6963 - val_loss: 0.6929 - val_acc: 0.6000\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5927 - acc: 0.6815 - val_loss: 0.6809 - val_acc: 0.5333\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5778 - acc: 0.6889 - val_loss: 0.6686 - val_acc: 0.5333\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5635 - acc: 0.7111 - val_loss: 0.6412 - val_acc: 0.6000\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5498 - acc: 0.6963 - val_loss: 0.6395 - val_acc: 0.5333\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5386 - acc: 0.7185 - val_loss: 0.6096 - val_acc: 0.6667\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5259 - acc: 0.7111 - val_loss: 0.6084 - val_acc: 0.6000\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5135 - acc: 0.7185 - val_loss: 0.5925 - val_acc: 0.6000\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5038 - acc: 0.7259 - val_loss: 0.5768 - val_acc: 0.6667\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4950 - acc: 0.7630 - val_loss: 0.5694 - val_acc: 0.6667\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4872 - acc: 0.7407 - val_loss: 0.5674 - val_acc: 0.6000\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4776 - acc: 0.7704 - val_loss: 0.5451 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4716 - acc: 0.7556 - val_loss: 0.5412 - val_acc: 0.8000\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4633 - acc: 0.7704 - val_loss: 0.5323 - val_acc: 0.8000\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4556 - acc: 0.7926 - val_loss: 0.5170 - val_acc: 0.8667\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4489 - acc: 0.8815 - val_loss: 0.5078 - val_acc: 0.8667\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4432 - acc: 0.7926 - val_loss: 0.5123 - val_acc: 0.8000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4380 - acc: 0.8667 - val_loss: 0.4957 - val_acc: 0.8667\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4310 - acc: 0.8444 - val_loss: 0.5051 - val_acc: 0.8000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4272 - acc: 0.8889 - val_loss: 0.4816 - val_acc: 0.8667\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4194 - acc: 0.8444 - val_loss: 0.4902 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4165 - acc: 0.8741 - val_loss: 0.4721 - val_acc: 0.8667\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4082 - acc: 0.8667 - val_loss: 0.4743 - val_acc: 0.8667\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4060 - acc: 0.8741 - val_loss: 0.4589 - val_acc: 0.8667\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3990 - acc: 0.8815 - val_loss: 0.4607 - val_acc: 0.8667\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3942 - acc: 0.8889 - val_loss: 0.4563 - val_acc: 0.8667\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3881 - acc: 0.9185 - val_loss: 0.4408 - val_acc: 0.9333\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3844 - acc: 0.9407 - val_loss: 0.4333 - val_acc: 0.9333\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3799 - acc: 0.9407 - val_loss: 0.4397 - val_acc: 0.8667\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3755 - acc: 0.9407 - val_loss: 0.4320 - val_acc: 0.8667\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3704 - acc: 0.9407 - val_loss: 0.4287 - val_acc: 0.8667\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3679 - acc: 0.9407 - val_loss: 0.4101 - val_acc: 0.9333\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3642 - acc: 0.9333 - val_loss: 0.4195 - val_acc: 0.9333\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3579 - acc: 0.9407 - val_loss: 0.4136 - val_acc: 0.9333\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3525 - acc: 0.9407 - val_loss: 0.4004 - val_acc: 0.9333\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3491 - acc: 0.9481 - val_loss: 0.3928 - val_acc: 0.9333\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3458 - acc: 0.9407 - val_loss: 0.3983 - val_acc: 0.9333\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.9481 - val_loss: 0.3903 - val_acc: 0.9333\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3360 - acc: 0.9556 - val_loss: 0.3891 - val_acc: 0.9333\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3320 - acc: 0.9481 - val_loss: 0.3872 - val_acc: 0.9333\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3276 - acc: 0.9556 - val_loss: 0.3775 - val_acc: 0.9333\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3245 - acc: 0.9556 - val_loss: 0.3736 - val_acc: 0.9333\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3217 - acc: 0.9481 - val_loss: 0.3710 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3158 - acc: 0.9704 - val_loss: 0.3568 - val_acc: 0.9333\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3119 - acc: 0.9630 - val_loss: 0.3614 - val_acc: 0.9333\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3093 - acc: 0.9704 - val_loss: 0.3595 - val_acc: 0.9333\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3075 - acc: 0.9407 - val_loss: 0.3534 - val_acc: 0.9333\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.9556 - val_loss: 0.3455 - val_acc: 0.9333\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2960 - acc: 0.9630 - val_loss: 0.3535 - val_acc: 0.9333\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2951 - acc: 0.9630 - val_loss: 0.3371 - val_acc: 0.9333\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2907 - acc: 0.9630 - val_loss: 0.3359 - val_acc: 0.9333\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2892 - acc: 0.9630 - val_loss: 0.3296 - val_acc: 0.9333\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2822 - acc: 0.9556 - val_loss: 0.3482 - val_acc: 0.9333\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2785 - acc: 0.9556 - val_loss: 0.3228 - val_acc: 0.9333\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2778 - acc: 0.9630 - val_loss: 0.3187 - val_acc: 0.9333\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2721 - acc: 0.9704 - val_loss: 0.3172 - val_acc: 0.9333\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2693 - acc: 0.9630 - val_loss: 0.3189 - val_acc: 0.9333\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2667 - acc: 0.9704 - val_loss: 0.3241 - val_acc: 0.9333\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2636 - acc: 0.9704 - val_loss: 0.3059 - val_acc: 0.9333\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.9704 - val_loss: 0.3035 - val_acc: 0.9333\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2560 - acc: 0.9704 - val_loss: 0.3014 - val_acc: 0.9333\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.9630 - val_loss: 0.3151 - val_acc: 0.9333\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2500 - acc: 0.9704 - val_loss: 0.2919 - val_acc: 0.9333\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2463 - acc: 0.9704 - val_loss: 0.2959 - val_acc: 0.9333\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2462 - acc: 0.9704 - val_loss: 0.3012 - val_acc: 0.9333\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2424 - acc: 0.9630 - val_loss: 0.2815 - val_acc: 0.9333\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2390 - acc: 0.9704 - val_loss: 0.2775 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2363 - acc: 0.9704 - val_loss: 0.2833 - val_acc: 0.9333\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2337 - acc: 0.9704 - val_loss: 0.2769 - val_acc: 0.9333\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2323 - acc: 0.9704 - val_loss: 0.2802 - val_acc: 0.9333\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2290 - acc: 0.9704 - val_loss: 0.2655 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2260 - acc: 0.9704 - val_loss: 0.2663 - val_acc: 0.9333\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2251 - acc: 0.9704 - val_loss: 0.2722 - val_acc: 0.9333\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2207 - acc: 0.9704 - val_loss: 0.2541 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2169 - acc: 0.9704 - val_loss: 0.2630 - val_acc: 0.9333\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2151 - acc: 0.9704 - val_loss: 0.2624 - val_acc: 0.9333\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2110 - acc: 0.9704 - val_loss: 0.2472 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2109 - acc: 0.9630 - val_loss: 0.2549 - val_acc: 0.9333\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2074 - acc: 0.9778 - val_loss: 0.2515 - val_acc: 0.9333\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2058 - acc: 0.9778 - val_loss: 0.2453 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2034 - acc: 0.9704 - val_loss: 0.2478 - val_acc: 0.9333\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2005 - acc: 0.9704 - val_loss: 0.2431 - val_acc: 0.9333\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1982 - acc: 0.9704 - val_loss: 0.2436 - val_acc: 0.9333\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1965 - acc: 0.9778 - val_loss: 0.2348 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1943 - acc: 0.9778 - val_loss: 0.2330 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1945 - acc: 0.9704 - val_loss: 0.2460 - val_acc: 0.9333\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1909 - acc: 0.9778 - val_loss: 0.2284 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1898 - acc: 0.9704 - val_loss: 0.2283 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1863 - acc: 0.9778 - val_loss: 0.2248 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1854 - acc: 0.9778 - val_loss: 0.2209 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1846 - acc: 0.9704 - val_loss: 0.2282 - val_acc: 0.9333\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1828 - acc: 0.9778 - val_loss: 0.2192 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1808 - acc: 0.9704 - val_loss: 0.2115 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1786 - acc: 0.9778 - val_loss: 0.2183 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1765 - acc: 0.9704 - val_loss: 0.2129 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1740 - acc: 0.9778 - val_loss: 0.2044 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1739 - acc: 0.9630 - val_loss: 0.2019 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1740 - acc: 0.9778 - val_loss: 0.2083 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1686 - acc: 0.9778 - val_loss: 0.2014 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1700 - acc: 0.9704 - val_loss: 0.2063 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1679 - acc: 0.9704 - val_loss: 0.2074 - val_acc: 0.9333\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1659 - acc: 0.9704 - val_loss: 0.1889 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1615 - acc: 0.9778 - val_loss: 0.2006 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1612 - acc: 0.9778 - val_loss: 0.2046 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1602 - acc: 0.9778 - val_loss: 0.1981 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1600 - acc: 0.9630 - val_loss: 0.1917 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1575 - acc: 0.9778 - val_loss: 0.1927 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1570 - acc: 0.9778 - val_loss: 0.1826 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1542 - acc: 0.9778 - val_loss: 0.1907 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1531 - acc: 0.9778 - val_loss: 0.1820 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1516 - acc: 0.9778 - val_loss: 0.1856 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1514 - acc: 0.9778 - val_loss: 0.1841 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1507 - acc: 0.9778 - val_loss: 0.1763 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1514 - acc: 0.9630 - val_loss: 0.1799 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1485 - acc: 0.9778 - val_loss: 0.1885 - val_acc: 0.9333\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1457 - acc: 0.9778 - val_loss: 0.1767 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1444 - acc: 0.9778 - val_loss: 0.1750 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1446 - acc: 0.9778 - val_loss: 0.1726 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1413 - acc: 0.9778 - val_loss: 0.1823 - val_acc: 0.9333\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1414 - acc: 0.9778 - val_loss: 0.1691 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1402 - acc: 0.9778 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1396 - acc: 0.9778 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1390 - acc: 0.9630 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1383 - acc: 0.9778 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1402 - acc: 0.9778 - val_loss: 0.1615 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1349 - acc: 0.9778 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1351 - acc: 0.9778 - val_loss: 0.1671 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1331 - acc: 0.9778 - val_loss: 0.1629 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1333 - acc: 0.9704 - val_loss: 0.1548 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1329 - acc: 0.9778 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1300 - acc: 0.9778 - val_loss: 0.1576 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1316 - acc: 0.9778 - val_loss: 0.1541 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1302 - acc: 0.9704 - val_loss: 0.1582 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1296 - acc: 0.9778 - val_loss: 0.1535 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1282 - acc: 0.9778 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1274 - acc: 0.9778 - val_loss: 0.1589 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1257 - acc: 0.9778 - val_loss: 0.1486 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1246 - acc: 0.9704 - val_loss: 0.1518 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1232 - acc: 0.9778 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1236 - acc: 0.9778 - val_loss: 0.1544 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1250 - acc: 0.9778 - val_loss: 0.1411 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1239 - acc: 0.9630 - val_loss: 0.1356 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1221 - acc: 0.9778 - val_loss: 0.1508 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1204 - acc: 0.9778 - val_loss: 0.1437 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1194 - acc: 0.9778 - val_loss: 0.1488 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1188 - acc: 0.9778 - val_loss: 0.1397 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1177 - acc: 0.9778 - val_loss: 0.1403 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1181 - acc: 0.9704 - val_loss: 0.1372 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1160 - acc: 0.9778 - val_loss: 0.1480 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1167 - acc: 0.9778 - val_loss: 0.1389 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1144 - acc: 0.9778 - val_loss: 0.1395 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1155 - acc: 0.9778 - val_loss: 0.1435 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1142 - acc: 0.9778 - val_loss: 0.1353 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1147 - acc: 0.9704 - val_loss: 0.1359 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1174 - acc: 0.9704 - val_loss: 0.1335 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1129 - acc: 0.9778 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1111 - acc: 0.9778 - val_loss: 0.1311 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1110 - acc: 0.9778 - val_loss: 0.1298 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1115 - acc: 0.9778 - val_loss: 0.1374 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1152 - acc: 0.9704 - val_loss: 0.1319 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0985 - acc: 0.984 - 0s 1ms/step - loss: 0.1092 - acc: 0.9778 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1088 - acc: 0.9778 - val_loss: 0.1295 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1090 - acc: 0.9704 - val_loss: 0.1299 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0955 - acc: 0.989 - 0s 1ms/step - loss: 0.1081 - acc: 0.9778 - val_loss: 0.1379 - val_acc: 1.0000\n",
      "Epoch 183/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1085 - acc: 0.9778 - val_loss: 0.1210 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1068 - acc: 0.9778 - val_loss: 0.1281 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1067 - acc: 0.9778 - val_loss: 0.1302 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1096 - acc: 0.9630 - val_loss: 0.1244 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1045 - acc: 0.9778 - val_loss: 0.1275 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1051 - acc: 0.9778 - val_loss: 0.1314 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1031 - acc: 0.9778 - val_loss: 0.1184 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1054 - acc: 0.9778 - val_loss: 0.1263 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1041 - acc: 0.9704 - val_loss: 0.1206 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1047 - acc: 0.9778 - val_loss: 0.1283 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1055 - acc: 0.9778 - val_loss: 0.1216 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1024 - acc: 0.9778 - val_loss: 0.1254 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1018 - acc: 0.9778 - val_loss: 0.1183 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9704 - val_loss: 0.1208 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1045 - acc: 0.9704 - val_loss: 0.1182 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1030 - acc: 0.9778 - val_loss: 0.1174 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1048 - acc: 0.9704 - val_loss: 0.1212 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1046 - acc: 0.9704 - val_loss: 0.1176 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 55ms/step - loss: 1.1148 - acc: 0.3333 - val_loss: 0.8976 - val_acc: 0.4000\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.7815 - acc: 0.6593 - val_loss: 0.7284 - val_acc: 1.0000\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6861 - acc: 0.9556 - val_loss: 0.6632 - val_acc: 0.8667\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6317 - acc: 0.9556 - val_loss: 0.6340 - val_acc: 0.9333\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5909 - acc: 0.9333 - val_loss: 0.6010 - val_acc: 0.8667\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5558 - acc: 0.9407 - val_loss: 0.5834 - val_acc: 0.9333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.5225 - acc: 0.952 - 0s 1ms/step - loss: 0.5304 - acc: 0.9481 - val_loss: 0.5559 - val_acc: 0.8667\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5136 - acc: 0.9333 - val_loss: 0.5601 - val_acc: 0.9333\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4938 - acc: 0.9778 - val_loss: 0.5383 - val_acc: 0.9333\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4781 - acc: 0.9407 - val_loss: 0.5247 - val_acc: 0.9333\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4631 - acc: 0.9481 - val_loss: 0.5054 - val_acc: 0.9333\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4511 - acc: 0.9556 - val_loss: 0.5036 - val_acc: 0.9333\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4377 - acc: 0.9630 - val_loss: 0.4967 - val_acc: 0.9333\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4257 - acc: 0.9407 - val_loss: 0.4742 - val_acc: 0.8667\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4143 - acc: 0.9630 - val_loss: 0.4721 - val_acc: 0.9333\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4021 - acc: 0.9704 - val_loss: 0.4652 - val_acc: 0.9333\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3922 - acc: 0.9481 - val_loss: 0.4544 - val_acc: 0.9333\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3814 - acc: 0.9778 - val_loss: 0.4535 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3722 - acc: 0.9704 - val_loss: 0.4342 - val_acc: 0.9333\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3652 - acc: 0.9481 - val_loss: 0.4333 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3637 - acc: 0.9407 - val_loss: 0.4200 - val_acc: 0.9333\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3470 - acc: 0.9778 - val_loss: 0.4191 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3434 - acc: 0.9630 - val_loss: 0.4186 - val_acc: 0.9333\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3336 - acc: 0.9556 - val_loss: 0.3994 - val_acc: 0.9333\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3286 - acc: 0.9704 - val_loss: 0.4127 - val_acc: 0.9333\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3176 - acc: 0.9630 - val_loss: 0.3893 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3130 - acc: 0.9630 - val_loss: 0.3744 - val_acc: 0.9333\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3039 - acc: 0.9778 - val_loss: 0.3768 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.9481 - val_loss: 0.3676 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2932 - acc: 0.9704 - val_loss: 0.3552 - val_acc: 0.9333\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2905 - acc: 0.9481 - val_loss: 0.3559 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2826 - acc: 0.9778 - val_loss: 0.3539 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2742 - acc: 0.9778 - val_loss: 0.3457 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2690 - acc: 0.9778 - val_loss: 0.3388 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2655 - acc: 0.9704 - val_loss: 0.3444 - val_acc: 0.9333\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2601 - acc: 0.9704 - val_loss: 0.3331 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2572 - acc: 0.9704 - val_loss: 0.3215 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2538 - acc: 0.9778 - val_loss: 0.3161 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2447 - acc: 0.9778 - val_loss: 0.3136 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2396 - acc: 0.9778 - val_loss: 0.3103 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2358 - acc: 0.9778 - val_loss: 0.3085 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2340 - acc: 0.9778 - val_loss: 0.3044 - val_acc: 1.0000\n",
      "Epoch 43/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2310 - acc: 0.9704 - val_loss: 0.2985 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2239 - acc: 0.9630 - val_loss: 0.2881 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2197 - acc: 0.9778 - val_loss: 0.2846 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2161 - acc: 0.9778 - val_loss: 0.2857 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2181 - acc: 0.9778 - val_loss: 0.2911 - val_acc: 0.9333\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2153 - acc: 0.9778 - val_loss: 0.2869 - val_acc: 0.9333\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2061 - acc: 0.9778 - val_loss: 0.2768 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2025 - acc: 0.9778 - val_loss: 0.2627 - val_acc: 0.9333\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1991 - acc: 0.9778 - val_loss: 0.2674 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1963 - acc: 0.9778 - val_loss: 0.2657 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1961 - acc: 0.9778 - val_loss: 0.2561 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1921 - acc: 0.9704 - val_loss: 0.2564 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1864 - acc: 0.9778 - val_loss: 0.2493 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1854 - acc: 0.9778 - val_loss: 0.2586 - val_acc: 0.9333\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1817 - acc: 0.9778 - val_loss: 0.2446 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1791 - acc: 0.9778 - val_loss: 0.2393 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1764 - acc: 0.9778 - val_loss: 0.2407 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1783 - acc: 0.9630 - val_loss: 0.2382 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1740 - acc: 0.9778 - val_loss: 0.2266 - val_acc: 0.9333\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1682 - acc: 0.9778 - val_loss: 0.2325 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1686 - acc: 0.9704 - val_loss: 0.2221 - val_acc: 0.9333\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1633 - acc: 0.9778 - val_loss: 0.2309 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1607 - acc: 0.9778 - val_loss: 0.2240 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1614 - acc: 0.9778 - val_loss: 0.2215 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1560 - acc: 0.9778 - val_loss: 0.2229 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1584 - acc: 0.9778 - val_loss: 0.2143 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1582 - acc: 0.9556 - val_loss: 0.2142 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1543 - acc: 0.9778 - val_loss: 0.2066 - val_acc: 0.9333\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1481 - acc: 0.9704 - val_loss: 0.2141 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1466 - acc: 0.9778 - val_loss: 0.2048 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1442 - acc: 0.9778 - val_loss: 0.2072 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1422 - acc: 0.9778 - val_loss: 0.2021 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1428 - acc: 0.9704 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1400 - acc: 0.9778 - val_loss: 0.1956 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1422 - acc: 0.9778 - val_loss: 0.1937 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1372 - acc: 0.9778 - val_loss: 0.2023 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1356 - acc: 0.9778 - val_loss: 0.1901 - val_acc: 0.9333\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1334 - acc: 0.9778 - val_loss: 0.1952 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1312 - acc: 0.9778 - val_loss: 0.1898 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1305 - acc: 0.9778 - val_loss: 0.1929 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1281 - acc: 0.9778 - val_loss: 0.1840 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1302 - acc: 0.9704 - val_loss: 0.1870 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1304 - acc: 0.9778 - val_loss: 0.1869 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1251 - acc: 0.9778 - val_loss: 0.1846 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1239 - acc: 0.9778 - val_loss: 0.1823 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1211 - acc: 0.9778 - val_loss: 0.1853 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1212 - acc: 0.9778 - val_loss: 0.1765 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1190 - acc: 0.9778 - val_loss: 0.1818 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1192 - acc: 0.9778 - val_loss: 0.1722 - val_acc: 0.9333\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1179 - acc: 0.9778 - val_loss: 0.1756 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1159 - acc: 0.9778 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1150 - acc: 0.9778 - val_loss: 0.1768 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1142 - acc: 0.9778 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1121 - acc: 0.9778 - val_loss: 0.1760 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1173 - acc: 0.9778 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1100 - acc: 0.9778 - val_loss: 0.1764 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1101 - acc: 0.9778 - val_loss: 0.1707 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1094 - acc: 0.9852 - val_loss: 0.1670 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1084 - acc: 0.9778 - val_loss: 0.1639 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1057 - acc: 0.9778 - val_loss: 0.1678 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1066 - acc: 0.9778 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 104/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1049 - acc: 0.9778 - val_loss: 0.1634 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1052 - acc: 0.9778 - val_loss: 0.1619 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1050 - acc: 0.9630 - val_loss: 0.1608 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1021 - acc: 0.9778 - val_loss: 0.1580 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1016 - acc: 0.9778 - val_loss: 0.1624 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1007 - acc: 0.9778 - val_loss: 0.1602 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1020 - acc: 0.9778 - val_loss: 0.1643 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0994 - acc: 0.9852 - val_loss: 0.1578 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0993 - acc: 0.9778 - val_loss: 0.1570 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0972 - acc: 0.9778 - val_loss: 0.1562 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0965 - acc: 0.9852 - val_loss: 0.1573 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0967 - acc: 0.9852 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0956 - acc: 0.9778 - val_loss: 0.1510 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0949 - acc: 0.9778 - val_loss: 0.1547 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0958 - acc: 0.9852 - val_loss: 0.1489 - val_acc: 0.9333\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0936 - acc: 0.9778 - val_loss: 0.1525 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0928 - acc: 0.9778 - val_loss: 0.1529 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0933 - acc: 0.9778 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0934 - acc: 0.9704 - val_loss: 0.1472 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0909 - acc: 0.9778 - val_loss: 0.1472 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0913 - acc: 0.9778 - val_loss: 0.1525 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0904 - acc: 0.9704 - val_loss: 0.1500 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0907 - acc: 0.9704 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0887 - acc: 0.9778 - val_loss: 0.1488 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0903 - acc: 0.9778 - val_loss: 0.1528 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0905 - acc: 0.9704 - val_loss: 0.1639 - val_acc: 0.9333\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0889 - acc: 0.9778 - val_loss: 0.1472 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0876 - acc: 0.9778 - val_loss: 0.1492 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0896 - acc: 0.9704 - val_loss: 0.1396 - val_acc: 0.9333\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0887 - acc: 0.9778 - val_loss: 0.1420 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0893 - acc: 0.9704 - val_loss: 0.1420 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0878 - acc: 0.9778 - val_loss: 0.1440 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0859 - acc: 0.9778 - val_loss: 0.1437 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0843 - acc: 0.9778 - val_loss: 0.1375 - val_acc: 0.9333\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0837 - acc: 0.9778 - val_loss: 0.1427 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0842 - acc: 0.9704 - val_loss: 0.1469 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0831 - acc: 0.9704 - val_loss: 0.1376 - val_acc: 0.9333\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0866 - acc: 0.9778 - val_loss: 0.1458 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0831 - acc: 0.9778 - val_loss: 0.1433 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0823 - acc: 0.9778 - val_loss: 0.1426 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 0.9778 - val_loss: 0.1366 - val_acc: 0.9333\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0835 - acc: 0.9778 - val_loss: 0.1466 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0822 - acc: 0.9778 - val_loss: 0.1423 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0820 - acc: 0.9778 - val_loss: 0.1354 - val_acc: 0.9333\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0959 - acc: 0.9556 - val_loss: 0.1346 - val_acc: 0.9333\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0818 - acc: 0.9778 - val_loss: 0.1355 - val_acc: 0.9333\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0780 - acc: 0.9704 - val_loss: 0.1377 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0778 - acc: 0.9778 - val_loss: 0.1373 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0807 - acc: 0.9778 - val_loss: 0.1399 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0797 - acc: 0.9852 - val_loss: 0.1377 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0779 - acc: 0.9704 - val_loss: 0.1363 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0791 - acc: 0.9704 - val_loss: 0.1345 - val_acc: 0.9333\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0845 - acc: 0.9778 - val_loss: 0.1409 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0774 - acc: 0.9778 - val_loss: 0.1450 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0795 - acc: 0.9704 - val_loss: 0.1390 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0814 - acc: 0.9704 - val_loss: 0.1449 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0792 - acc: 0.9778 - val_loss: 0.1325 - val_acc: 0.9333\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0792 - acc: 0.9704 - val_loss: 0.1393 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0770 - acc: 0.9778 - val_loss: 0.1327 - val_acc: 0.9333\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0737 - acc: 0.9852 - val_loss: 0.1431 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0740 - acc: 0.9778 - val_loss: 0.1328 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0737 - acc: 0.9778 - val_loss: 0.1330 - val_acc: 0.9333\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0797 - acc: 0.9704 - val_loss: 0.1325 - val_acc: 0.9333\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0741 - acc: 0.9778 - val_loss: 0.1329 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0725 - acc: 0.9778 - val_loss: 0.1309 - val_acc: 0.9333\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0727 - acc: 0.9778 - val_loss: 0.1353 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0798 - acc: 0.9704 - val_loss: 0.1307 - val_acc: 0.9333\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0715 - acc: 0.9778 - val_loss: 0.1355 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0726 - acc: 0.9852 - val_loss: 0.1314 - val_acc: 0.9333\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0738 - acc: 0.9778 - val_loss: 0.1312 - val_acc: 0.9333\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0787 - acc: 0.9704 - val_loss: 0.1348 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0739 - acc: 0.9778 - val_loss: 0.1271 - val_acc: 0.9333\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0779 - acc: 0.9704 - val_loss: 0.1309 - val_acc: 0.9333\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0716 - acc: 0.9778 - val_loss: 0.1321 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0718 - acc: 0.9852 - val_loss: 0.1356 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0696 - acc: 0.9778 - val_loss: 0.1287 - val_acc: 0.9333\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0709 - acc: 0.9778 - val_loss: 0.1370 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0719 - acc: 0.9778 - val_loss: 0.1285 - val_acc: 0.9333\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0744 - acc: 0.9778 - val_loss: 0.1291 - val_acc: 0.9333\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0717 - acc: 0.9852 - val_loss: 0.1368 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0702 - acc: 0.9778 - val_loss: 0.1272 - val_acc: 0.9333\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0721 - acc: 0.9778 - val_loss: 0.1467 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0705 - acc: 0.9852 - val_loss: 0.1298 - val_acc: 0.9333\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0679 - acc: 0.9778 - val_loss: 0.1283 - val_acc: 0.9333\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0741 - acc: 0.9778 - val_loss: 0.1366 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0668 - acc: 0.9778 - val_loss: 0.1302 - val_acc: 0.9333\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0745 - acc: 0.9704 - val_loss: 0.1317 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0683 - acc: 0.9778 - val_loss: 0.1318 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0709 - acc: 0.9704 - val_loss: 0.1347 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0666 - acc: 0.9778 - val_loss: 0.1329 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0668 - acc: 0.9778 - val_loss: 0.1296 - val_acc: 0.9333\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0658 - acc: 0.9852 - val_loss: 0.1283 - val_acc: 0.9333\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0662 - acc: 0.9778 - val_loss: 0.1388 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0686 - acc: 0.9704 - val_loss: 0.1313 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0657 - acc: 0.976 - 0s 2ms/step - loss: 0.0664 - acc: 0.9778 - val_loss: 0.1379 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0672 - acc: 0.9778 - val_loss: 0.1282 - val_acc: 0.9333\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0707 - acc: 0.9778 - val_loss: 0.1243 - val_acc: 0.9333\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 55ms/step - loss: 4.5053 - acc: 0.3407 - val_loss: 4.7418 - val_acc: 0.2667\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.7671 - acc: 0.3407 - val_loss: 3.9921 - val_acc: 0.2667\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.1497 - acc: 0.3407 - val_loss: 3.3039 - val_acc: 0.2667\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.6102 - acc: 0.3407 - val_loss: 2.7511 - val_acc: 0.2667\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.1879 - acc: 0.3407 - val_loss: 2.2877 - val_acc: 0.2667\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.8487 - acc: 0.3407 - val_loss: 1.9367 - val_acc: 0.2667\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.6102 - acc: 0.3407 - val_loss: 1.6475 - val_acc: 0.2667\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.4206 - acc: 0.3407 - val_loss: 1.4631 - val_acc: 0.2667\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.3001 - acc: 0.3407 - val_loss: 1.3586 - val_acc: 0.2667\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2317 - acc: 0.3407 - val_loss: 1.2710 - val_acc: 0.2667\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1795 - acc: 0.3407 - val_loss: 1.2081 - val_acc: 0.2667\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1423 - acc: 0.3407 - val_loss: 1.1605 - val_acc: 0.2667\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1141 - acc: 0.3407 - val_loss: 1.1238 - val_acc: 0.2667\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0927 - acc: 0.3407 - val_loss: 1.0955 - val_acc: 0.2667\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0767 - acc: 0.3407 - val_loss: 1.0765 - val_acc: 0.3333\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0652 - acc: 0.3852 - val_loss: 1.0541 - val_acc: 0.3333\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0528 - acc: 0.4296 - val_loss: 1.0394 - val_acc: 0.3333\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0421 - acc: 0.5259 - val_loss: 1.0244 - val_acc: 0.4667\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0307 - acc: 0.6148 - val_loss: 1.0148 - val_acc: 0.5333\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0212 - acc: 0.6593 - val_loss: 1.0080 - val_acc: 0.5333\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0126 - acc: 0.6963 - val_loss: 0.9990 - val_acc: 0.6000\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0025 - acc: 0.6963 - val_loss: 0.9913 - val_acc: 0.6000\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9925 - acc: 0.7037 - val_loss: 0.9819 - val_acc: 0.6000\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9829 - acc: 0.7407 - val_loss: 0.9701 - val_acc: 0.6000\n",
      "Epoch 25/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9729 - acc: 0.7407 - val_loss: 0.9610 - val_acc: 0.6000\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9641 - acc: 0.7407 - val_loss: 0.9506 - val_acc: 0.6667\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9527 - acc: 0.7481 - val_loss: 0.9392 - val_acc: 0.6000\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9408 - acc: 0.7704 - val_loss: 0.9280 - val_acc: 0.6667\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9299 - acc: 0.7704 - val_loss: 0.9157 - val_acc: 0.6667\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9175 - acc: 0.7926 - val_loss: 0.9024 - val_acc: 0.7333\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9052 - acc: 0.7852 - val_loss: 0.8882 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8920 - acc: 0.8000 - val_loss: 0.8741 - val_acc: 0.7333\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8782 - acc: 0.8296 - val_loss: 0.8598 - val_acc: 0.8000\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8641 - acc: 0.8296 - val_loss: 0.8461 - val_acc: 0.8000\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8499 - acc: 0.8370 - val_loss: 0.8296 - val_acc: 0.8000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8348 - acc: 0.8296 - val_loss: 0.8143 - val_acc: 0.8000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8205 - acc: 0.8444 - val_loss: 0.7987 - val_acc: 0.8000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8050 - acc: 0.8519 - val_loss: 0.7820 - val_acc: 0.8667\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7893 - acc: 0.8519 - val_loss: 0.7663 - val_acc: 0.8667\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7739 - acc: 0.8519 - val_loss: 0.7494 - val_acc: 0.8667\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7572 - acc: 0.8593 - val_loss: 0.7337 - val_acc: 0.8667\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7425 - acc: 0.8519 - val_loss: 0.7168 - val_acc: 0.8667\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7272 - acc: 0.8667 - val_loss: 0.7000 - val_acc: 0.9333\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7112 - acc: 0.8741 - val_loss: 0.6845 - val_acc: 0.9333\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6956 - acc: 0.8963 - val_loss: 0.6695 - val_acc: 0.9333\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6821 - acc: 0.8815 - val_loss: 0.6557 - val_acc: 0.8667\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6664 - acc: 0.8889 - val_loss: 0.6394 - val_acc: 0.9333\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6523 - acc: 0.8889 - val_loss: 0.6245 - val_acc: 0.9333\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6381 - acc: 0.9037 - val_loss: 0.6125 - val_acc: 0.9333\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6251 - acc: 0.9037 - val_loss: 0.5970 - val_acc: 0.9333\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6122 - acc: 0.8963 - val_loss: 0.5824 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5998 - acc: 0.9037 - val_loss: 0.5700 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5887 - acc: 0.8963 - val_loss: 0.5569 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5769 - acc: 0.9037 - val_loss: 0.5484 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5648 - acc: 0.8963 - val_loss: 0.5353 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5546 - acc: 0.9037 - val_loss: 0.5236 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5447 - acc: 0.8963 - val_loss: 0.5149 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5348 - acc: 0.8963 - val_loss: 0.5017 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5254 - acc: 0.9111 - val_loss: 0.4968 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5168 - acc: 0.8963 - val_loss: 0.4862 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5079 - acc: 0.9111 - val_loss: 0.4774 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4994 - acc: 0.9111 - val_loss: 0.4702 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4907 - acc: 0.9111 - val_loss: 0.4578 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4837 - acc: 0.9111 - val_loss: 0.4517 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4756 - acc: 0.9037 - val_loss: 0.4437 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4692 - acc: 0.9111 - val_loss: 0.4401 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4611 - acc: 0.9111 - val_loss: 0.4311 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4544 - acc: 0.9185 - val_loss: 0.4222 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4479 - acc: 0.9111 - val_loss: 0.4178 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4422 - acc: 0.9185 - val_loss: 0.4083 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4360 - acc: 0.9333 - val_loss: 0.4047 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4287 - acc: 0.9259 - val_loss: 0.3994 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4233 - acc: 0.9259 - val_loss: 0.3979 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4177 - acc: 0.9333 - val_loss: 0.3867 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4112 - acc: 0.9333 - val_loss: 0.3825 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4057 - acc: 0.9185 - val_loss: 0.3780 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3997 - acc: 0.9259 - val_loss: 0.3652 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3943 - acc: 0.9259 - val_loss: 0.3627 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3896 - acc: 0.9333 - val_loss: 0.3573 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3844 - acc: 0.9185 - val_loss: 0.3528 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3782 - acc: 0.9407 - val_loss: 0.3492 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3740 - acc: 0.9333 - val_loss: 0.3409 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3685 - acc: 0.9407 - val_loss: 0.3389 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3642 - acc: 0.9333 - val_loss: 0.3337 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3604 - acc: 0.9481 - val_loss: 0.3264 - val_acc: 1.0000\n",
      "Epoch 86/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3566 - acc: 0.9407 - val_loss: 0.3225 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3496 - acc: 0.9407 - val_loss: 0.3196 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3460 - acc: 0.9407 - val_loss: 0.3102 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.9556 - val_loss: 0.3119 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3363 - acc: 0.9556 - val_loss: 0.3064 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3315 - acc: 0.9556 - val_loss: 0.2988 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3279 - acc: 0.9556 - val_loss: 0.2970 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3232 - acc: 0.9556 - val_loss: 0.2912 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3193 - acc: 0.9407 - val_loss: 0.2818 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3168 - acc: 0.9407 - val_loss: 0.2890 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3126 - acc: 0.9481 - val_loss: 0.2757 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3074 - acc: 0.9481 - val_loss: 0.2757 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3039 - acc: 0.9481 - val_loss: 0.2716 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2990 - acc: 0.9556 - val_loss: 0.2685 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2957 - acc: 0.9556 - val_loss: 0.2627 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2916 - acc: 0.9556 - val_loss: 0.2603 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2886 - acc: 0.9556 - val_loss: 0.2544 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2850 - acc: 0.9556 - val_loss: 0.2500 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2828 - acc: 0.9407 - val_loss: 0.2457 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2772 - acc: 0.9556 - val_loss: 0.2504 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2748 - acc: 0.9481 - val_loss: 0.2455 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2703 - acc: 0.9556 - val_loss: 0.2362 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2674 - acc: 0.9556 - val_loss: 0.2308 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2648 - acc: 0.9556 - val_loss: 0.2267 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2615 - acc: 0.9556 - val_loss: 0.2291 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2579 - acc: 0.9556 - val_loss: 0.2243 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.9556 - val_loss: 0.2193 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2523 - acc: 0.9556 - val_loss: 0.2194 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2489 - acc: 0.9556 - val_loss: 0.2121 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2470 - acc: 0.9630 - val_loss: 0.2084 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2451 - acc: 0.9556 - val_loss: 0.2122 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2445 - acc: 0.9556 - val_loss: 0.2010 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2440 - acc: 0.9185 - val_loss: 0.2143 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2396 - acc: 0.9556 - val_loss: 0.1951 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2330 - acc: 0.9556 - val_loss: 0.2017 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2318 - acc: 0.9556 - val_loss: 0.1957 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2272 - acc: 0.9556 - val_loss: 0.1890 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2261 - acc: 0.9556 - val_loss: 0.1898 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2251 - acc: 0.9630 - val_loss: 0.1839 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2198 - acc: 0.9556 - val_loss: 0.1906 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2187 - acc: 0.9556 - val_loss: 0.1812 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2159 - acc: 0.9556 - val_loss: 0.1773 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2138 - acc: 0.9556 - val_loss: 0.1847 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2115 - acc: 0.9556 - val_loss: 0.1736 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2093 - acc: 0.9630 - val_loss: 0.1698 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2070 - acc: 0.9556 - val_loss: 0.1690 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2049 - acc: 0.9556 - val_loss: 0.1739 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2027 - acc: 0.9556 - val_loss: 0.1640 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2010 - acc: 0.9556 - val_loss: 0.1623 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1988 - acc: 0.9556 - val_loss: 0.1652 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1970 - acc: 0.9556 - val_loss: 0.1600 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1949 - acc: 0.9556 - val_loss: 0.1563 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1943 - acc: 0.9556 - val_loss: 0.1536 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1918 - acc: 0.9556 - val_loss: 0.1476 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1917 - acc: 0.9556 - val_loss: 0.1541 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1882 - acc: 0.9556 - val_loss: 0.1503 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1872 - acc: 0.9630 - val_loss: 0.1440 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1843 - acc: 0.9630 - val_loss: 0.1470 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1834 - acc: 0.9556 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1821 - acc: 0.9556 - val_loss: 0.1414 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1809 - acc: 0.9556 - val_loss: 0.1393 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1782 - acc: 0.9630 - val_loss: 0.1397 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1770 - acc: 0.9630 - val_loss: 0.1351 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1763 - acc: 0.9556 - val_loss: 0.1426 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1766 - acc: 0.9630 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1717 - acc: 0.9630 - val_loss: 0.1325 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1706 - acc: 0.9556 - val_loss: 0.1361 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1705 - acc: 0.9556 - val_loss: 0.1265 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1682 - acc: 0.9556 - val_loss: 0.1298 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1665 - acc: 0.9556 - val_loss: 0.1233 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1658 - acc: 0.9556 - val_loss: 0.1282 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1644 - acc: 0.9630 - val_loss: 0.1191 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1640 - acc: 0.9556 - val_loss: 0.1174 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1619 - acc: 0.9556 - val_loss: 0.1191 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1646 - acc: 0.9556 - val_loss: 0.1215 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1588 - acc: 0.9556 - val_loss: 0.1184 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1582 - acc: 0.9556 - val_loss: 0.1169 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1577 - acc: 0.9630 - val_loss: 0.1133 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1577 - acc: 0.9556 - val_loss: 0.1123 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1554 - acc: 0.9556 - val_loss: 0.1164 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1536 - acc: 0.9556 - val_loss: 0.1126 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1577 - acc: 0.9556 - val_loss: 0.1119 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1531 - acc: 0.9556 - val_loss: 0.1101 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1513 - acc: 0.9556 - val_loss: 0.1064 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1490 - acc: 0.9556 - val_loss: 0.1027 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1481 - acc: 0.9556 - val_loss: 0.1079 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1479 - acc: 0.9556 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1477 - acc: 0.9556 - val_loss: 0.1059 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1470 - acc: 0.9630 - val_loss: 0.1003 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1452 - acc: 0.9630 - val_loss: 0.1098 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1439 - acc: 0.9556 - val_loss: 0.1036 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1439 - acc: 0.9556 - val_loss: 0.1009 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1426 - acc: 0.9556 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1427 - acc: 0.9556 - val_loss: 0.1031 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1450 - acc: 0.960 - 0s 1ms/step - loss: 0.1399 - acc: 0.9630 - val_loss: 0.0934 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1407 - acc: 0.9556 - val_loss: 0.0944 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1386 - acc: 0.9556 - val_loss: 0.0977 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1376 - acc: 0.9556 - val_loss: 0.0926 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1368 - acc: 0.9630 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1389 - acc: 0.9556 - val_loss: 0.0997 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1358 - acc: 0.9556 - val_loss: 0.0947 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1343 - acc: 0.9556 - val_loss: 0.0916 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1339 - acc: 0.9556 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1338 - acc: 0.9630 - val_loss: 0.0858 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1334 - acc: 0.9556 - val_loss: 0.0914 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1316 - acc: 0.9556 - val_loss: 0.0876 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1311 - acc: 0.9556 - val_loss: 0.0920 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1329 - acc: 0.9556 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1303 - acc: 0.9630 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9704 - val_loss: 0.0885 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1280 - acc: 0.9556 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1277 - acc: 0.9556 - val_loss: 0.0811 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1274 - acc: 0.9630 - val_loss: 0.0847 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1268 - acc: 0.9556 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1295 - acc: 0.9556 - val_loss: 0.0834 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 52ms/step - loss: 4.4691 - acc: 0.3481 - val_loss: 4.7459 - val_acc: 0.2000\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 3.6038 - acc: 0.3481 - val_loss: 3.7708 - val_acc: 0.2000\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.7860 - acc: 0.3481 - val_loss: 2.9190 - val_acc: 0.2000\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.1526 - acc: 0.3481 - val_loss: 2.2420 - val_acc: 0.2000\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.6634 - acc: 0.352 - 0s 1ms/step - loss: 1.6843 - acc: 0.3481 - val_loss: 1.7866 - val_acc: 0.2000\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.3922 - acc: 0.3630 - val_loss: 1.4556 - val_acc: 0.4000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1882 - acc: 0.4370 - val_loss: 1.2052 - val_acc: 0.4667\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0361 - acc: 0.4815 - val_loss: 1.0079 - val_acc: 0.4667\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9353 - acc: 0.4889 - val_loss: 0.9009 - val_acc: 0.6000\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8821 - acc: 0.6222 - val_loss: 0.8419 - val_acc: 1.0000\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8549 - acc: 0.8222 - val_loss: 0.7865 - val_acc: 1.0000\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8208 - acc: 0.7556 - val_loss: 0.7663 - val_acc: 0.9333\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7883 - acc: 0.8222 - val_loss: 0.7261 - val_acc: 1.0000\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7639 - acc: 0.8148 - val_loss: 0.6958 - val_acc: 1.0000\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7389 - acc: 0.8222 - val_loss: 0.6711 - val_acc: 1.0000\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7180 - acc: 0.8593 - val_loss: 0.6385 - val_acc: 1.0000\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.8222 - val_loss: 0.6205 - val_acc: 1.0000\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6739 - acc: 0.8370 - val_loss: 0.5985 - val_acc: 1.0000\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6547 - acc: 0.8148 - val_loss: 0.5804 - val_acc: 1.0000\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6358 - acc: 0.8741 - val_loss: 0.5496 - val_acc: 1.0000\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6186 - acc: 0.8370 - val_loss: 0.5400 - val_acc: 1.0000\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6012 - acc: 0.8519 - val_loss: 0.5160 - val_acc: 1.0000\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5854 - acc: 0.8370 - val_loss: 0.5031 - val_acc: 1.0000\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5713 - acc: 0.8667 - val_loss: 0.4821 - val_acc: 1.0000\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5583 - acc: 0.8370 - val_loss: 0.4737 - val_acc: 1.0000\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5439 - acc: 0.8519 - val_loss: 0.4520 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5338 - acc: 0.8667 - val_loss: 0.4413 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5210 - acc: 0.8667 - val_loss: 0.4285 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5095 - acc: 0.8741 - val_loss: 0.4165 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5005 - acc: 0.8741 - val_loss: 0.4050 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4930 - acc: 0.9259 - val_loss: 0.3968 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4815 - acc: 0.8815 - val_loss: 0.3843 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4722 - acc: 0.9037 - val_loss: 0.3729 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4628 - acc: 0.8741 - val_loss: 0.3677 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4565 - acc: 0.8889 - val_loss: 0.3509 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4489 - acc: 0.9481 - val_loss: 0.3460 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4401 - acc: 0.9185 - val_loss: 0.3369 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4309 - acc: 0.9407 - val_loss: 0.3278 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4240 - acc: 0.9259 - val_loss: 0.3243 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4167 - acc: 0.8963 - val_loss: 0.3168 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4107 - acc: 0.9407 - val_loss: 0.3081 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4027 - acc: 0.9481 - val_loss: 0.2996 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3967 - acc: 0.9333 - val_loss: 0.2916 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3891 - acc: 0.9630 - val_loss: 0.2873 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3848 - acc: 0.9333 - val_loss: 0.2840 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3761 - acc: 0.9630 - val_loss: 0.2686 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3720 - acc: 0.9556 - val_loss: 0.2659 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3655 - acc: 0.9556 - val_loss: 0.2606 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3607 - acc: 0.9778 - val_loss: 0.2538 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3570 - acc: 0.9556 - val_loss: 0.2488 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3495 - acc: 0.9704 - val_loss: 0.2426 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3447 - acc: 0.9556 - val_loss: 0.2451 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3405 - acc: 0.9556 - val_loss: 0.2335 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3365 - acc: 0.9778 - val_loss: 0.2257 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3345 - acc: 0.9481 - val_loss: 0.2268 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3232 - acc: 0.9704 - val_loss: 0.2170 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3192 - acc: 0.9704 - val_loss: 0.2116 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3119 - acc: 0.9704 - val_loss: 0.2108 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3099 - acc: 0.9704 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3060 - acc: 0.9704 - val_loss: 0.1982 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2997 - acc: 0.9704 - val_loss: 0.1954 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2952 - acc: 0.9704 - val_loss: 0.1910 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2893 - acc: 0.9704 - val_loss: 0.1871 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2856 - acc: 0.9630 - val_loss: 0.1862 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2831 - acc: 0.9704 - val_loss: 0.1786 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2761 - acc: 0.9704 - val_loss: 0.1733 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2724 - acc: 0.9704 - val_loss: 0.1711 - val_acc: 1.0000\n",
      "Epoch 68/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2676 - acc: 0.9778 - val_loss: 0.1679 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2704 - acc: 0.9556 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2655 - acc: 0.9481 - val_loss: 0.1591 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2605 - acc: 0.9630 - val_loss: 0.1603 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2557 - acc: 0.9926 - val_loss: 0.1515 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2475 - acc: 0.9778 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2463 - acc: 0.9630 - val_loss: 0.1456 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2463 - acc: 0.9630 - val_loss: 0.1426 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2398 - acc: 0.9704 - val_loss: 0.1432 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2366 - acc: 0.9778 - val_loss: 0.1407 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2309 - acc: 0.9778 - val_loss: 0.1350 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2289 - acc: 0.9778 - val_loss: 0.1364 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2229 - acc: 0.9778 - val_loss: 0.1289 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2213 - acc: 0.9778 - val_loss: 0.1257 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2159 - acc: 0.9778 - val_loss: 0.1240 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2137 - acc: 0.9778 - val_loss: 0.1214 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2124 - acc: 0.9778 - val_loss: 0.1164 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2114 - acc: 0.9778 - val_loss: 0.1180 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2037 - acc: 0.9778 - val_loss: 0.1115 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2026 - acc: 0.9778 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1987 - acc: 0.9778 - val_loss: 0.1081 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1959 - acc: 0.9778 - val_loss: 0.1062 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1948 - acc: 0.9778 - val_loss: 0.1052 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1910 - acc: 0.9778 - val_loss: 0.1010 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1886 - acc: 0.9778 - val_loss: 0.1021 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1860 - acc: 0.9778 - val_loss: 0.0975 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1857 - acc: 0.9778 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1822 - acc: 0.9852 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1798 - acc: 0.9704 - val_loss: 0.0910 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1779 - acc: 0.9778 - val_loss: 0.0890 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1750 - acc: 0.9704 - val_loss: 0.0908 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1736 - acc: 0.9778 - val_loss: 0.0851 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1771 - acc: 0.9704 - val_loss: 0.0828 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1691 - acc: 0.9704 - val_loss: 0.0822 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1670 - acc: 0.9704 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1635 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1627 - acc: 0.9778 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1618 - acc: 0.9778 - val_loss: 0.0760 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1601 - acc: 0.9778 - val_loss: 0.0762 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1599 - acc: 0.9778 - val_loss: 0.0743 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1632 - acc: 0.9704 - val_loss: 0.0708 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1556 - acc: 0.9778 - val_loss: 0.0719 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1536 - acc: 0.9778 - val_loss: 0.0690 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1509 - acc: 0.9852 - val_loss: 0.0681 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1496 - acc: 0.9778 - val_loss: 0.0691 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1483 - acc: 0.9778 - val_loss: 0.0659 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1463 - acc: 0.9778 - val_loss: 0.0639 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1454 - acc: 0.9778 - val_loss: 0.0641 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1429 - acc: 0.9704 - val_loss: 0.0635 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1418 - acc: 0.9704 - val_loss: 0.0595 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1408 - acc: 0.9778 - val_loss: 0.0597 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1380 - acc: 0.9778 - val_loss: 0.0588 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1375 - acc: 0.9778 - val_loss: 0.0578 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1380 - acc: 0.9778 - val_loss: 0.0582 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1364 - acc: 0.9704 - val_loss: 0.0545 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1329 - acc: 0.9778 - val_loss: 0.0556 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1340 - acc: 0.9704 - val_loss: 0.0557 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1311 - acc: 0.9704 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1308 - acc: 0.9852 - val_loss: 0.0524 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1296 - acc: 0.9704 - val_loss: 0.0519 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1287 - acc: 0.9778 - val_loss: 0.0504 - val_acc: 1.0000\n",
      "Epoch 129/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1273 - acc: 0.9778 - val_loss: 0.0487 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1254 - acc: 0.9778 - val_loss: 0.0484 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1248 - acc: 0.9704 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1240 - acc: 0.9778 - val_loss: 0.0474 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1231 - acc: 0.9704 - val_loss: 0.0468 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1229 - acc: 0.9704 - val_loss: 0.0443 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1239 - acc: 0.9704 - val_loss: 0.0437 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1214 - acc: 0.9778 - val_loss: 0.0439 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1192 - acc: 0.9704 - val_loss: 0.0439 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1190 - acc: 0.9778 - val_loss: 0.0419 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1204 - acc: 0.9778 - val_loss: 0.0420 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1179 - acc: 0.9704 - val_loss: 0.0407 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1163 - acc: 0.9704 - val_loss: 0.0405 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1144 - acc: 0.9778 - val_loss: 0.0391 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1153 - acc: 0.9704 - val_loss: 0.0382 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1136 - acc: 0.9778 - val_loss: 0.0390 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1149 - acc: 0.9630 - val_loss: 0.0392 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1137 - acc: 0.9704 - val_loss: 0.0383 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1106 - acc: 0.9778 - val_loss: 0.0358 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1117 - acc: 0.9778 - val_loss: 0.0352 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1133 - acc: 0.9704 - val_loss: 0.0357 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1116 - acc: 0.9778 - val_loss: 0.0349 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1092 - acc: 0.9778 - val_loss: 0.0345 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1083 - acc: 0.9852 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9704 - val_loss: 0.0332 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1113 - acc: 0.9778 - val_loss: 0.0334 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1098 - acc: 0.9630 - val_loss: 0.0318 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1050 - acc: 0.9704 - val_loss: 0.0316 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1054 - acc: 0.9778 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1049 - acc: 0.9704 - val_loss: 0.0314 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1038 - acc: 0.9630 - val_loss: 0.0307 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1078 - acc: 0.9704 - val_loss: 0.0301 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1036 - acc: 0.9704 - val_loss: 0.0307 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1024 - acc: 0.9778 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1006 - acc: 0.9630 - val_loss: 0.0298 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1042 - acc: 0.9778 - val_loss: 0.0278 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1003 - acc: 0.9704 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1016 - acc: 0.9778 - val_loss: 0.0271 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1000 - acc: 0.9852 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9630 - val_loss: 0.0267 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0979 - acc: 0.9704 - val_loss: 0.0269 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0980 - acc: 0.9704 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0994 - acc: 0.9778 - val_loss: 0.0274 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0992 - acc: 0.9630 - val_loss: 0.0260 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9704 - val_loss: 0.0249 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0975 - acc: 0.9704 - val_loss: 0.0252 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1005 - acc: 0.9852 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1017 - acc: 0.9778 - val_loss: 0.0250 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0962 - acc: 0.9852 - val_loss: 0.0233 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0967 - acc: 0.9704 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0955 - acc: 0.9704 - val_loss: 0.0229 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0986 - acc: 0.9704 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0945 - acc: 0.9704 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0922 - acc: 0.9630 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0939 - acc: 0.9704 - val_loss: 0.0214 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0927 - acc: 0.9778 - val_loss: 0.0221 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0941 - acc: 0.9704 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0936 - acc: 0.9704 - val_loss: 0.0210 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0902 - acc: 0.9704 - val_loss: 0.0218 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0923 - acc: 0.9704 - val_loss: 0.0208 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0913 - acc: 0.9778 - val_loss: 0.0201 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0895 - acc: 0.9704 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0912 - acc: 0.9778 - val_loss: 0.0201 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0903 - acc: 0.9704 - val_loss: 0.0196 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0906 - acc: 0.9852 - val_loss: 0.0200 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.0891 - acc: 0.9630 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0890 - acc: 0.9704 - val_loss: 0.0192 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0905 - acc: 0.9852 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0901 - acc: 0.9704 - val_loss: 0.0187 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0871 - acc: 0.9778 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0866 - acc: 0.9778 - val_loss: 0.0186 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0877 - acc: 0.960 - 0s 1ms/step - loss: 0.0862 - acc: 0.9630 - val_loss: 0.0177 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 52ms/step - loss: 3.1052 - acc: 0.3259 - val_loss: 2.4614 - val_acc: 0.4000\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.3428 - acc: 0.3259 - val_loss: 1.8563 - val_acc: 0.4000\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.7399 - acc: 0.3259 - val_loss: 1.4710 - val_acc: 0.4000\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4242 - acc: 0.3407 - val_loss: 1.2630 - val_acc: 0.4667\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2507 - acc: 0.3926 - val_loss: 1.1529 - val_acc: 0.5333\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1453 - acc: 0.4444 - val_loss: 1.0463 - val_acc: 0.5333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0509 - acc: 0.4815 - val_loss: 0.9705 - val_acc: 0.5333\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9845 - acc: 0.4741 - val_loss: 0.8891 - val_acc: 0.6000\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9174 - acc: 0.4889 - val_loss: 0.8316 - val_acc: 0.6000\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8655 - acc: 0.5481 - val_loss: 0.7929 - val_acc: 0.6000\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8302 - acc: 0.5037 - val_loss: 0.7505 - val_acc: 0.5333\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7892 - acc: 0.4889 - val_loss: 0.7082 - val_acc: 0.5333\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7599 - acc: 0.5037 - val_loss: 0.6800 - val_acc: 0.5333\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7328 - acc: 0.4963 - val_loss: 0.6521 - val_acc: 0.5333\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7088 - acc: 0.5333 - val_loss: 0.6341 - val_acc: 0.5333\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6893 - acc: 0.5556 - val_loss: 0.6046 - val_acc: 0.6000\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6624 - acc: 0.5630 - val_loss: 0.5858 - val_acc: 0.6667\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6440 - acc: 0.5704 - val_loss: 0.5677 - val_acc: 0.6667\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6315 - acc: 0.5778 - val_loss: 0.5525 - val_acc: 0.6000\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6208 - acc: 0.6222 - val_loss: 0.5288 - val_acc: 0.6667\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5923 - acc: 0.6963 - val_loss: 0.5165 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5770 - acc: 0.7259 - val_loss: 0.5008 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5634 - acc: 0.8000 - val_loss: 0.4887 - val_acc: 0.8667\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5474 - acc: 0.7926 - val_loss: 0.4716 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5332 - acc: 0.8519 - val_loss: 0.4598 - val_acc: 0.9333\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5215 - acc: 0.8889 - val_loss: 0.4471 - val_acc: 1.0000\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5093 - acc: 0.9111 - val_loss: 0.4391 - val_acc: 1.0000\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4956 - acc: 0.9407 - val_loss: 0.4266 - val_acc: 1.0000\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4852 - acc: 0.9481 - val_loss: 0.4160 - val_acc: 1.0000\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4754 - acc: 0.9556 - val_loss: 0.4065 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4638 - acc: 0.9481 - val_loss: 0.3956 - val_acc: 1.0000\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4553 - acc: 0.9630 - val_loss: 0.3897 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4487 - acc: 0.958 - 0s 1ms/step - loss: 0.4451 - acc: 0.9556 - val_loss: 0.3787 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4361 - acc: 0.9630 - val_loss: 0.3704 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4279 - acc: 0.9630 - val_loss: 0.3672 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4215 - acc: 0.9704 - val_loss: 0.3572 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4105 - acc: 0.9630 - val_loss: 0.3493 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4027 - acc: 0.9630 - val_loss: 0.3411 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3974 - acc: 0.9630 - val_loss: 0.3366 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3895 - acc: 0.9630 - val_loss: 0.3279 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3838 - acc: 0.9704 - val_loss: 0.3236 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3879 - acc: 0.958 - 0s 1ms/step - loss: 0.3748 - acc: 0.9630 - val_loss: 0.3186 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3693 - acc: 0.9704 - val_loss: 0.3103 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3637 - acc: 0.9556 - val_loss: 0.3039 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3549 - acc: 0.9778 - val_loss: 0.2998 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3488 - acc: 0.9630 - val_loss: 0.2922 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3415 - acc: 0.9704 - val_loss: 0.2872 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3368 - acc: 0.9704 - val_loss: 0.2834 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3315 - acc: 0.9630 - val_loss: 0.2781 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3297 - acc: 0.9704 - val_loss: 0.2722 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3204 - acc: 0.9630 - val_loss: 0.2668 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3158 - acc: 0.9778 - val_loss: 0.2638 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3092 - acc: 0.9778 - val_loss: 0.2585 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3046 - acc: 0.9778 - val_loss: 0.2546 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2998 - acc: 0.9778 - val_loss: 0.2497 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2946 - acc: 0.9778 - val_loss: 0.2453 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2911 - acc: 0.9778 - val_loss: 0.2416 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2875 - acc: 0.9704 - val_loss: 0.2372 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2828 - acc: 0.9704 - val_loss: 0.2324 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2787 - acc: 0.9778 - val_loss: 0.2285 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2728 - acc: 0.9778 - val_loss: 0.2260 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2691 - acc: 0.9704 - val_loss: 0.2210 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2643 - acc: 0.9778 - val_loss: 0.2173 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2608 - acc: 0.9778 - val_loss: 0.2141 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2571 - acc: 0.9704 - val_loss: 0.2107 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2555 - acc: 0.9778 - val_loss: 0.2069 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2510 - acc: 0.9852 - val_loss: 0.2037 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2460 - acc: 0.9778 - val_loss: 0.2000 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.9778 - val_loss: 0.1972 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.9704 - val_loss: 0.1946 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2363 - acc: 0.9704 - val_loss: 0.1911 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2340 - acc: 0.9778 - val_loss: 0.1884 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2312 - acc: 0.9778 - val_loss: 0.1847 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2310 - acc: 0.9778 - val_loss: 0.1831 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2240 - acc: 0.9704 - val_loss: 0.1803 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2226 - acc: 0.9704 - val_loss: 0.1771 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2203 - acc: 0.9704 - val_loss: 0.1742 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2156 - acc: 0.9778 - val_loss: 0.1717 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2121 - acc: 0.9778 - val_loss: 0.1692 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2105 - acc: 0.9704 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2086 - acc: 0.9852 - val_loss: 0.1649 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2046 - acc: 0.9704 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2033 - acc: 0.9778 - val_loss: 0.1597 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1987 - acc: 0.9852 - val_loss: 0.1577 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1977 - acc: 0.9778 - val_loss: 0.1553 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1955 - acc: 0.9704 - val_loss: 0.1530 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1938 - acc: 0.9778 - val_loss: 0.1510 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1903 - acc: 0.9852 - val_loss: 0.1490 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1884 - acc: 0.9704 - val_loss: 0.1463 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1860 - acc: 0.9704 - val_loss: 0.1446 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1842 - acc: 0.9852 - val_loss: 0.1427 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1834 - acc: 0.9778 - val_loss: 0.1406 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1807 - acc: 0.9778 - val_loss: 0.1390 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1785 - acc: 0.9852 - val_loss: 0.1372 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1776 - acc: 0.9852 - val_loss: 0.1353 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1747 - acc: 0.9778 - val_loss: 0.1334 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1750 - acc: 0.9778 - val_loss: 0.1316 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1711 - acc: 0.9778 - val_loss: 0.1300 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1690 - acc: 0.9852 - val_loss: 0.1278 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1684 - acc: 0.9852 - val_loss: 0.1268 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1652 - acc: 0.9778 - val_loss: 0.1248 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1660 - acc: 0.9778 - val_loss: 0.1234 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1621 - acc: 0.9852 - val_loss: 0.1215 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1614 - acc: 0.9778 - val_loss: 0.1202 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1632 - acc: 0.9704 - val_loss: 0.1186 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1587 - acc: 0.9778 - val_loss: 0.1174 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1560 - acc: 0.9778 - val_loss: 0.1162 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1552 - acc: 0.9778 - val_loss: 0.1144 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1533 - acc: 0.9852 - val_loss: 0.1129 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1527 - acc: 0.9852 - val_loss: 0.1121 - val_acc: 1.0000\n",
      "Epoch 111/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1526 - acc: 0.9778 - val_loss: 0.1107 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1484 - acc: 0.9778 - val_loss: 0.1093 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1488 - acc: 0.9778 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1486 - acc: 0.9778 - val_loss: 0.1068 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1449 - acc: 0.9778 - val_loss: 0.1053 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1469 - acc: 0.9852 - val_loss: 0.1038 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1470 - acc: 0.9778 - val_loss: 0.1026 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1423 - acc: 0.9778 - val_loss: 0.1014 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1415 - acc: 0.9778 - val_loss: 0.1004 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1404 - acc: 0.9852 - val_loss: 0.0996 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1392 - acc: 0.9852 - val_loss: 0.0979 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1389 - acc: 0.9778 - val_loss: 0.0970 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1386 - acc: 0.9778 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1364 - acc: 0.9778 - val_loss: 0.0951 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1377 - acc: 0.9778 - val_loss: 0.0941 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1343 - acc: 0.9852 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1321 - acc: 0.9778 - val_loss: 0.0916 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1368 - acc: 0.9778 - val_loss: 0.0910 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1348 - acc: 0.9852 - val_loss: 0.0904 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1297 - acc: 0.9778 - val_loss: 0.0897 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1297 - acc: 0.9852 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1299 - acc: 0.9778 - val_loss: 0.0872 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1272 - acc: 0.9778 - val_loss: 0.0860 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1287 - acc: 0.9778 - val_loss: 0.0852 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1260 - acc: 0.9852 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1269 - acc: 0.9778 - val_loss: 0.0835 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1244 - acc: 0.9778 - val_loss: 0.0825 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1236 - acc: 0.9778 - val_loss: 0.0816 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1234 - acc: 0.9852 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1211 - acc: 0.9778 - val_loss: 0.0813 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1211 - acc: 0.9778 - val_loss: 0.0792 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1214 - acc: 0.9778 - val_loss: 0.0785 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1252 - acc: 0.9704 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1201 - acc: 0.9778 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1187 - acc: 0.9778 - val_loss: 0.0766 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1167 - acc: 0.9778 - val_loss: 0.0755 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1179 - acc: 0.9778 - val_loss: 0.0748 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1153 - acc: 0.9778 - val_loss: 0.0741 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1160 - acc: 0.9704 - val_loss: 0.0742 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1134 - acc: 0.9778 - val_loss: 0.0726 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1164 - acc: 0.9778 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1143 - acc: 0.9778 - val_loss: 0.0716 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1163 - acc: 0.9778 - val_loss: 0.0711 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1126 - acc: 0.9778 - val_loss: 0.0703 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1114 - acc: 0.9778 - val_loss: 0.0693 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1116 - acc: 0.9778 - val_loss: 0.0689 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1106 - acc: 0.9852 - val_loss: 0.0683 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1103 - acc: 0.9778 - val_loss: 0.0674 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1084 - acc: 0.9778 - val_loss: 0.0674 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1095 - acc: 0.9778 - val_loss: 0.0664 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1082 - acc: 0.9778 - val_loss: 0.0655 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1095 - acc: 0.9778 - val_loss: 0.0651 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1078 - acc: 0.9778 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1067 - acc: 0.9852 - val_loss: 0.0639 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1059 - acc: 0.9778 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1069 - acc: 0.9778 - val_loss: 0.0640 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1055 - acc: 0.9778 - val_loss: 0.0624 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1076 - acc: 0.9778 - val_loss: 0.0622 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1076 - acc: 0.9704 - val_loss: 0.0612 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1037 - acc: 0.9778 - val_loss: 0.0611 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1030 - acc: 0.9778 - val_loss: 0.0601 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1034 - acc: 0.9852 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9852 - val_loss: 0.0595 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1026 - acc: 0.9778 - val_loss: 0.0586 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1012 - acc: 0.9778 - val_loss: 0.0585 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9778 - val_loss: 0.0578 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1002 - acc: 0.9852 - val_loss: 0.0572 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1034 - acc: 0.9704 - val_loss: 0.0567 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.9852 - val_loss: 0.0563 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9778 - val_loss: 0.0568 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0984 - acc: 0.9778 - val_loss: 0.0555 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1009 - acc: 0.9778 - val_loss: 0.0551 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1034 - acc: 0.9704 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0971 - acc: 0.9778 - val_loss: 0.0546 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0995 - acc: 0.9778 - val_loss: 0.0536 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0977 - acc: 0.9778 - val_loss: 0.0538 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0961 - acc: 0.9778 - val_loss: 0.0530 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0965 - acc: 0.9778 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0971 - acc: 0.9778 - val_loss: 0.0519 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0992 - acc: 0.9778 - val_loss: 0.0527 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1036 - acc: 0.9630 - val_loss: 0.0514 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0958 - acc: 0.9778 - val_loss: 0.0528 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0952 - acc: 0.9704 - val_loss: 0.0503 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0968 - acc: 0.9778 - val_loss: 0.0499 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0940 - acc: 0.9778 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.0502 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0977 - acc: 0.9778 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0933 - acc: 0.9852 - val_loss: 0.0498 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0921 - acc: 0.9778 - val_loss: 0.0481 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0943 - acc: 0.9704 - val_loss: 0.0485 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 49ms/step - loss: 4.3847 - acc: 0.3333 - val_loss: 4.1172 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.2919 - acc: 0.3333 - val_loss: 3.0267 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.3823 - acc: 0.3333 - val_loss: 2.1296 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.6855 - acc: 0.3333 - val_loss: 1.5663 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2897 - acc: 0.3630 - val_loss: 1.2085 - val_acc: 0.4000\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0495 - acc: 0.5259 - val_loss: 1.0089 - val_acc: 0.5333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9160 - acc: 0.6296 - val_loss: 0.8755 - val_acc: 0.6000\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8472 - acc: 0.7111 - val_loss: 0.7889 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8048 - acc: 0.8074 - val_loss: 0.7482 - val_acc: 0.8000\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7800 - acc: 0.8296 - val_loss: 0.7236 - val_acc: 0.8000\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7602 - acc: 0.8074 - val_loss: 0.6983 - val_acc: 0.8000\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7420 - acc: 0.8148 - val_loss: 0.6797 - val_acc: 0.8000\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7259 - acc: 0.8222 - val_loss: 0.6638 - val_acc: 0.8000\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7125 - acc: 0.8000 - val_loss: 0.6466 - val_acc: 0.8000\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6970 - acc: 0.8148 - val_loss: 0.6332 - val_acc: 0.8000\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6826 - acc: 0.8296 - val_loss: 0.6218 - val_acc: 0.8667\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6693 - acc: 0.8296 - val_loss: 0.6079 - val_acc: 0.8667\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6555 - acc: 0.8370 - val_loss: 0.5920 - val_acc: 0.8667\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6422 - acc: 0.8370 - val_loss: 0.5789 - val_acc: 0.8667\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6295 - acc: 0.8296 - val_loss: 0.5668 - val_acc: 0.8667\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6184 - acc: 0.8593 - val_loss: 0.5559 - val_acc: 0.8667\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6079 - acc: 0.8222 - val_loss: 0.5380 - val_acc: 0.8667\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5940 - acc: 0.8519 - val_loss: 0.5340 - val_acc: 0.8667\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5837 - acc: 0.8889 - val_loss: 0.5240 - val_acc: 0.8667\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5709 - acc: 0.8741 - val_loss: 0.5121 - val_acc: 0.8667\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5602 - acc: 0.8667 - val_loss: 0.5004 - val_acc: 0.8667\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5502 - acc: 0.8741 - val_loss: 0.4887 - val_acc: 0.8667\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5410 - acc: 0.8519 - val_loss: 0.4800 - val_acc: 0.8667\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5315 - acc: 0.8741 - val_loss: 0.4702 - val_acc: 0.8667\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5227 - acc: 0.8889 - val_loss: 0.4658 - val_acc: 1.0000\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5138 - acc: 0.8815 - val_loss: 0.4547 - val_acc: 0.8667\n",
      "Epoch 32/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5051 - acc: 0.9037 - val_loss: 0.4502 - val_acc: 1.0000\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4971 - acc: 0.8815 - val_loss: 0.4401 - val_acc: 1.0000\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4884 - acc: 0.8963 - val_loss: 0.4322 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4813 - acc: 0.8889 - val_loss: 0.4252 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4731 - acc: 0.9185 - val_loss: 0.4197 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4672 - acc: 0.9037 - val_loss: 0.4101 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4597 - acc: 0.9185 - val_loss: 0.4074 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4522 - acc: 0.9185 - val_loss: 0.3986 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4466 - acc: 0.9111 - val_loss: 0.3893 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4379 - acc: 0.9407 - val_loss: 0.3862 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4313 - acc: 0.9333 - val_loss: 0.3793 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4252 - acc: 0.9333 - val_loss: 0.3728 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4183 - acc: 0.9481 - val_loss: 0.3659 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4118 - acc: 0.9481 - val_loss: 0.3591 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4063 - acc: 0.9481 - val_loss: 0.3556 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4019 - acc: 0.9259 - val_loss: 0.3459 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3952 - acc: 0.9407 - val_loss: 0.3440 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3893 - acc: 0.9407 - val_loss: 0.3353 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3829 - acc: 0.9556 - val_loss: 0.3306 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3765 - acc: 0.9481 - val_loss: 0.3266 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3720 - acc: 0.9556 - val_loss: 0.3223 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3658 - acc: 0.9556 - val_loss: 0.3152 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3603 - acc: 0.9630 - val_loss: 0.3075 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3554 - acc: 0.9556 - val_loss: 0.3029 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3500 - acc: 0.9630 - val_loss: 0.2949 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3455 - acc: 0.9556 - val_loss: 0.2955 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3404 - acc: 0.9630 - val_loss: 0.2879 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3338 - acc: 0.9556 - val_loss: 0.2813 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3293 - acc: 0.9630 - val_loss: 0.2744 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3236 - acc: 0.9556 - val_loss: 0.2734 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3204 - acc: 0.9556 - val_loss: 0.2665 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3145 - acc: 0.9556 - val_loss: 0.2645 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3120 - acc: 0.9481 - val_loss: 0.2570 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3073 - acc: 0.9630 - val_loss: 0.2565 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3013 - acc: 0.9556 - val_loss: 0.2452 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2998 - acc: 0.9630 - val_loss: 0.2473 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2915 - acc: 0.9630 - val_loss: 0.2347 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2867 - acc: 0.9630 - val_loss: 0.2358 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2829 - acc: 0.9630 - val_loss: 0.2293 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2774 - acc: 0.9630 - val_loss: 0.2243 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2745 - acc: 0.9556 - val_loss: 0.2236 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 4ms/step - loss: 0.2707 - acc: 0.9630 - val_loss: 0.2176 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2676 - acc: 0.9630 - val_loss: 0.2166 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2616 - acc: 0.9630 - val_loss: 0.2092 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2593 - acc: 0.9630 - val_loss: 0.2053 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2562 - acc: 0.9556 - val_loss: 0.2014 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2508 - acc: 0.9630 - val_loss: 0.1971 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2484 - acc: 0.9630 - val_loss: 0.1963 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2437 - acc: 0.9630 - val_loss: 0.1893 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2392 - acc: 0.9630 - val_loss: 0.1873 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2357 - acc: 0.9630 - val_loss: 0.1889 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2331 - acc: 0.9630 - val_loss: 0.1845 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2285 - acc: 0.9630 - val_loss: 0.1775 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2267 - acc: 0.9630 - val_loss: 0.1737 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2233 - acc: 0.9630 - val_loss: 0.1753 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2196 - acc: 0.9630 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2173 - acc: 0.9630 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2145 - acc: 0.9630 - val_loss: 0.1647 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2130 - acc: 0.9704 - val_loss: 0.1622 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2087 - acc: 0.9630 - val_loss: 0.1579 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2074 - acc: 0.9630 - val_loss: 0.1586 - val_acc: 1.0000\n",
      "Epoch 93/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2096 - acc: 0.9704 - val_loss: 0.1519 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2023 - acc: 0.9630 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1973 - acc: 0.9630 - val_loss: 0.1456 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1968 - acc: 0.9630 - val_loss: 0.1486 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1972 - acc: 0.9556 - val_loss: 0.1390 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1915 - acc: 0.9630 - val_loss: 0.1485 - val_acc: 0.9333\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1883 - acc: 0.9704 - val_loss: 0.1419 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1859 - acc: 0.9630 - val_loss: 0.1362 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1836 - acc: 0.9704 - val_loss: 0.1389 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1811 - acc: 0.9630 - val_loss: 0.1338 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1798 - acc: 0.9704 - val_loss: 0.1289 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1784 - acc: 0.9630 - val_loss: 0.1280 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1757 - acc: 0.9704 - val_loss: 0.1308 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1732 - acc: 0.9704 - val_loss: 0.1250 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1724 - acc: 0.9630 - val_loss: 0.1280 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1692 - acc: 0.9704 - val_loss: 0.1202 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1671 - acc: 0.9704 - val_loss: 0.1224 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1664 - acc: 0.9704 - val_loss: 0.1210 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1645 - acc: 0.966 - 0s 2ms/step - loss: 0.1640 - acc: 0.9704 - val_loss: 0.1189 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1618 - acc: 0.9704 - val_loss: 0.1135 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1598 - acc: 0.9704 - val_loss: 0.1138 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1580 - acc: 0.9704 - val_loss: 0.1141 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1580 - acc: 0.9704 - val_loss: 0.1166 - val_acc: 0.9333\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1544 - acc: 0.9704 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1581 - acc: 0.968 - 0s 1ms/step - loss: 0.1541 - acc: 0.9704 - val_loss: 0.1101 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1515 - acc: 0.9704 - val_loss: 0.1078 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1502 - acc: 0.9704 - val_loss: 0.1051 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1497 - acc: 0.9704 - val_loss: 0.1030 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1484 - acc: 0.9704 - val_loss: 0.1096 - val_acc: 0.9333\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1464 - acc: 0.9704 - val_loss: 0.1068 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1451 - acc: 0.9704 - val_loss: 0.1059 - val_acc: 0.9333\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1432 - acc: 0.9704 - val_loss: 0.0984 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1421 - acc: 0.9704 - val_loss: 0.1024 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1402 - acc: 0.9704 - val_loss: 0.0993 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1424 - acc: 0.9556 - val_loss: 0.0997 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1381 - acc: 0.9704 - val_loss: 0.1033 - val_acc: 0.9333\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1396 - acc: 0.9704 - val_loss: 0.0921 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1356 - acc: 0.9704 - val_loss: 0.1029 - val_acc: 0.9333\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1346 - acc: 0.9704 - val_loss: 0.0924 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1333 - acc: 0.9704 - val_loss: 0.0880 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1336 - acc: 0.9704 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1338 - acc: 0.9704 - val_loss: 0.0909 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1318 - acc: 0.9704 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1287 - acc: 0.9704 - val_loss: 0.0905 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1282 - acc: 0.9704 - val_loss: 0.0873 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1285 - acc: 0.9704 - val_loss: 0.0894 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1261 - acc: 0.9704 - val_loss: 0.0926 - val_acc: 0.9333\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1277 - acc: 0.9704 - val_loss: 0.0872 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1259 - acc: 0.9704 - val_loss: 0.0915 - val_acc: 0.9333\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1244 - acc: 0.9630 - val_loss: 0.0824 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1230 - acc: 0.9704 - val_loss: 0.0887 - val_acc: 0.9333\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1220 - acc: 0.9704 - val_loss: 0.0832 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1227 - acc: 0.9630 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1189 - acc: 0.9704 - val_loss: 0.0897 - val_acc: 0.9333\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1189 - acc: 0.9704 - val_loss: 0.0834 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1193 - acc: 0.9704 - val_loss: 0.0787 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1174 - acc: 0.9704 - val_loss: 0.0857 - val_acc: 0.9333\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1176 - acc: 0.9704 - val_loss: 0.0763 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1177 - acc: 0.9704 - val_loss: 0.0759 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1158 - acc: 0.9704 - val_loss: 0.0820 - val_acc: 1.0000\n",
      "Epoch 153/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1168 - acc: 0.9704 - val_loss: 0.0795 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1145 - acc: 0.9704 - val_loss: 0.0791 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1135 - acc: 0.9704 - val_loss: 0.0740 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1128 - acc: 0.9704 - val_loss: 0.0833 - val_acc: 0.9333\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1112 - acc: 0.9704 - val_loss: 0.0754 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1117 - acc: 0.9630 - val_loss: 0.0742 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1110 - acc: 0.9704 - val_loss: 0.0749 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1101 - acc: 0.9704 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1101 - acc: 0.9704 - val_loss: 0.0770 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1095 - acc: 0.9704 - val_loss: 0.0669 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1097 - acc: 0.9704 - val_loss: 0.0725 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1072 - acc: 0.9704 - val_loss: 0.0673 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1079 - acc: 0.9704 - val_loss: 0.0781 - val_acc: 0.9333\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1055 - acc: 0.9704 - val_loss: 0.0653 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1066 - acc: 0.9704 - val_loss: 0.0721 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1065 - acc: 0.9704 - val_loss: 0.0612 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1038 - acc: 0.9704 - val_loss: 0.0702 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1053 - acc: 0.9704 - val_loss: 0.0733 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1043 - acc: 0.9704 - val_loss: 0.0660 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1024 - acc: 0.9704 - val_loss: 0.0745 - val_acc: 0.9333\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1028 - acc: 0.9704 - val_loss: 0.0714 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1017 - acc: 0.9704 - val_loss: 0.0679 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1013 - acc: 0.9704 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1041 - acc: 0.9630 - val_loss: 0.0776 - val_acc: 0.9333\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1029 - acc: 0.9704 - val_loss: 0.0639 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1010 - acc: 0.9704 - val_loss: 0.0724 - val_acc: 0.9333\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0987 - acc: 0.9704 - val_loss: 0.0638 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1000 - acc: 0.9704 - val_loss: 0.0611 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0979 - acc: 0.9704 - val_loss: 0.0712 - val_acc: 0.9333\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0981 - acc: 0.9704 - val_loss: 0.0699 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1009 - acc: 0.9630 - val_loss: 0.0543 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0999 - acc: 0.9630 - val_loss: 0.0624 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0986 - acc: 0.9630 - val_loss: 0.0623 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0973 - acc: 0.9704 - val_loss: 0.0692 - val_acc: 0.9333\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0958 - acc: 0.9704 - val_loss: 0.0617 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0960 - acc: 0.9704 - val_loss: 0.0613 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0950 - acc: 0.9704 - val_loss: 0.0666 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0993 - acc: 0.9630 - val_loss: 0.0598 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0940 - acc: 0.9704 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0950 - acc: 0.9704 - val_loss: 0.0564 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0962 - acc: 0.9630 - val_loss: 0.0608 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0936 - acc: 0.9704 - val_loss: 0.0656 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0939 - acc: 0.9704 - val_loss: 0.0672 - val_acc: 0.9333\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0952 - acc: 0.9630 - val_loss: 0.0531 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0971 - acc: 0.9704 - val_loss: 0.0656 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0974 - acc: 0.9556 - val_loss: 0.0597 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0913 - acc: 0.9704 - val_loss: 0.0663 - val_acc: 0.9333\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0912 - acc: 0.9704 - val_loss: 0.0567 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 51ms/step - loss: 3.6256 - acc: 0.3333 - val_loss: 2.3725 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.9757 - acc: 0.4519 - val_loss: 2.0221 - val_acc: 0.7333\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.5735 - acc: 0.6444 - val_loss: 1.7665 - val_acc: 0.7333\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.2357 - acc: 0.6519 - val_loss: 1.5317 - val_acc: 0.7333\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.9371 - acc: 0.6593 - val_loss: 1.3154 - val_acc: 0.7333\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.6549 - acc: 0.6593 - val_loss: 1.1450 - val_acc: 0.7333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4256 - acc: 0.6593 - val_loss: 1.0064 - val_acc: 0.7333\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2449 - acc: 0.6593 - val_loss: 0.8989 - val_acc: 0.7333\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1051 - acc: 0.6593 - val_loss: 0.8278 - val_acc: 0.7333\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0097 - acc: 0.6593 - val_loss: 0.7829 - val_acc: 0.7333\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9403 - acc: 0.6593 - val_loss: 0.7532 - val_acc: 0.7333\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9007 - acc: 0.6593 - val_loss: 0.7334 - val_acc: 0.7333\n",
      "Epoch 13/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8685 - acc: 0.6593 - val_loss: 0.7190 - val_acc: 0.8000\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8441 - acc: 0.6593 - val_loss: 0.6967 - val_acc: 0.8000\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8212 - acc: 0.6667 - val_loss: 0.6802 - val_acc: 0.9333\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7988 - acc: 0.6741 - val_loss: 0.6616 - val_acc: 0.9333\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7769 - acc: 0.6963 - val_loss: 0.6481 - val_acc: 0.9333\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7560 - acc: 0.7037 - val_loss: 0.6339 - val_acc: 0.9333\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7396 - acc: 0.6963 - val_loss: 0.6190 - val_acc: 0.9333\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7233 - acc: 0.7185 - val_loss: 0.6058 - val_acc: 0.9333\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7073 - acc: 0.7333 - val_loss: 0.5880 - val_acc: 0.9333\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6919 - acc: 0.7259 - val_loss: 0.5746 - val_acc: 0.9333\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6774 - acc: 0.7259 - val_loss: 0.5593 - val_acc: 0.9333\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6628 - acc: 0.7333 - val_loss: 0.5443 - val_acc: 0.9333\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6502 - acc: 0.7407 - val_loss: 0.5322 - val_acc: 0.9333\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6365 - acc: 0.7556 - val_loss: 0.5191 - val_acc: 0.9333\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6243 - acc: 0.7704 - val_loss: 0.5084 - val_acc: 0.9333\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6112 - acc: 0.7630 - val_loss: 0.4933 - val_acc: 0.9333\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5988 - acc: 0.7704 - val_loss: 0.4826 - val_acc: 0.9333\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5870 - acc: 0.8148 - val_loss: 0.4711 - val_acc: 0.9333\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5755 - acc: 0.8000 - val_loss: 0.4604 - val_acc: 0.9333\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5642 - acc: 0.8370 - val_loss: 0.4505 - val_acc: 0.9333\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5555 - acc: 0.7926 - val_loss: 0.4381 - val_acc: 0.9333\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5437 - acc: 0.8519 - val_loss: 0.4316 - val_acc: 1.0000\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5346 - acc: 0.8741 - val_loss: 0.4208 - val_acc: 1.0000\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5233 - acc: 0.8815 - val_loss: 0.4116 - val_acc: 1.0000\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5159 - acc: 0.9037 - val_loss: 0.4047 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5053 - acc: 0.8963 - val_loss: 0.3932 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4980 - acc: 0.8667 - val_loss: 0.3838 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4880 - acc: 0.9111 - val_loss: 0.3790 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4809 - acc: 0.8963 - val_loss: 0.3681 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4713 - acc: 0.9111 - val_loss: 0.3622 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4631 - acc: 0.9185 - val_loss: 0.3569 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4553 - acc: 0.9259 - val_loss: 0.3502 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4493 - acc: 0.9111 - val_loss: 0.3401 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4410 - acc: 0.9259 - val_loss: 0.3344 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4333 - acc: 0.9259 - val_loss: 0.3287 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4267 - acc: 0.9481 - val_loss: 0.3237 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4177 - acc: 0.936 - 0s 1ms/step - loss: 0.4219 - acc: 0.9259 - val_loss: 0.3127 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4174 - acc: 0.9333 - val_loss: 0.3132 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4070 - acc: 0.9407 - val_loss: 0.3022 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4009 - acc: 0.9481 - val_loss: 0.2985 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3944 - acc: 0.9407 - val_loss: 0.2899 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3887 - acc: 0.9481 - val_loss: 0.2874 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3845 - acc: 0.9481 - val_loss: 0.2766 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3769 - acc: 0.9704 - val_loss: 0.2760 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3713 - acc: 0.9704 - val_loss: 0.2669 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3656 - acc: 0.9630 - val_loss: 0.2675 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3600 - acc: 0.9704 - val_loss: 0.2600 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3553 - acc: 0.9556 - val_loss: 0.2516 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3495 - acc: 0.9630 - val_loss: 0.2492 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3439 - acc: 0.9704 - val_loss: 0.2466 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3408 - acc: 0.9704 - val_loss: 0.2396 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3365 - acc: 0.9556 - val_loss: 0.2315 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3278 - acc: 0.9704 - val_loss: 0.2313 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3255 - acc: 0.9778 - val_loss: 0.2257 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3189 - acc: 0.9704 - val_loss: 0.2190 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3147 - acc: 0.9704 - val_loss: 0.2142 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3144 - acc: 0.9630 - val_loss: 0.2106 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3067 - acc: 0.9704 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3032 - acc: 0.9704 - val_loss: 0.2018 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2978 - acc: 0.9778 - val_loss: 0.1989 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2928 - acc: 0.9704 - val_loss: 0.1917 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2884 - acc: 0.9704 - val_loss: 0.1895 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2857 - acc: 0.9778 - val_loss: 0.1888 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2816 - acc: 0.9704 - val_loss: 0.1809 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2767 - acc: 0.9704 - val_loss: 0.1764 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2713 - acc: 0.9778 - val_loss: 0.1778 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2706 - acc: 0.9778 - val_loss: 0.1730 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2673 - acc: 0.9704 - val_loss: 0.1676 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2610 - acc: 0.9778 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2576 - acc: 0.9778 - val_loss: 0.1618 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2546 - acc: 0.9704 - val_loss: 0.1566 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2502 - acc: 0.9778 - val_loss: 0.1543 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2488 - acc: 0.9778 - val_loss: 0.1520 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2480 - acc: 0.9630 - val_loss: 0.1437 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2394 - acc: 0.9778 - val_loss: 0.1478 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2399 - acc: 0.9778 - val_loss: 0.1463 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2348 - acc: 0.9778 - val_loss: 0.1356 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2305 - acc: 0.9778 - val_loss: 0.1381 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2279 - acc: 0.9778 - val_loss: 0.1316 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2250 - acc: 0.9778 - val_loss: 0.1293 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2215 - acc: 0.9778 - val_loss: 0.1264 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2188 - acc: 0.9778 - val_loss: 0.1236 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2153 - acc: 0.9778 - val_loss: 0.1234 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2148 - acc: 0.9852 - val_loss: 0.1214 - val_acc: 1.0000\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2119 - acc: 0.9778 - val_loss: 0.1161 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2078 - acc: 0.9778 - val_loss: 0.1135 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2076 - acc: 0.9704 - val_loss: 0.1106 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2072 - acc: 0.9704 - val_loss: 0.1124 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2046 - acc: 0.9778 - val_loss: 0.1061 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1982 - acc: 0.9778 - val_loss: 0.1047 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2088 - acc: 0.966 - 0s 1ms/step - loss: 0.1951 - acc: 0.9778 - val_loss: 0.1037 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1970 - acc: 0.9778 - val_loss: 0.0995 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1929 - acc: 0.9778 - val_loss: 0.0993 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1899 - acc: 0.9778 - val_loss: 0.0982 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1869 - acc: 0.9778 - val_loss: 0.0933 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1843 - acc: 0.9778 - val_loss: 0.0933 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1828 - acc: 0.9852 - val_loss: 0.0924 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1803 - acc: 0.9778 - val_loss: 0.0898 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1794 - acc: 0.9778 - val_loss: 0.0903 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1755 - acc: 0.9778 - val_loss: 0.0848 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1741 - acc: 0.9778 - val_loss: 0.0843 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1725 - acc: 0.9778 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1710 - acc: 0.9778 - val_loss: 0.0815 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1686 - acc: 0.9778 - val_loss: 0.0798 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1696 - acc: 0.9778 - val_loss: 0.0770 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1688 - acc: 0.9704 - val_loss: 0.0774 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1644 - acc: 0.9778 - val_loss: 0.0747 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1617 - acc: 0.9778 - val_loss: 0.0743 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1602 - acc: 0.9704 - val_loss: 0.0726 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1585 - acc: 0.9778 - val_loss: 0.0700 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1562 - acc: 0.9778 - val_loss: 0.0706 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1568 - acc: 0.9778 - val_loss: 0.0671 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1538 - acc: 0.9778 - val_loss: 0.0674 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1525 - acc: 0.9778 - val_loss: 0.0659 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1511 - acc: 0.9778 - val_loss: 0.0641 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1492 - acc: 0.9778 - val_loss: 0.0654 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1492 - acc: 0.9778 - val_loss: 0.0629 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1463 - acc: 0.9778 - val_loss: 0.0606 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1451 - acc: 0.9778 - val_loss: 0.0608 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1443 - acc: 0.9852 - val_loss: 0.0602 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1438 - acc: 0.9778 - val_loss: 0.0588 - val_acc: 1.0000\n",
      "Epoch 134/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1427 - acc: 0.9704 - val_loss: 0.0572 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1398 - acc: 0.9778 - val_loss: 0.0559 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1388 - acc: 0.9778 - val_loss: 0.0545 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1386 - acc: 0.9778 - val_loss: 0.0543 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1372 - acc: 0.9778 - val_loss: 0.0563 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1369 - acc: 0.9852 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1354 - acc: 0.9778 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1332 - acc: 0.9778 - val_loss: 0.0493 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1351 - acc: 0.9778 - val_loss: 0.0518 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1333 - acc: 0.9778 - val_loss: 0.0471 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1343 - acc: 0.9778 - val_loss: 0.0477 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1302 - acc: 0.9704 - val_loss: 0.0475 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1289 - acc: 0.9778 - val_loss: 0.0453 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1303 - acc: 0.9704 - val_loss: 0.0452 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1270 - acc: 0.9778 - val_loss: 0.0432 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1267 - acc: 0.9704 - val_loss: 0.0442 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1241 - acc: 0.9778 - val_loss: 0.0435 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1242 - acc: 0.9778 - val_loss: 0.0431 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1261 - acc: 0.9852 - val_loss: 0.0444 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1216 - acc: 0.9778 - val_loss: 0.0403 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1205 - acc: 0.9778 - val_loss: 0.0414 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1208 - acc: 0.9778 - val_loss: 0.0403 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1194 - acc: 0.9704 - val_loss: 0.0423 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1217 - acc: 0.9704 - val_loss: 0.0402 - val_acc: 1.0000\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1172 - acc: 0.9778 - val_loss: 0.0393 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1175 - acc: 0.9704 - val_loss: 0.0377 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1167 - acc: 0.9778 - val_loss: 0.0372 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1146 - acc: 0.9704 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1147 - acc: 0.9704 - val_loss: 0.0374 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1133 - acc: 0.9778 - val_loss: 0.0359 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1126 - acc: 0.9778 - val_loss: 0.0351 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1123 - acc: 0.9778 - val_loss: 0.0349 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1162 - acc: 0.9778 - val_loss: 0.0340 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1119 - acc: 0.9778 - val_loss: 0.0338 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1166 - acc: 0.9778 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1109 - acc: 0.9778 - val_loss: 0.0346 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1079 - acc: 0.9778 - val_loss: 0.0320 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1090 - acc: 0.9778 - val_loss: 0.0317 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1085 - acc: 0.9778 - val_loss: 0.0312 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1079 - acc: 0.9704 - val_loss: 0.0322 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1072 - acc: 0.9778 - val_loss: 0.0315 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1058 - acc: 0.9704 - val_loss: 0.0299 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1058 - acc: 0.9778 - val_loss: 0.0303 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1069 - acc: 0.9778 - val_loss: 0.0286 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1057 - acc: 0.9704 - val_loss: 0.0290 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1051 - acc: 0.9704 - val_loss: 0.0276 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1035 - acc: 0.9704 - val_loss: 0.0287 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1022 - acc: 0.9704 - val_loss: 0.0281 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1053 - acc: 0.9778 - val_loss: 0.0279 - val_acc: 1.0000\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1034 - acc: 0.9778 - val_loss: 0.0273 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1008 - acc: 0.9778 - val_loss: 0.0255 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1013 - acc: 0.9704 - val_loss: 0.0256 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1020 - acc: 0.9778 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0995 - acc: 0.9778 - val_loss: 0.0261 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1002 - acc: 0.9778 - val_loss: 0.0253 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0977 - acc: 0.9778 - val_loss: 0.0240 - val_acc: 1.0000\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0973 - acc: 0.9778 - val_loss: 0.0244 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1006 - acc: 0.9704 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0969 - acc: 0.9778 - val_loss: 0.0228 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0969 - acc: 0.9852 - val_loss: 0.0239 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0973 - acc: 0.9778 - val_loss: 0.0223 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0957 - acc: 0.9704 - val_loss: 0.0241 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0952 - acc: 0.9778 - val_loss: 0.0230 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0942 - acc: 0.9704 - val_loss: 0.0219 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0953 - acc: 0.9778 - val_loss: 0.0223 - val_acc: 1.0000\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0945 - acc: 0.9778 - val_loss: 0.0207 - val_acc: 1.0000\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0933 - acc: 0.9778 - val_loss: 0.0224 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 8s 56ms/step - loss: 1.8956 - acc: 0.3333 - val_loss: 1.6973 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.6306 - acc: 0.3333 - val_loss: 1.4831 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4254 - acc: 0.3333 - val_loss: 1.3199 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2724 - acc: 0.3333 - val_loss: 1.1999 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1640 - acc: 0.3333 - val_loss: 1.1053 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0794 - acc: 0.3407 - val_loss: 1.0409 - val_acc: 0.3333\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0213 - acc: 0.4370 - val_loss: 0.9872 - val_acc: 0.6000\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9698 - acc: 0.6444 - val_loss: 0.9486 - val_acc: 0.6667\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9319 - acc: 0.6667 - val_loss: 0.9133 - val_acc: 0.6667\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8978 - acc: 0.6667 - val_loss: 0.8845 - val_acc: 0.6667\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8683 - acc: 0.6667 - val_loss: 0.8585 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8437 - acc: 0.6667 - val_loss: 0.8329 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8202 - acc: 0.6667 - val_loss: 0.8095 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7984 - acc: 0.6667 - val_loss: 0.7895 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7786 - acc: 0.6667 - val_loss: 0.7719 - val_acc: 0.6667\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7602 - acc: 0.6593 - val_loss: 0.7542 - val_acc: 0.6667\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7432 - acc: 0.6593 - val_loss: 0.7367 - val_acc: 0.6667\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7265 - acc: 0.6593 - val_loss: 0.7205 - val_acc: 0.6667\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7100 - acc: 0.6593 - val_loss: 0.7056 - val_acc: 0.6667\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6951 - acc: 0.6593 - val_loss: 0.6915 - val_acc: 0.6667\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6808 - acc: 0.6593 - val_loss: 0.6774 - val_acc: 0.6667\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6660 - acc: 0.6519 - val_loss: 0.6636 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6524 - acc: 0.6593 - val_loss: 0.6512 - val_acc: 0.7333\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6397 - acc: 0.7259 - val_loss: 0.6393 - val_acc: 0.6000\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6265 - acc: 0.7704 - val_loss: 0.6278 - val_acc: 0.6667\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6137 - acc: 0.8296 - val_loss: 0.6169 - val_acc: 0.6667\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6022 - acc: 0.8222 - val_loss: 0.6071 - val_acc: 0.6667\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5906 - acc: 0.8593 - val_loss: 0.5970 - val_acc: 0.6667\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5794 - acc: 0.9111 - val_loss: 0.5879 - val_acc: 0.6667\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5696 - acc: 0.9111 - val_loss: 0.5805 - val_acc: 0.6667\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5584 - acc: 0.8963 - val_loss: 0.5708 - val_acc: 0.7333\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5490 - acc: 0.9037 - val_loss: 0.5645 - val_acc: 0.6667\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5394 - acc: 0.9037 - val_loss: 0.5561 - val_acc: 0.7333\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5295 - acc: 0.9037 - val_loss: 0.5508 - val_acc: 0.7333\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5198 - acc: 0.9111 - val_loss: 0.5443 - val_acc: 0.7333\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5119 - acc: 0.9333 - val_loss: 0.5380 - val_acc: 0.7333\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5024 - acc: 0.9111 - val_loss: 0.5323 - val_acc: 0.7333\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4945 - acc: 0.9111 - val_loss: 0.5267 - val_acc: 0.7333\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4863 - acc: 0.9185 - val_loss: 0.5214 - val_acc: 0.8000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4780 - acc: 0.9185 - val_loss: 0.5162 - val_acc: 0.8000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4712 - acc: 0.9111 - val_loss: 0.5114 - val_acc: 0.8000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4628 - acc: 0.9185 - val_loss: 0.5064 - val_acc: 0.7333\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4583 - acc: 0.9185 - val_loss: 0.5026 - val_acc: 0.8000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4494 - acc: 0.9111 - val_loss: 0.4968 - val_acc: 0.7333\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4412 - acc: 0.9333 - val_loss: 0.4928 - val_acc: 0.7333\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4335 - acc: 0.9259 - val_loss: 0.4877 - val_acc: 0.7333\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4267 - acc: 0.9333 - val_loss: 0.4831 - val_acc: 0.7333\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4245 - acc: 0.928 - 0s 1ms/step - loss: 0.4202 - acc: 0.9333 - val_loss: 0.4785 - val_acc: 0.7333\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4141 - acc: 0.9185 - val_loss: 0.4746 - val_acc: 0.7333\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4079 - acc: 0.9259 - val_loss: 0.4699 - val_acc: 0.8000\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3992 - acc: 0.9333 - val_loss: 0.4668 - val_acc: 0.8000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3934 - acc: 0.9259 - val_loss: 0.4615 - val_acc: 0.8000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3867 - acc: 0.9407 - val_loss: 0.4580 - val_acc: 0.8000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3814 - acc: 0.9481 - val_loss: 0.4541 - val_acc: 0.8000\n",
      "Epoch 55/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3743 - acc: 0.9556 - val_loss: 0.4500 - val_acc: 0.8000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3697 - acc: 0.9481 - val_loss: 0.4478 - val_acc: 0.8000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3643 - acc: 0.9556 - val_loss: 0.4433 - val_acc: 0.8667\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3606 - acc: 0.9556 - val_loss: 0.4372 - val_acc: 0.8000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3510 - acc: 0.9556 - val_loss: 0.4391 - val_acc: 0.8000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3491 - acc: 0.9333 - val_loss: 0.4312 - val_acc: 0.8000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3436 - acc: 0.9556 - val_loss: 0.4297 - val_acc: 0.8667\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3362 - acc: 0.9556 - val_loss: 0.4238 - val_acc: 0.8000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3305 - acc: 0.9630 - val_loss: 0.4199 - val_acc: 0.8000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3270 - acc: 0.9481 - val_loss: 0.4172 - val_acc: 0.8667\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3215 - acc: 0.9704 - val_loss: 0.4144 - val_acc: 0.8667\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3164 - acc: 0.9630 - val_loss: 0.4117 - val_acc: 0.8667\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3114 - acc: 0.9630 - val_loss: 0.4097 - val_acc: 0.8667\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3064 - acc: 0.9630 - val_loss: 0.4022 - val_acc: 0.8000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3030 - acc: 0.9630 - val_loss: 0.4040 - val_acc: 0.8667\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2980 - acc: 0.9630 - val_loss: 0.4002 - val_acc: 0.8667\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2950 - acc: 0.9630 - val_loss: 0.3927 - val_acc: 0.8000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2891 - acc: 0.9704 - val_loss: 0.3923 - val_acc: 0.8667\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2849 - acc: 0.9630 - val_loss: 0.3876 - val_acc: 0.8667\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2796 - acc: 0.9630 - val_loss: 0.3871 - val_acc: 0.8667\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2756 - acc: 0.9704 - val_loss: 0.3846 - val_acc: 0.8667\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2763 - acc: 0.969 - 0s 1ms/step - loss: 0.2739 - acc: 0.9704 - val_loss: 0.3792 - val_acc: 0.8667\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2691 - acc: 0.9630 - val_loss: 0.3739 - val_acc: 0.8000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2684 - acc: 0.9704 - val_loss: 0.3748 - val_acc: 0.8667\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.9704 - val_loss: 0.3702 - val_acc: 0.8667\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2581 - acc: 0.9630 - val_loss: 0.3677 - val_acc: 0.8667\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2558 - acc: 0.9556 - val_loss: 0.3705 - val_acc: 0.8667\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2549 - acc: 0.9630 - val_loss: 0.3608 - val_acc: 0.8667\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2493 - acc: 0.9704 - val_loss: 0.3671 - val_acc: 0.8667\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2437 - acc: 0.9704 - val_loss: 0.3565 - val_acc: 0.8667\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2407 - acc: 0.9630 - val_loss: 0.3604 - val_acc: 0.8667\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2394 - acc: 0.9630 - val_loss: 0.3542 - val_acc: 0.8667\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2355 - acc: 0.9630 - val_loss: 0.3506 - val_acc: 0.8667\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2299 - acc: 0.9704 - val_loss: 0.3518 - val_acc: 0.8667\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2281 - acc: 0.9778 - val_loss: 0.3500 - val_acc: 0.8667\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2265 - acc: 0.9630 - val_loss: 0.3446 - val_acc: 0.8667\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2217 - acc: 0.9704 - val_loss: 0.3435 - val_acc: 0.8667\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2193 - acc: 0.9630 - val_loss: 0.3410 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2173 - acc: 0.9704 - val_loss: 0.3396 - val_acc: 0.8667\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2142 - acc: 0.9704 - val_loss: 0.3366 - val_acc: 0.8667\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2114 - acc: 0.9704 - val_loss: 0.3337 - val_acc: 0.8667\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2092 - acc: 0.9630 - val_loss: 0.3337 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2066 - acc: 0.9630 - val_loss: 0.3312 - val_acc: 0.8667\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2047 - acc: 0.9852 - val_loss: 0.3325 - val_acc: 0.8667\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2021 - acc: 0.9630 - val_loss: 0.3248 - val_acc: 0.8667\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2011 - acc: 0.9704 - val_loss: 0.3320 - val_acc: 0.8667\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1971 - acc: 0.9852 - val_loss: 0.3244 - val_acc: 0.8667\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1947 - acc: 0.9630 - val_loss: 0.3195 - val_acc: 0.8667\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1929 - acc: 0.9704 - val_loss: 0.3155 - val_acc: 0.8667\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1923 - acc: 0.9630 - val_loss: 0.3211 - val_acc: 0.8667\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1887 - acc: 0.9704 - val_loss: 0.3159 - val_acc: 0.8667\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1857 - acc: 0.9778 - val_loss: 0.3183 - val_acc: 0.8667\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1835 - acc: 0.9704 - val_loss: 0.3109 - val_acc: 0.8667\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1818 - acc: 0.9630 - val_loss: 0.3109 - val_acc: 0.8667\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1803 - acc: 0.9630 - val_loss: 0.3097 - val_acc: 0.8667\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1776 - acc: 0.9704 - val_loss: 0.3082 - val_acc: 0.8667\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1758 - acc: 0.9704 - val_loss: 0.3059 - val_acc: 0.8667\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1742 - acc: 0.9704 - val_loss: 0.3031 - val_acc: 0.8667\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1730 - acc: 0.9704 - val_loss: 0.3020 - val_acc: 0.8667\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1705 - acc: 0.9704 - val_loss: 0.3013 - val_acc: 0.8667\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1699 - acc: 0.9630 - val_loss: 0.2979 - val_acc: 0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1684 - acc: 0.9778 - val_loss: 0.2980 - val_acc: 0.9333\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1665 - acc: 0.9704 - val_loss: 0.2988 - val_acc: 0.8667\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1640 - acc: 0.9778 - val_loss: 0.2986 - val_acc: 0.8667\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1628 - acc: 0.9778 - val_loss: 0.2970 - val_acc: 0.8667\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1620 - acc: 0.9630 - val_loss: 0.2911 - val_acc: 0.9333\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1593 - acc: 0.9704 - val_loss: 0.2956 - val_acc: 0.8667\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1578 - acc: 0.9704 - val_loss: 0.2896 - val_acc: 0.9333\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1580 - acc: 0.9778 - val_loss: 0.2921 - val_acc: 0.8667\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1547 - acc: 0.9778 - val_loss: 0.2864 - val_acc: 0.9333\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1538 - acc: 0.9630 - val_loss: 0.2879 - val_acc: 0.9333\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1528 - acc: 0.9778 - val_loss: 0.2888 - val_acc: 0.9333\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1528 - acc: 0.9630 - val_loss: 0.2799 - val_acc: 0.9333\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1488 - acc: 0.9704 - val_loss: 0.2892 - val_acc: 0.8667\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1486 - acc: 0.9704 - val_loss: 0.2831 - val_acc: 0.9333\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1469 - acc: 0.9704 - val_loss: 0.2855 - val_acc: 0.9333\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1456 - acc: 0.9778 - val_loss: 0.2811 - val_acc: 0.9333\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1458 - acc: 0.9704 - val_loss: 0.2778 - val_acc: 0.9333\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1444 - acc: 0.9704 - val_loss: 0.2775 - val_acc: 0.9333\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1429 - acc: 0.9778 - val_loss: 0.2837 - val_acc: 0.9333\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1402 - acc: 0.9778 - val_loss: 0.2726 - val_acc: 0.9333\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1405 - acc: 0.9704 - val_loss: 0.2786 - val_acc: 0.9333\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1402 - acc: 0.9778 - val_loss: 0.2671 - val_acc: 0.9333\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1379 - acc: 0.9704 - val_loss: 0.2680 - val_acc: 0.9333\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1371 - acc: 0.9704 - val_loss: 0.2704 - val_acc: 0.9333\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1374 - acc: 0.9778 - val_loss: 0.2819 - val_acc: 0.9333\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1342 - acc: 0.9704 - val_loss: 0.2637 - val_acc: 0.9333\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1342 - acc: 0.9704 - val_loss: 0.2689 - val_acc: 0.9333\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1332 - acc: 0.9852 - val_loss: 0.2659 - val_acc: 0.9333\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1320 - acc: 0.9704 - val_loss: 0.2639 - val_acc: 0.9333\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1307 - acc: 0.9778 - val_loss: 0.2748 - val_acc: 0.9333\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1311 - acc: 0.9704 - val_loss: 0.2585 - val_acc: 0.9333\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1281 - acc: 0.9704 - val_loss: 0.2648 - val_acc: 0.9333\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1272 - acc: 0.9778 - val_loss: 0.2637 - val_acc: 0.9333\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1265 - acc: 0.9778 - val_loss: 0.2699 - val_acc: 0.9333\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1260 - acc: 0.9778 - val_loss: 0.2685 - val_acc: 0.9333\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1278 - acc: 0.9630 - val_loss: 0.2563 - val_acc: 0.9333\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1235 - acc: 0.9778 - val_loss: 0.2739 - val_acc: 0.9333\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1232 - acc: 0.9852 - val_loss: 0.2640 - val_acc: 0.9333\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1262 - acc: 0.9630 - val_loss: 0.2607 - val_acc: 0.9333\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1229 - acc: 0.9852 - val_loss: 0.2691 - val_acc: 0.9333\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1240 - acc: 0.9630 - val_loss: 0.2516 - val_acc: 0.9333\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1214 - acc: 0.9778 - val_loss: 0.2690 - val_acc: 0.9333\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1184 - acc: 0.9704 - val_loss: 0.2487 - val_acc: 0.9333\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1184 - acc: 0.9778 - val_loss: 0.2552 - val_acc: 0.9333\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1174 - acc: 0.9704 - val_loss: 0.2490 - val_acc: 0.9333\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1164 - acc: 0.9778 - val_loss: 0.2568 - val_acc: 0.9333\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1157 - acc: 0.9704 - val_loss: 0.2525 - val_acc: 0.9333\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1155 - acc: 0.9852 - val_loss: 0.2630 - val_acc: 0.9333\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1156 - acc: 0.9778 - val_loss: 0.2507 - val_acc: 0.9333\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1140 - acc: 0.9778 - val_loss: 0.2590 - val_acc: 0.9333\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1135 - acc: 0.9704 - val_loss: 0.2487 - val_acc: 0.9333\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1136 - acc: 0.9778 - val_loss: 0.2536 - val_acc: 0.9333\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1112 - acc: 0.9778 - val_loss: 0.2473 - val_acc: 0.9333\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1106 - acc: 0.9778 - val_loss: 0.2471 - val_acc: 0.9333\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1109 - acc: 0.9852 - val_loss: 0.2490 - val_acc: 0.9333\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1098 - acc: 0.9630 - val_loss: 0.2407 - val_acc: 0.9333\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1098 - acc: 0.9630 - val_loss: 0.2590 - val_acc: 0.9333\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1088 - acc: 0.9852 - val_loss: 0.2584 - val_acc: 0.9333\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1104 - acc: 0.9704 - val_loss: 0.2409 - val_acc: 0.9333\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1060 - acc: 0.9778 - val_loss: 0.2541 - val_acc: 0.9333\n",
      "Epoch 176/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1066 - acc: 0.9852 - val_loss: 0.2433 - val_acc: 0.9333\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1065 - acc: 0.9778 - val_loss: 0.2430 - val_acc: 0.9333\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1059 - acc: 0.9778 - val_loss: 0.2511 - val_acc: 0.9333\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1068 - acc: 0.9778 - val_loss: 0.2486 - val_acc: 0.9333\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1048 - acc: 0.9778 - val_loss: 0.2432 - val_acc: 0.9333\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1073 - acc: 0.9630 - val_loss: 0.2472 - val_acc: 0.9333\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1027 - acc: 0.9778 - val_loss: 0.2455 - val_acc: 0.9333\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1036 - acc: 0.9778 - val_loss: 0.2476 - val_acc: 0.9333\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1017 - acc: 0.9778 - val_loss: 0.2446 - val_acc: 0.9333\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1012 - acc: 0.9778 - val_loss: 0.2462 - val_acc: 0.9333\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1010 - acc: 0.9778 - val_loss: 0.2432 - val_acc: 0.9333\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1011 - acc: 0.9704 - val_loss: 0.2318 - val_acc: 0.9333\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1004 - acc: 0.9778 - val_loss: 0.2423 - val_acc: 0.9333\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1100 - acc: 0.968 - 0s 1ms/step - loss: 0.0998 - acc: 0.9778 - val_loss: 0.2363 - val_acc: 0.9333\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1016 - acc: 0.9778 - val_loss: 0.2328 - val_acc: 0.9333\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0985 - acc: 0.9778 - val_loss: 0.2431 - val_acc: 0.9333\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9852 - val_loss: 0.2442 - val_acc: 0.9333\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0974 - acc: 0.9778 - val_loss: 0.2365 - val_acc: 0.9333\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0975 - acc: 0.9778 - val_loss: 0.2327 - val_acc: 0.9333\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0986 - acc: 0.9778 - val_loss: 0.2485 - val_acc: 0.9333\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0963 - acc: 0.9778 - val_loss: 0.2313 - val_acc: 0.9333\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0993 - acc: 0.9778 - val_loss: 0.2437 - val_acc: 0.9333\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0944 - acc: 0.9778 - val_loss: 0.2288 - val_acc: 0.9333\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0953 - acc: 0.9778 - val_loss: 0.2321 - val_acc: 0.9333\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0894 - acc: 0.982 - 0s 2ms/step - loss: 0.0943 - acc: 0.9778 - val_loss: 0.2348 - val_acc: 0.9333\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 49ms/step - loss: 3.6409 - acc: 0.3333 - val_loss: 3.0945 - val_acc: 0.3333\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.9231 - acc: 0.3333 - val_loss: 2.4194 - val_acc: 0.3333\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.2680 - acc: 0.3333 - val_loss: 1.7963 - val_acc: 0.3333\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.6945 - acc: 0.3333 - val_loss: 1.3305 - val_acc: 0.3333\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.3114 - acc: 0.3333 - val_loss: 1.0489 - val_acc: 0.3333\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0880 - acc: 0.3481 - val_loss: 0.9460 - val_acc: 0.4000\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9705 - acc: 0.4296 - val_loss: 0.8978 - val_acc: 0.4667\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8913 - acc: 0.5111 - val_loss: 0.8534 - val_acc: 0.4000\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8360 - acc: 0.4148 - val_loss: 0.8279 - val_acc: 0.4000\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7818 - acc: 0.4370 - val_loss: 0.7840 - val_acc: 0.4000\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7416 - acc: 0.4370 - val_loss: 0.7507 - val_acc: 0.5333\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7075 - acc: 0.6074 - val_loss: 0.7391 - val_acc: 0.5333\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6713 - acc: 0.6148 - val_loss: 0.6956 - val_acc: 0.5333\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6446 - acc: 0.6370 - val_loss: 0.6689 - val_acc: 0.5333\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6194 - acc: 0.6000 - val_loss: 0.6485 - val_acc: 0.5333\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5944 - acc: 0.6815 - val_loss: 0.6400 - val_acc: 0.5333\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5756 - acc: 0.6889 - val_loss: 0.6187 - val_acc: 0.6000\n",
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5560 - acc: 0.6889 - val_loss: 0.5963 - val_acc: 0.6000\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5400 - acc: 0.7037 - val_loss: 0.5854 - val_acc: 0.6000\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5241 - acc: 0.6963 - val_loss: 0.5615 - val_acc: 0.7333\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5098 - acc: 0.8370 - val_loss: 0.5432 - val_acc: 0.8000\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4961 - acc: 0.7852 - val_loss: 0.5284 - val_acc: 0.8667\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4815 - acc: 0.8741 - val_loss: 0.5237 - val_acc: 0.8000\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4693 - acc: 0.8519 - val_loss: 0.5114 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.8593 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4487 - acc: 0.9185 - val_loss: 0.4764 - val_acc: 0.9333\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4362 - acc: 0.9111 - val_loss: 0.4789 - val_acc: 0.8667\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4278 - acc: 0.8741 - val_loss: 0.4647 - val_acc: 0.9333\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4167 - acc: 0.9333 - val_loss: 0.4529 - val_acc: 0.9333\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4069 - acc: 0.9333 - val_loss: 0.4460 - val_acc: 0.9333\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3987 - acc: 0.9185 - val_loss: 0.4329 - val_acc: 0.9333\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3892 - acc: 0.9333 - val_loss: 0.4224 - val_acc: 0.9333\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3882 - acc: 0.8889 - val_loss: 0.4161 - val_acc: 0.9333\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3821 - acc: 0.9481 - val_loss: 0.4033 - val_acc: 0.9333\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3696 - acc: 0.9185 - val_loss: 0.3923 - val_acc: 1.0000\n",
      "Epoch 36/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3581 - acc: 0.9481 - val_loss: 0.3891 - val_acc: 0.9333\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3499 - acc: 0.9481 - val_loss: 0.3703 - val_acc: 1.0000\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3426 - acc: 0.9556 - val_loss: 0.3667 - val_acc: 1.0000\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3353 - acc: 0.9481 - val_loss: 0.3610 - val_acc: 1.0000\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3280 - acc: 0.9704 - val_loss: 0.3553 - val_acc: 1.0000\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3225 - acc: 0.9481 - val_loss: 0.3469 - val_acc: 1.0000\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3171 - acc: 0.9556 - val_loss: 0.3336 - val_acc: 1.0000\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3089 - acc: 0.9481 - val_loss: 0.3389 - val_acc: 1.0000\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3026 - acc: 0.9778 - val_loss: 0.3231 - val_acc: 1.0000\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2990 - acc: 0.9481 - val_loss: 0.3164 - val_acc: 1.0000\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2923 - acc: 0.9778 - val_loss: 0.3064 - val_acc: 1.0000\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2841 - acc: 0.9778 - val_loss: 0.3056 - val_acc: 1.0000\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2807 - acc: 0.9704 - val_loss: 0.2969 - val_acc: 1.0000\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2742 - acc: 0.9481 - val_loss: 0.2945 - val_acc: 1.0000\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2668 - acc: 0.9852 - val_loss: 0.2830 - val_acc: 1.0000\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2675 - acc: 0.9630 - val_loss: 0.2772 - val_acc: 1.0000\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2596 - acc: 0.9704 - val_loss: 0.2731 - val_acc: 1.0000\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2557 - acc: 0.9556 - val_loss: 0.2679 - val_acc: 1.0000\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2534 - acc: 0.9556 - val_loss: 0.2673 - val_acc: 1.0000\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2490 - acc: 0.9630 - val_loss: 0.2622 - val_acc: 1.0000\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2396 - acc: 0.9704 - val_loss: 0.2563 - val_acc: 1.0000\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2339 - acc: 0.9852 - val_loss: 0.2509 - val_acc: 1.0000\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2303 - acc: 0.9704 - val_loss: 0.2494 - val_acc: 1.0000\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2251 - acc: 0.9852 - val_loss: 0.2391 - val_acc: 1.0000\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2231 - acc: 0.9704 - val_loss: 0.2368 - val_acc: 1.0000\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2223 - acc: 0.9778 - val_loss: 0.2313 - val_acc: 1.0000\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2168 - acc: 0.9778 - val_loss: 0.2297 - val_acc: 1.0000\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2108 - acc: 0.9852 - val_loss: 0.2232 - val_acc: 1.0000\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2096 - acc: 0.9704 - val_loss: 0.2207 - val_acc: 1.0000\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2034 - acc: 0.9778 - val_loss: 0.2165 - val_acc: 1.0000\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2012 - acc: 0.9778 - val_loss: 0.2137 - val_acc: 1.0000\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2041 - acc: 0.9630 - val_loss: 0.2106 - val_acc: 1.0000\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1982 - acc: 0.9630 - val_loss: 0.2102 - val_acc: 1.0000\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1918 - acc: 0.9778 - val_loss: 0.2041 - val_acc: 1.0000\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1887 - acc: 0.9778 - val_loss: 0.1997 - val_acc: 1.0000\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1867 - acc: 0.9778 - val_loss: 0.1969 - val_acc: 1.0000\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1850 - acc: 0.9704 - val_loss: 0.1947 - val_acc: 1.0000\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1806 - acc: 0.9630 - val_loss: 0.1921 - val_acc: 1.0000\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1777 - acc: 0.9778 - val_loss: 0.1896 - val_acc: 1.0000\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1746 - acc: 0.9778 - val_loss: 0.1862 - val_acc: 1.0000\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1731 - acc: 0.9778 - val_loss: 0.1836 - val_acc: 1.0000\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1709 - acc: 0.9778 - val_loss: 0.1807 - val_acc: 1.0000\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1671 - acc: 0.9778 - val_loss: 0.1787 - val_acc: 1.0000\n",
      "Epoch 79/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1657 - acc: 0.9778 - val_loss: 0.1768 - val_acc: 1.0000\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1643 - acc: 0.9778 - val_loss: 0.1741 - val_acc: 1.0000\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1645 - acc: 0.9778 - val_loss: 0.1722 - val_acc: 1.0000\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1652 - acc: 0.9556 - val_loss: 0.1695 - val_acc: 1.0000\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1629 - acc: 0.9704 - val_loss: 0.1672 - val_acc: 1.0000\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1577 - acc: 0.9778 - val_loss: 0.1654 - val_acc: 1.0000\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1531 - acc: 0.9704 - val_loss: 0.1628 - val_acc: 1.0000\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1513 - acc: 0.9778 - val_loss: 0.1614 - val_acc: 1.0000\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1499 - acc: 0.9704 - val_loss: 0.1590 - val_acc: 1.0000\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1496 - acc: 0.9778 - val_loss: 0.1575 - val_acc: 1.0000\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1472 - acc: 0.9778 - val_loss: 0.1566 - val_acc: 1.0000\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1449 - acc: 0.9704 - val_loss: 0.1542 - val_acc: 1.0000\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1435 - acc: 0.9704 - val_loss: 0.1518 - val_acc: 1.0000\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1423 - acc: 0.9704 - val_loss: 0.1498 - val_acc: 1.0000\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1399 - acc: 0.9704 - val_loss: 0.1493 - val_acc: 1.0000\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1383 - acc: 0.9778 - val_loss: 0.1465 - val_acc: 1.0000\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1369 - acc: 0.9778 - val_loss: 0.1449 - val_acc: 1.0000\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1356 - acc: 0.9778 - val_loss: 0.1430 - val_acc: 1.0000\n",
      "Epoch 97/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1338 - acc: 0.9778 - val_loss: 0.1423 - val_acc: 1.0000\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1332 - acc: 0.9778 - val_loss: 0.1403 - val_acc: 1.0000\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1333 - acc: 0.9704 - val_loss: 0.1386 - val_acc: 1.0000\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1314 - acc: 0.9778 - val_loss: 0.1384 - val_acc: 1.0000\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1303 - acc: 0.9778 - val_loss: 0.1381 - val_acc: 1.0000\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1290 - acc: 0.9778 - val_loss: 0.1355 - val_acc: 1.0000\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1269 - acc: 0.9704 - val_loss: 0.1335 - val_acc: 1.0000\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1289 - acc: 0.9704 - val_loss: 0.1330 - val_acc: 1.0000\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1235 - acc: 0.9778 - val_loss: 0.1306 - val_acc: 1.0000\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1251 - acc: 0.9778 - val_loss: 0.1289 - val_acc: 1.0000\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1241 - acc: 0.9778 - val_loss: 0.1281 - val_acc: 1.0000\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1220 - acc: 0.9778 - val_loss: 0.1276 - val_acc: 1.0000\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1201 - acc: 0.9778 - val_loss: 0.1262 - val_acc: 1.0000\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1247 - acc: 0.9778 - val_loss: 0.1250 - val_acc: 1.0000\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1230 - acc: 0.9556 - val_loss: 0.1233 - val_acc: 1.0000\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1196 - acc: 0.9778 - val_loss: 0.1217 - val_acc: 1.0000\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1193 - acc: 0.9704 - val_loss: 0.1269 - val_acc: 1.0000\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1169 - acc: 0.9704 - val_loss: 0.1192 - val_acc: 1.0000\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1138 - acc: 0.9778 - val_loss: 0.1201 - val_acc: 1.0000\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1180 - acc: 0.9630 - val_loss: 0.1173 - val_acc: 1.0000\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1136 - acc: 0.9778 - val_loss: 0.1193 - val_acc: 1.0000\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1140 - acc: 0.9778 - val_loss: 0.1160 - val_acc: 1.0000\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1103 - acc: 0.9778 - val_loss: 0.1179 - val_acc: 1.0000\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1091 - acc: 0.9778 - val_loss: 0.1142 - val_acc: 1.0000\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1108 - acc: 0.9704 - val_loss: 0.1166 - val_acc: 1.0000\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1101 - acc: 0.9778 - val_loss: 0.1129 - val_acc: 1.0000\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1101 - acc: 0.9778 - val_loss: 0.1111 - val_acc: 1.0000\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1064 - acc: 0.9778 - val_loss: 0.1122 - val_acc: 1.0000\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1068 - acc: 0.9778 - val_loss: 0.1124 - val_acc: 1.0000\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1061 - acc: 0.9778 - val_loss: 0.1084 - val_acc: 1.0000\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1076 - acc: 0.9704 - val_loss: 0.1074 - val_acc: 1.0000\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1050 - acc: 0.9778 - val_loss: 0.1076 - val_acc: 1.0000\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1046 - acc: 0.9778 - val_loss: 0.1114 - val_acc: 1.0000\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1029 - acc: 0.9778 - val_loss: 0.1064 - val_acc: 1.0000\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1018 - acc: 0.9778 - val_loss: 0.1085 - val_acc: 1.0000\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1012 - acc: 0.9778 - val_loss: 0.1071 - val_acc: 1.0000\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1027 - acc: 0.9778 - val_loss: 0.1034 - val_acc: 1.0000\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1003 - acc: 0.9704 - val_loss: 0.1069 - val_acc: 1.0000\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1016 - acc: 0.9778 - val_loss: 0.1095 - val_acc: 1.0000\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0996 - acc: 0.9778 - val_loss: 0.1009 - val_acc: 1.0000\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1002 - acc: 0.9704 - val_loss: 0.1018 - val_acc: 1.0000\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1004 - acc: 0.9778 - val_loss: 0.1006 - val_acc: 1.0000\n",
      "Epoch 139/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0973 - acc: 0.9778 - val_loss: 0.1072 - val_acc: 1.0000\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0997 - acc: 0.9778 - val_loss: 0.1020 - val_acc: 1.0000\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0958 - acc: 0.9778 - val_loss: 0.1017 - val_acc: 1.0000\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0960 - acc: 0.9778 - val_loss: 0.1007 - val_acc: 1.0000\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0951 - acc: 0.9778 - val_loss: 0.0971 - val_acc: 1.0000\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0969 - acc: 0.9778 - val_loss: 0.0998 - val_acc: 1.0000\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0970 - acc: 0.9778 - val_loss: 0.0969 - val_acc: 1.0000\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0942 - acc: 0.9778 - val_loss: 0.0949 - val_acc: 1.0000\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0967 - acc: 0.9704 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0924 - acc: 0.9778 - val_loss: 0.0942 - val_acc: 1.0000\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0918 - acc: 0.9778 - val_loss: 0.0954 - val_acc: 1.0000\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0931 - acc: 0.9778 - val_loss: 0.0956 - val_acc: 1.0000\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0919 - acc: 0.9778 - val_loss: 0.0967 - val_acc: 1.0000\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0918 - acc: 0.9704 - val_loss: 0.0917 - val_acc: 1.0000\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0913 - acc: 0.9778 - val_loss: 0.0966 - val_acc: 1.0000\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0908 - acc: 0.9778 - val_loss: 0.0938 - val_acc: 1.0000\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0930 - acc: 0.9704 - val_loss: 0.0950 - val_acc: 1.0000\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0932 - acc: 0.9704 - val_loss: 0.0932 - val_acc: 1.0000\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0916 - acc: 0.9778 - val_loss: 0.0964 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0893 - acc: 0.9852 - val_loss: 0.0914 - val_acc: 1.0000\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0889 - acc: 0.9778 - val_loss: 0.0948 - val_acc: 1.0000\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0874 - acc: 0.9852 - val_loss: 0.0890 - val_acc: 1.0000\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0905 - acc: 0.9778 - val_loss: 0.0889 - val_acc: 1.0000\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0896 - acc: 0.9704 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0882 - acc: 0.9778 - val_loss: 0.0968 - val_acc: 1.0000\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0871 - acc: 0.9778 - val_loss: 0.0888 - val_acc: 1.0000\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0858 - acc: 0.9778 - val_loss: 0.0959 - val_acc: 1.0000\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.9852 - val_loss: 0.0898 - val_acc: 1.0000\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0868 - acc: 0.9778 - val_loss: 0.0899 - val_acc: 1.0000\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0853 - acc: 0.9778 - val_loss: 0.0857 - val_acc: 1.0000\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0858 - acc: 0.9778 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0905 - acc: 0.9630 - val_loss: 0.0895 - val_acc: 1.0000\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0855 - acc: 0.9852 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0852 - acc: 0.9778 - val_loss: 0.0830 - val_acc: 1.0000\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0855 - acc: 0.9852 - val_loss: 0.0868 - val_acc: 1.0000\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0828 - acc: 0.9778 - val_loss: 0.0838 - val_acc: 1.0000\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0817 - acc: 0.9852 - val_loss: 0.0922 - val_acc: 1.0000\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0825 - acc: 0.9778 - val_loss: 0.0831 - val_acc: 1.0000\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0824 - acc: 0.9852 - val_loss: 0.0830 - val_acc: 1.0000\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9778 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0851 - acc: 0.9778 - val_loss: 0.0859 - val_acc: 1.0000\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 0.9852 - val_loss: 0.0893 - val_acc: 1.0000\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0822 - acc: 0.9852 - val_loss: 0.0772 - val_acc: 1.0000\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0802 - acc: 0.9852 - val_loss: 0.0910 - val_acc: 0.9333\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0828 - acc: 0.9778 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0839 - acc: 0.9704 - val_loss: 0.0837 - val_acc: 1.0000\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0809 - acc: 0.9704 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0796 - acc: 0.9852 - val_loss: 0.0823 - val_acc: 1.0000\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0800 - acc: 0.9778 - val_loss: 0.0778 - val_acc: 1.0000\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0779 - acc: 0.9852 - val_loss: 0.0835 - val_acc: 1.0000\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0858 - acc: 0.9630 - val_loss: 0.0892 - val_acc: 0.9333\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0839 - acc: 0.976 - 0s 1ms/step - loss: 0.0833 - acc: 0.9778 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0829 - acc: 0.976 - 0s 1ms/step - loss: 0.0789 - acc: 0.9778 - val_loss: 0.0898 - val_acc: 0.9333\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0770 - acc: 0.9852 - val_loss: 0.0800 - val_acc: 1.0000\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0784 - acc: 0.9852 - val_loss: 0.0769 - val_acc: 1.0000\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0785 - acc: 0.9852 - val_loss: 0.0781 - val_acc: 1.0000\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0786 - acc: 0.9852 - val_loss: 0.0764 - val_acc: 1.0000\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0765 - acc: 0.9852 - val_loss: 0.0858 - val_acc: 1.0000\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0766 - acc: 0.9852 - val_loss: 0.0782 - val_acc: 1.0000\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0770 - acc: 0.9778 - val_loss: 0.0892 - val_acc: 0.9333\n",
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0766 - acc: 0.9852 - val_loss: 0.0891 - val_acc: 0.9333\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0768 - acc: 0.9852 - val_loss: 0.0781 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/200\n",
      "135/135 [==============================] - 7s 53ms/step - loss: 4.5211 - acc: 0.3259 - val_loss: 4.6279 - val_acc: 0.2667\n",
      "Epoch 2/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 3.6304 - acc: 0.1852 - val_loss: 3.7325 - val_acc: 0.0000e+00\n",
      "Epoch 3/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.9221 - acc: 0.0222 - val_loss: 2.8920 - val_acc: 0.0667\n",
      "Epoch 4/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.2699 - acc: 0.0444 - val_loss: 2.1709 - val_acc: 0.0667\n",
      "Epoch 5/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.8075 - acc: 0.0815 - val_loss: 1.6286 - val_acc: 0.0667\n",
      "Epoch 6/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.5181 - acc: 0.0667 - val_loss: 1.4441 - val_acc: 0.2667\n",
      "Epoch 7/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.4167 - acc: 0.2000 - val_loss: 1.3167 - val_acc: 0.2667\n",
      "Epoch 8/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.3572 - acc: 0.0815 - val_loss: 1.2476 - val_acc: 0.1333\n",
      "Epoch 9/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.2781 - acc: 0.1185 - val_loss: 1.1882 - val_acc: 0.2667\n",
      "Epoch 10/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1819 - acc: 0.2593 - val_loss: 1.1023 - val_acc: 0.2667\n",
      "Epoch 11/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0807 - acc: 0.3037 - val_loss: 1.0273 - val_acc: 0.6667\n",
      "Epoch 12/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9910 - acc: 0.6370 - val_loss: 0.9651 - val_acc: 0.6667\n",
      "Epoch 13/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9262 - acc: 0.6593 - val_loss: 0.9132 - val_acc: 0.6667\n",
      "Epoch 14/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8701 - acc: 0.6593 - val_loss: 0.8621 - val_acc: 0.6667\n",
      "Epoch 15/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8191 - acc: 0.6667 - val_loss: 0.8252 - val_acc: 0.6667\n",
      "Epoch 16/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7777 - acc: 0.6889 - val_loss: 0.7815 - val_acc: 0.6667\n",
      "Epoch 17/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7403 - acc: 0.6667 - val_loss: 0.7495 - val_acc: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7070 - acc: 0.6963 - val_loss: 0.7236 - val_acc: 0.6667\n",
      "Epoch 19/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6792 - acc: 0.7333 - val_loss: 0.6975 - val_acc: 0.6667\n",
      "Epoch 20/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6506 - acc: 0.7111 - val_loss: 0.6787 - val_acc: 0.6667\n",
      "Epoch 21/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6259 - acc: 0.8074 - val_loss: 0.6577 - val_acc: 0.7333\n",
      "Epoch 22/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6057 - acc: 0.8074 - val_loss: 0.6379 - val_acc: 0.7333\n",
      "Epoch 23/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5904 - acc: 0.8000 - val_loss: 0.6217 - val_acc: 0.7333\n",
      "Epoch 24/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5692 - acc: 0.8667 - val_loss: 0.6095 - val_acc: 0.8000\n",
      "Epoch 25/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5534 - acc: 0.8444 - val_loss: 0.5952 - val_acc: 0.8000\n",
      "Epoch 26/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5378 - acc: 0.9037 - val_loss: 0.5852 - val_acc: 0.8667\n",
      "Epoch 27/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5237 - acc: 0.9259 - val_loss: 0.5702 - val_acc: 0.8000\n",
      "Epoch 28/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5119 - acc: 0.8889 - val_loss: 0.5617 - val_acc: 0.8667\n",
      "Epoch 29/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4986 - acc: 0.9185 - val_loss: 0.5508 - val_acc: 0.8667\n",
      "Epoch 30/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4903 - acc: 0.8889 - val_loss: 0.5392 - val_acc: 0.8000\n",
      "Epoch 31/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4789 - acc: 0.8815 - val_loss: 0.5316 - val_acc: 0.8667\n",
      "Epoch 32/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4656 - acc: 0.9778 - val_loss: 0.5255 - val_acc: 0.8667\n",
      "Epoch 33/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4567 - acc: 0.9630 - val_loss: 0.5171 - val_acc: 0.8667\n",
      "Epoch 34/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4460 - acc: 0.9630 - val_loss: 0.5070 - val_acc: 0.8667\n",
      "Epoch 35/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4376 - acc: 0.9185 - val_loss: 0.5005 - val_acc: 0.8667\n",
      "Epoch 36/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4291 - acc: 0.9704 - val_loss: 0.4952 - val_acc: 0.8667\n",
      "Epoch 37/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4235 - acc: 0.9630 - val_loss: 0.4863 - val_acc: 0.8667\n",
      "Epoch 38/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4128 - acc: 0.9704 - val_loss: 0.4835 - val_acc: 0.8667\n",
      "Epoch 39/200\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.4049 - acc: 0.9630 - val_loss: 0.4750 - val_acc: 0.8667\n",
      "Epoch 40/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3980 - acc: 0.9704 - val_loss: 0.4699 - val_acc: 0.8667\n",
      "Epoch 41/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3909 - acc: 0.9926 - val_loss: 0.4623 - val_acc: 0.8667\n",
      "Epoch 42/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3853 - acc: 0.9556 - val_loss: 0.4571 - val_acc: 0.8667\n",
      "Epoch 43/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3771 - acc: 0.9926 - val_loss: 0.4545 - val_acc: 0.8667\n",
      "Epoch 44/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3724 - acc: 0.9630 - val_loss: 0.4476 - val_acc: 0.8667\n",
      "Epoch 45/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3647 - acc: 0.9704 - val_loss: 0.4409 - val_acc: 0.8667\n",
      "Epoch 46/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3570 - acc: 0.9778 - val_loss: 0.4375 - val_acc: 0.8667\n",
      "Epoch 47/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3510 - acc: 0.9852 - val_loss: 0.4324 - val_acc: 0.8667\n",
      "Epoch 48/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3455 - acc: 0.9926 - val_loss: 0.4262 - val_acc: 0.8667\n",
      "Epoch 49/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3388 - acc: 0.9778 - val_loss: 0.4222 - val_acc: 0.8667\n",
      "Epoch 50/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3317 - acc: 0.9852 - val_loss: 0.4181 - val_acc: 0.8667\n",
      "Epoch 51/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3254 - acc: 0.9852 - val_loss: 0.4124 - val_acc: 0.8667\n",
      "Epoch 52/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3203 - acc: 0.9852 - val_loss: 0.4089 - val_acc: 0.8667\n",
      "Epoch 53/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3178 - acc: 0.9704 - val_loss: 0.4060 - val_acc: 0.8667\n",
      "Epoch 54/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3095 - acc: 0.9704 - val_loss: 0.4000 - val_acc: 0.8667\n",
      "Epoch 55/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3032 - acc: 0.9852 - val_loss: 0.3959 - val_acc: 0.8667\n",
      "Epoch 56/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2996 - acc: 0.9852 - val_loss: 0.3918 - val_acc: 0.8667\n",
      "Epoch 57/200\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.2939 - acc: 0.9926 - val_loss: 0.3879 - val_acc: 0.8667\n",
      "Epoch 58/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2874 - acc: 0.9926 - val_loss: 0.3843 - val_acc: 0.8667\n",
      "Epoch 59/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2839 - acc: 0.9926 - val_loss: 0.3810 - val_acc: 0.8667\n",
      "Epoch 60/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2817 - acc: 0.9778 - val_loss: 0.3770 - val_acc: 0.8667\n",
      "Epoch 61/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2809 - acc: 0.9778 - val_loss: 0.3736 - val_acc: 0.8667\n",
      "Epoch 62/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2692 - acc: 0.9926 - val_loss: 0.3710 - val_acc: 0.8667\n",
      "Epoch 63/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2643 - acc: 0.9926 - val_loss: 0.3669 - val_acc: 0.8667\n",
      "Epoch 64/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2606 - acc: 0.9926 - val_loss: 0.3642 - val_acc: 0.8667\n",
      "Epoch 65/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2544 - acc: 0.9926 - val_loss: 0.3603 - val_acc: 0.8667\n",
      "Epoch 66/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2513 - acc: 0.9926 - val_loss: 0.3575 - val_acc: 0.8667\n",
      "Epoch 67/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2473 - acc: 0.9926 - val_loss: 0.3540 - val_acc: 0.8667\n",
      "Epoch 68/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2440 - acc: 0.9926 - val_loss: 0.3518 - val_acc: 0.8667\n",
      "Epoch 69/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2435 - acc: 0.9778 - val_loss: 0.3481 - val_acc: 0.8667\n",
      "Epoch 70/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2356 - acc: 0.9926 - val_loss: 0.3457 - val_acc: 0.8667\n",
      "Epoch 71/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2324 - acc: 0.9926 - val_loss: 0.3423 - val_acc: 0.8667\n",
      "Epoch 72/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2283 - acc: 0.9926 - val_loss: 0.3400 - val_acc: 0.8667\n",
      "Epoch 73/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2241 - acc: 0.9926 - val_loss: 0.3376 - val_acc: 0.8667\n",
      "Epoch 74/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2213 - acc: 0.9926 - val_loss: 0.3350 - val_acc: 0.8667\n",
      "Epoch 75/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2195 - acc: 0.9852 - val_loss: 0.3317 - val_acc: 0.8667\n",
      "Epoch 76/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2143 - acc: 0.9926 - val_loss: 0.3293 - val_acc: 0.8667\n",
      "Epoch 77/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2105 - acc: 0.9926 - val_loss: 0.3268 - val_acc: 0.8667\n",
      "Epoch 78/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2088 - acc: 0.9852 - val_loss: 0.3263 - val_acc: 0.8667\n",
      "Epoch 79/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2074 - acc: 0.9926 - val_loss: 0.3220 - val_acc: 0.8667\n",
      "Epoch 80/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2027 - acc: 0.9926 - val_loss: 0.3230 - val_acc: 0.8667\n",
      "Epoch 81/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2007 - acc: 0.9778 - val_loss: 0.3181 - val_acc: 0.8667\n",
      "Epoch 82/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1960 - acc: 0.9926 - val_loss: 0.3174 - val_acc: 0.8667\n",
      "Epoch 83/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1936 - acc: 0.9852 - val_loss: 0.3136 - val_acc: 0.8667\n",
      "Epoch 84/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1923 - acc: 0.9852 - val_loss: 0.3124 - val_acc: 0.8667\n",
      "Epoch 85/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1891 - acc: 0.9926 - val_loss: 0.3113 - val_acc: 0.8667\n",
      "Epoch 86/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1844 - acc: 0.9926 - val_loss: 0.3102 - val_acc: 0.8667\n",
      "Epoch 87/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1814 - acc: 0.9926 - val_loss: 0.3051 - val_acc: 0.8667\n",
      "Epoch 88/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1800 - acc: 0.9926 - val_loss: 0.3092 - val_acc: 0.8667\n",
      "Epoch 89/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1765 - acc: 0.9926 - val_loss: 0.3042 - val_acc: 0.8667\n",
      "Epoch 90/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1744 - acc: 0.9852 - val_loss: 0.2996 - val_acc: 0.8667\n",
      "Epoch 91/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1715 - acc: 0.9852 - val_loss: 0.2996 - val_acc: 0.8667\n",
      "Epoch 92/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1702 - acc: 0.9926 - val_loss: 0.2989 - val_acc: 0.8667\n",
      "Epoch 93/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1662 - acc: 0.9926 - val_loss: 0.2944 - val_acc: 0.8667\n",
      "Epoch 94/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1639 - acc: 0.9926 - val_loss: 0.2973 - val_acc: 0.8667\n",
      "Epoch 95/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1622 - acc: 0.9926 - val_loss: 0.2934 - val_acc: 0.8667\n",
      "Epoch 96/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1626 - acc: 0.9926 - val_loss: 0.2962 - val_acc: 0.8667\n",
      "Epoch 97/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1575 - acc: 0.9926 - val_loss: 0.2917 - val_acc: 0.8667\n",
      "Epoch 98/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1564 - acc: 0.9926 - val_loss: 0.2905 - val_acc: 0.8667\n",
      "Epoch 99/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1531 - acc: 0.9926 - val_loss: 0.2873 - val_acc: 0.8667\n",
      "Epoch 100/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1515 - acc: 0.9926 - val_loss: 0.2849 - val_acc: 0.8667\n",
      "Epoch 101/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1497 - acc: 0.9926 - val_loss: 0.2848 - val_acc: 0.8667\n",
      "Epoch 102/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1467 - acc: 0.9926 - val_loss: 0.2827 - val_acc: 0.8667\n",
      "Epoch 103/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1481 - acc: 0.9926 - val_loss: 0.2850 - val_acc: 0.8667\n",
      "Epoch 104/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1577 - acc: 0.9778 - val_loss: 0.2936 - val_acc: 0.8667\n",
      "Epoch 105/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1478 - acc: 0.9778 - val_loss: 0.2784 - val_acc: 0.8667\n",
      "Epoch 106/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1422 - acc: 0.9778 - val_loss: 0.2786 - val_acc: 0.8667\n",
      "Epoch 107/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1394 - acc: 0.9926 - val_loss: 0.2762 - val_acc: 0.8667\n",
      "Epoch 108/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1411 - acc: 0.9778 - val_loss: 0.2833 - val_acc: 0.8667\n",
      "Epoch 109/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1395 - acc: 0.9778 - val_loss: 0.2718 - val_acc: 0.8667\n",
      "Epoch 110/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1350 - acc: 0.9778 - val_loss: 0.2731 - val_acc: 0.8667\n",
      "Epoch 111/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1322 - acc: 0.9926 - val_loss: 0.2742 - val_acc: 0.8667\n",
      "Epoch 112/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1313 - acc: 0.9926 - val_loss: 0.2701 - val_acc: 0.8667\n",
      "Epoch 113/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1306 - acc: 0.9926 - val_loss: 0.2688 - val_acc: 0.8667\n",
      "Epoch 114/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1292 - acc: 0.9704 - val_loss: 0.2718 - val_acc: 0.8667\n",
      "Epoch 115/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1283 - acc: 0.9852 - val_loss: 0.2721 - val_acc: 0.8667\n",
      "Epoch 116/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1269 - acc: 0.9778 - val_loss: 0.2752 - val_acc: 0.8667\n",
      "Epoch 117/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1235 - acc: 0.9926 - val_loss: 0.2689 - val_acc: 0.8667\n",
      "Epoch 118/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1211 - acc: 0.9926 - val_loss: 0.2644 - val_acc: 0.8667\n",
      "Epoch 119/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1200 - acc: 0.9926 - val_loss: 0.2680 - val_acc: 0.8667\n",
      "Epoch 120/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1224 - acc: 0.9926 - val_loss: 0.2648 - val_acc: 0.8667\n",
      "Epoch 121/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1214 - acc: 0.9852 - val_loss: 0.2607 - val_acc: 0.8667\n",
      "Epoch 122/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1158 - acc: 0.9926 - val_loss: 0.2707 - val_acc: 0.8667\n",
      "Epoch 123/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1166 - acc: 0.9926 - val_loss: 0.2601 - val_acc: 0.8667\n",
      "Epoch 124/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1175 - acc: 0.9926 - val_loss: 0.2586 - val_acc: 0.8667\n",
      "Epoch 125/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1136 - acc: 0.9926 - val_loss: 0.2606 - val_acc: 0.8667\n",
      "Epoch 126/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1143 - acc: 0.9852 - val_loss: 0.2585 - val_acc: 0.8667\n",
      "Epoch 127/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1123 - acc: 0.9926 - val_loss: 0.2615 - val_acc: 0.8667\n",
      "Epoch 128/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1126 - acc: 0.9926 - val_loss: 0.2610 - val_acc: 0.8667\n",
      "Epoch 129/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1113 - acc: 0.9852 - val_loss: 0.2602 - val_acc: 0.8667\n",
      "Epoch 130/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1087 - acc: 0.9926 - val_loss: 0.2559 - val_acc: 0.8667\n",
      "Epoch 131/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1065 - acc: 0.9926 - val_loss: 0.2586 - val_acc: 0.8667\n",
      "Epoch 132/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1071 - acc: 0.9926 - val_loss: 0.2561 - val_acc: 0.8667\n",
      "Epoch 133/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1055 - acc: 0.9926 - val_loss: 0.2626 - val_acc: 0.8667\n",
      "Epoch 134/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1059 - acc: 0.9926 - val_loss: 0.2512 - val_acc: 0.8667\n",
      "Epoch 135/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1081 - acc: 0.976 - 0s 1ms/step - loss: 0.1044 - acc: 0.9778 - val_loss: 0.2579 - val_acc: 0.8667\n",
      "Epoch 136/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1028 - acc: 0.9926 - val_loss: 0.2532 - val_acc: 0.8667\n",
      "Epoch 137/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1025 - acc: 0.9778 - val_loss: 0.2599 - val_acc: 0.8667\n",
      "Epoch 138/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1013 - acc: 0.9926 - val_loss: 0.2535 - val_acc: 0.8667\n",
      "Epoch 139/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1009 - acc: 0.9778 - val_loss: 0.2591 - val_acc: 0.8667\n",
      "Epoch 140/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0992 - acc: 0.9926 - val_loss: 0.2523 - val_acc: 0.8667\n",
      "Epoch 141/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0978 - acc: 0.9852 - val_loss: 0.2520 - val_acc: 0.8667\n",
      "Epoch 142/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0983 - acc: 0.9926 - val_loss: 0.2528 - val_acc: 0.8667\n",
      "Epoch 143/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0998 - acc: 0.9778 - val_loss: 0.2515 - val_acc: 0.8667\n",
      "Epoch 144/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0982 - acc: 0.9778 - val_loss: 0.2560 - val_acc: 0.8667\n",
      "Epoch 145/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0980 - acc: 0.9926 - val_loss: 0.2479 - val_acc: 0.8667\n",
      "Epoch 146/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0948 - acc: 0.9852 - val_loss: 0.2559 - val_acc: 0.8667\n",
      "Epoch 147/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0945 - acc: 0.9926 - val_loss: 0.2484 - val_acc: 0.8667\n",
      "Epoch 148/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0941 - acc: 0.9852 - val_loss: 0.2440 - val_acc: 0.8667\n",
      "Epoch 149/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0910 - acc: 0.9926 - val_loss: 0.2512 - val_acc: 0.8667\n",
      "Epoch 150/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0915 - acc: 0.9926 - val_loss: 0.2460 - val_acc: 0.8667\n",
      "Epoch 151/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0904 - acc: 0.9926 - val_loss: 0.2515 - val_acc: 0.8667\n",
      "Epoch 152/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0895 - acc: 0.9926 - val_loss: 0.2479 - val_acc: 0.8667\n",
      "Epoch 153/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0898 - acc: 0.9926 - val_loss: 0.2532 - val_acc: 0.8667\n",
      "Epoch 154/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0877 - acc: 0.9926 - val_loss: 0.2450 - val_acc: 0.8667\n",
      "Epoch 155/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0876 - acc: 0.9852 - val_loss: 0.2516 - val_acc: 0.8667\n",
      "Epoch 156/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0882 - acc: 0.9926 - val_loss: 0.2560 - val_acc: 0.8667\n",
      "Epoch 157/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0894 - acc: 0.9778 - val_loss: 0.2386 - val_acc: 0.8667\n",
      "Epoch 158/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0865 - acc: 0.9926 - val_loss: 0.2571 - val_acc: 0.8667\n",
      "Epoch 159/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0848 - acc: 0.9926 - val_loss: 0.2455 - val_acc: 0.8667\n",
      "Epoch 160/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0864 - acc: 0.9926 - val_loss: 0.2544 - val_acc: 0.8667\n",
      "Epoch 161/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9926 - val_loss: 0.2465 - val_acc: 0.8667\n",
      "Epoch 162/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0841 - acc: 0.9852 - val_loss: 0.2502 - val_acc: 0.8667\n",
      "Epoch 163/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9926 - val_loss: 0.2516 - val_acc: 0.8667\n",
      "Epoch 164/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0823 - acc: 0.9926 - val_loss: 0.2456 - val_acc: 0.8667\n",
      "Epoch 165/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0819 - acc: 0.9926 - val_loss: 0.2494 - val_acc: 0.8667\n",
      "Epoch 166/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0857 - acc: 0.9926 - val_loss: 0.2569 - val_acc: 0.8667\n",
      "Epoch 167/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0831 - acc: 0.9926 - val_loss: 0.2369 - val_acc: 0.8667\n",
      "Epoch 168/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0816 - acc: 0.9852 - val_loss: 0.2526 - val_acc: 0.8667\n",
      "Epoch 169/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9926 - val_loss: 0.2379 - val_acc: 0.8667\n",
      "Epoch 170/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0805 - acc: 0.9852 - val_loss: 0.2429 - val_acc: 0.8667\n",
      "Epoch 171/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0807 - acc: 0.9926 - val_loss: 0.2632 - val_acc: 0.8667\n",
      "Epoch 172/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0821 - acc: 0.9852 - val_loss: 0.2363 - val_acc: 0.8667\n",
      "Epoch 173/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0794 - acc: 0.9852 - val_loss: 0.2511 - val_acc: 0.8667\n",
      "Epoch 174/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0799 - acc: 0.9778 - val_loss: 0.2434 - val_acc: 0.8667\n",
      "Epoch 175/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0769 - acc: 0.9926 - val_loss: 0.2490 - val_acc: 0.8667\n",
      "Epoch 176/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0761 - acc: 0.9926 - val_loss: 0.2380 - val_acc: 0.8667\n",
      "Epoch 177/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0788 - acc: 0.9852 - val_loss: 0.2571 - val_acc: 0.8667\n",
      "Epoch 178/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0782 - acc: 0.9926 - val_loss: 0.2439 - val_acc: 0.8667\n",
      "Epoch 179/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0766 - acc: 0.9926 - val_loss: 0.2431 - val_acc: 0.8667\n",
      "Epoch 180/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0785 - acc: 0.9926 - val_loss: 0.2459 - val_acc: 0.8667\n",
      "Epoch 181/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0838 - acc: 0.9704 - val_loss: 0.2578 - val_acc: 0.8667\n",
      "Epoch 182/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0750 - acc: 0.9926 - val_loss: 0.2372 - val_acc: 0.8667\n",
      "Epoch 183/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0748 - acc: 0.9778 - val_loss: 0.2595 - val_acc: 0.8667\n",
      "Epoch 184/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0751 - acc: 0.9926 - val_loss: 0.2424 - val_acc: 0.8667\n",
      "Epoch 185/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0744 - acc: 0.984 - 0s 1ms/step - loss: 0.0738 - acc: 0.9852 - val_loss: 0.2424 - val_acc: 0.8667\n",
      "Epoch 186/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0718 - acc: 0.9926 - val_loss: 0.2412 - val_acc: 0.8667\n",
      "Epoch 187/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0758 - acc: 0.992 - 0s 1ms/step - loss: 0.0721 - acc: 0.9926 - val_loss: 0.2450 - val_acc: 0.8667\n",
      "Epoch 188/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0727 - acc: 0.9926 - val_loss: 0.2454 - val_acc: 0.8667\n",
      "Epoch 189/200\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.0767 - acc: 0.983 - 0s 1ms/step - loss: 0.0725 - acc: 0.9852 - val_loss: 0.2338 - val_acc: 0.8667\n",
      "Epoch 190/200\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.0731 - acc: 0.9852 - val_loss: 0.2547 - val_acc: 0.8667\n",
      "Epoch 191/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0742 - acc: 0.9778 - val_loss: 0.2657 - val_acc: 0.8667\n",
      "Epoch 192/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0697 - acc: 0.9926 - val_loss: 0.2338 - val_acc: 0.8667\n",
      "Epoch 193/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0723 - acc: 0.9778 - val_loss: 0.2380 - val_acc: 0.8667\n",
      "Epoch 194/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0705 - acc: 0.9926 - val_loss: 0.2532 - val_acc: 0.8667\n",
      "Epoch 195/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0686 - acc: 0.9926 - val_loss: 0.2358 - val_acc: 0.8667\n",
      "Epoch 196/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0685 - acc: 0.9852 - val_loss: 0.2439 - val_acc: 0.8667\n",
      "Epoch 197/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0703 - acc: 0.9852 - val_loss: 0.2450 - val_acc: 0.8667\n",
      "Epoch 198/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0682 - acc: 0.9926 - val_loss: 0.2501 - val_acc: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 199/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0702 - acc: 0.9926 - val_loss: 0.2488 - val_acc: 0.8667\n",
      "Epoch 200/200\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.0723 - acc: 0.9778 - val_loss: 0.2403 - val_acc: 0.8667\n",
      "Accuracy is found to be 0.921366668909788\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAHrtJREFUeJzt3XuUXXV99/H3ZyZDCEnIQDKJkAtJJEZALuEZIoJaKqiQ\nWlItQtCKj9gnYtES8YZYra121dZby6OV0qVL6IN4h9IW5CY3qwQmIQmEcAn3QG6E3BNy/T5//PY5\nc2YyZ2Zy2WfPzPm81trrnLPPnnO+s+fkfPLbv71/P0UEZmZmAA1FF2BmZn2HQ8HMzMocCmZmVuZQ\nMDOzMoeCmZmVORTMzKzMoWBmZmUOBTMzK3MomJlZ2aCiC9hbo0aNiokTJxZdhplZvzJv3rxXIqKl\np+36XShMnDiRtra2osswM+tXJD3fm+18+MjMzMocCmZmVuZQMDOzMoeCmZmVORTMzKwst1CQdLCk\nByUtlLRY0t90sY0kXSVpqaRFkk7Oqx4zM+tZnqekbgPeERGbJDUBv5V0a0Q8ULHNOcCUbHkz8P3s\n1szMCpBbSyGSTdnDpmzpPPfnTOC6bNsHgGZJR+RRz6OPwpe+BK+8kserm5kNDLn2KUhqlLQAWAXc\nERFzO20yFnix4vGybN0B98QT8LWvwfLleby6mdnAkGsoRMSuiDgJGAdMl/SmfXkdSbMltUlqW716\n9T7Vcsgh6XbLln36cTOzulCTs48iYh1wN3B2p6deAsZXPB6Xrev889dERGtEtLa09Dh0R5ccCmZm\nPcvz7KMWSc3Z/SHAO4HHO212M3BRdhbSqcD6iMjlAE8pFLZuzePVzcwGhjzPPjoCuFZSIyl8fhYR\n/yXpEoCIuBq4BZgBLAW2AB/Jqxi3FMzMepZbKETEImBaF+uvrrgfwKV51VDJoWBm1rO6uaJ5yJB0\n61AwM6uubkLBLQUzs57VTSi4pWBm1rO6CYWmprQ4FMzMqqubUIB0CMmhYGZWnUPBzMzKHApmZlZW\nd6HgK5rNzKqru1BwS8HMrLq6CoUhQxwKZmbdqatQcEvBzKx7DgUzMytzKJiZWZlDwczMyhwKZmZW\nVpehEFF0JWZmfVPdhcLu3bBjR9GVmJn1TXUXCuBDSGZm1dRVKHhOBTOz7tVVKLilYGbWPYeCmZmV\nORTMzKzMoWBmZmUOBTMzK3MomJlZWW6hIGm8pLslPSZpsaTLutjmDEnrJS3Ili/nVQ+0h4JnXzMz\n69qgHF97J/DpiJgvaTgwT9IdEfFYp+3uj4j35FhHmVsKZmbdy62lEBHLI2J+dn8jsAQYm9f79YZD\nwcysezXpU5A0EZgGzO3i6dMkLZJ0q6Tj8qzDVzSbmXUvz8NHAEgaBvwSmBMRGzo9PR+YEBGbJM0A\nbgKmdPEas4HZABMmTNjnWhob4aCDHApmZtXk2lKQ1EQKhOsj4ledn4+IDRGxKbt/C9AkaVQX210T\nEa0R0drS0rJfNXlOBTOz6vI8+0jAD4AlEfHtKtu8LtsOSdOzetbkVRM4FMzMupPn4aPTgQ8Bj0ha\nkK27EpgAEBFXA+cBH5e0E9gKzIrIdwoch4KZWXW5hUJE/BZQD9t8F/huXjV05ZBDYPPmWr6jmVn/\nUVdXNAMMHeqWgplZNXUXCsOGwaZNRVdhZtY3ORTMzKzMoWBmZmUOBTMzK6u7UBg61KFgZlZN3YXC\nsGFp6Oxdu4quxMys76nLUACflmpm1pW6DQUfQjIz25NDwczMyhwKZmZW5lAwM7Myh4KZmZXVXSgM\nHZpuHQpmZnuqu1BwS8HMrDqHgpmZlTkUzMysrO5CYfBgaGx0KJiZdaXuQkFKrQVPyWlmtqe6CwXw\n8NlmZtU4FMzMrMyhYGZmZXUZCp5ox8ysa3UZCm4pmJl1zaFgZmZluYWCpPGS7pb0mKTFki7rYhtJ\nukrSUkmLJJ2cVz2VHApmZl0blONr7wQ+HRHzJQ0H5km6IyIeq9jmHGBKtrwZ+H52myuHgplZ13Jr\nKUTE8oiYn93fCCwBxnbabCZwXSQPAM2SjsirppJSKETk/U5mZv1LTfoUJE0EpgFzOz01Fnix4vEy\n9gyOA27YMNi1C7Zty/udzMz6l9xDQdIw4JfAnIjYsI+vMVtSm6S21atX73dNHhTPzKxruYaCpCZS\nIFwfEb/qYpOXgPEVj8dl6zqIiGsiojUiWltaWva7rtJEOx7/yMysozzPPhLwA2BJRHy7ymY3Axdl\nZyGdCqyPiOV51VTiloKZWdfyPPvodOBDwCOSFmTrrgQmAETE1cAtwAxgKbAF+EiO9ZSVQmHjxlq8\nm5lZ/5FbKETEbwH1sE0Al+ZVQzUjRqTbDfvUw2FmNnDV5RXNzc3pdt26YuswM+trHApmZlbmUDAz\ns7K6DIVDDoFBgxwKZmad1WUoSKm14FAwM+uoLkMBHApmZl2p21AYMcKhYGbWWd2GglsKZmZ76jEU\nJF0m6dBsKIofSJov6V21KC5Pzc2wfn3RVZiZ9S29aSlcnI1u+i7gMNLQFV/PtaoacEvBzGxPvQmF\n0lAVM4B/j4jF9DB8RX/gUDAz21NvQmGepNtJoXBbNrXm7nzLyl9zM2zZAtu3F12JmVnf0ZsB8T4K\nnAQ8ExFbJB1OjUYzzVPpqub16+EATNFgZjYg9Kal8BbgiYhYJ+nPgL8C+n0XrYe6MDPbU29C4fvA\nFkknAp8Gngauy7WqGnAomJntqTehsDOb92Am8N2I+B4wPN+y8udQMDPbU2/6FDZK+gLpVNS3SWoA\nmvItK3+liXZ8rYKZWbvetBQuALaRrldYAYwDvpFrVTXgloKZ2Z56DIUsCK4HRkh6D/BaRLhPwcxs\nAOrNMBfnAw8C7wfOB+ZKOi/vwvI2bBg0NDgUzMwq9aZP4YvAKRGxCkBSC3An8Is8C8ub51QwM9tT\nb/oUGkqBkFnTy5/r8xwKZmYd9aal8GtJtwE3ZI8vAG7Jr6TacSiYmXXUYyhExGcl/Slwerbqmoi4\nMd+yauOww+DVV4uuwsys7+hNS4GI+CXwy5xrqbnRo+Ghh4quwsys76jaNyBpo6QNXSwbJW3o6YUl\n/VDSKkmPVnn+DEnrJS3Ili/vzy+yL0aPhpUra/2uZmZ9V9WWQkTs71AWPwK+S/fjJN0fEe/Zz/fZ\nZ6NHw8aNsHUrDBlSVBVmZn1HbmcRRcR9QJ8+Yj96dLpdvbrYOszM+oqiTy09TdIiSbdKOq7Wb14K\nhVWrut/OzKxe9KqjOSfzgQkRsUnSDOAmYEpXG0qaDcwGmDBhwgErYMyYdOt+BTOzpLCWQkRsiIhN\n2f1bgCZJo6pse01EtEZEa8sBnCbNLQUzs46qthQkbQSiq6eAiIhD9+eNJb0OWBkRIWk6KaDW7M9r\n7i2HgplZR7mdfSTpBuAMYJSkZcBfk83DEBFXA+cBH5e0E9gKzMom86mZoUPhkEMcCmZmJb3uU5A0\nGji49DgiXuhu+4i4sIfnv0s6ZbVQY8a4T8HMrKQ3Q2efK+kp4FngXuA54Nac66qZ0aPdUjAzK+lN\nR/NXgVOBJyNiEnAm8ECuVdWQQ8HMrF1vQmFHRKwBGiQ1RMTdQGvOddWMQ8HMrF1v+hTWSRoG3Adc\nL2kVsDnfsmpnzJgUCrt3p5nYzMzqWW++BmcCW4BPAb8Gngb+OM+iamn0aNi1C9auLboSM7Pi9aal\n8DHgpxHxEnBtzvXUXOW1CiNHFluLmVnRetNSGA7cLul+SZ+QNCbvomqpFAo+LdXMrBehEBF/ExHH\nAZcCRwD3Sroz98pqZPz4dPv888XWYWbWF+xN1+oqYAVpKIrR+ZRTe5MmQWMjPPVU0ZWYmRWvNxev\n/YWke4C7gJHA/4mIE/IurFaammDiRIeCmRn0rqN5PDAnIhbkXUxRjj4ali4tugozs+L1GAoR8YVa\nFFKkKVPgd7+DCJCKrsbMrDi+XIsUChs3+spmMzOHAikUwP0KZmYOBVKfArhfwczMoUA6+8inpZqZ\nORSAdFrqpEkOBTMzh0JmyhR44omiqzAzK5ZDIXPCCbBkCWzfXnQlZmbFcShkpk2DHTtg8eKiKzEz\nK45DITNtWrp9+OFi6zAzK5JDIXP00TB0qEPBzOqbQyHT0AAnnuhQMLP65lCoMG0aLFyY5ms2M6tH\nDoUK06bBpk3w9NNFV2JmVozcQkHSDyWtkvRolecl6SpJSyUtknRyXrX01slZBW1txdZhZlaUPFsK\nPwLO7ub5c4Ap2TIb+H6OtfTK8cdDczPcdVfRlZiZFSO3UIiI+4BXu9lkJnBdJA8AzZKOyKue3hg0\nCN7xDrj99jS3gplZvSmyT2Es8GLF42XZukK9853w4ovw5JNFV2JmVnv9oqNZ0mxJbZLaVq9enet7\nvetd6faOO3J9GzOzPqnIUHiJNP9zybhs3R4i4pqIaI2I1paWllyLmjw5LQ4FM6tHRYbCzcBF2VlI\npwLrI2J5gfWUzZiR+hXWri26EjOz2srzlNQbgN8DUyUtk/RRSZdIuiTb5BbgGWAp8G/AX+RVy966\n+GJ47TW47rqiKzEzqy1FPzvNprW1NdpqcCHBqafC+vXw2GMg5f52Zma5kjQvIlp72q5fdDQX4ZJL\n4PHH4Z57iq7EzKx2HApVXHABtLTA3/990ZWYmdWOQ6GKIUPgc59LZyH97ndFV2NmVhsOhW58/OOp\ntfCVrxRdiZlZbTgUujF0KHz+86m1cPvtRVdjZpY/h0IPPvGJdDHb5ZfDzp1FV2Nmli+HQg8GD4Zv\nfAMWL4Z/+qeiqzEzy5dDoRfe+960XHEF/OY3RVdjZpYfh0IvSHDttTB1Kpx/Pjz3XNEVmZnlw6HQ\nS8OHw003pX6F974XtmwpuiIzswPPobAXpkyBH/8YFi6EP/9zT8RjZgOPQ2EvzZgBX/sa3HADfOtb\nRVdjZnZgDSq6gP7oC1+Ahx9OVzw3NcFllxVdkZnZgeFQ2AdSGlZ71y6YMwdeeCGdttrgdpeZ9XP+\nGttHQ4bAz3+eLm779rfhwgvTHAxmZv2ZWwr7obERrroKjjoKPvtZWL48naF0+OFFV2Zmtm/cUthP\nEnzmM6njee5caG2Fhx4quiozs33jUDhAZs1KE/Ls2gWnnw7f+Y5PWTWz/sehcAC95S3prKQ/+qM0\ngN6558KaNUVXZWbWew6FA+zww+FXv0p9DbffDieeCLfdVnRVZma941DIgQSf/CT8/vdpeIyzz4aL\nL4a1a4uuzMysew6FHJ18cjqcdOWV6bqGY4+Fr38dVq0qujIzs645FHJ28MHwd38HDz4Ib3xjuhp6\n6lT42c+KrszMbE8OhRo5+WS4++40Wc/UqXDBBXD88fDP/+wZ3cys73Ao1Nixx8L998PVV6f+hjlz\n4O1v97UNZtY35BoKks6W9ISkpZKu6OL5MyStl7QgW76cZz19RVMTfOxj8D//A9dfD48/DtOnwx/+\nIdxyi69vMLPi5BYKkhqB7wHnAMcCF0o6totN74+Ik7Llb/Oqpy+S4AMfSDO5ffObsHRpusbhhBNS\nx/T27UVXaGb1Js+WwnRgaUQ8ExHbgZ8AM3N8v37r0EPh05+Gp59O034CfPjDMHlymrth2bJi6zOz\n+pFnKIwFXqx4vCxb19lpkhZJulXScTnW0+cddBBcdBEsWpQOI02dCl/6Uhpw75xz0qis27YVXaWZ\nDWRFdzTPByZExAnA/wVu6mojSbMltUlqW716dU0LLIKUQuCuu9IhpSuvhEcfhfPPhyOPTJP6LFpU\ndJVmNhDlGQovAeMrHo/L1pVFxIaI2JTdvwVokjSq8wtFxDUR0RoRrS0tLTmW3Pe8/vXw1a+mfodf\n/xrOOiuduXTiiWlE1n/5F18pbWYHTp6h8BAwRdIkSQcBs4CbKzeQ9DpJyu5Pz+rxEHJdaGyEd78b\nfvpTePnldH3Djh1w6aWp9fDBD8JvfgO7dxddqZn1Z7mFQkTsBD4B3AYsAX4WEYslXSLpkmyz84BH\nJS0ErgJmRfiEzJ6MHAl/+ZewYAG0taVxlf77v+HMM1NAzJoFN97os5fMbO+pv30Ht7a2RltbW9Fl\n9Dlbt6bRWW+9Fe68E1auTGc1nXVWmir03HNTR7aZ1SdJ8yKitcftHAoDz86dadjum25KLYiXX4ah\nQ+GUU1I4zJoFRxxRdJVmVksOBQPSTHB33JFOcb3vPli4EBoa0tXT739/ulhu7Nh0xpOZDVwOBevS\n44+n+aR//ON0uiukiYHe+laYMSMt48d3/xpm1v84FKxbEenah3vuSdc83HEHPP98eu6UU9LZTG9+\ncxrJdejQQks1swOgt6EwqBbFWN8jpS/8449PjyNSK+I//zMN0jdnTvt2b3wjvO99MHNmuj7CHdZm\nA5dbCtal559P/Q8LFqShvkvXQAweDNOmpVZEaZk0yX0SZn2dDx/ZAbViRQqHuXPTMm9eOg0WoKUl\nDf1dConp06G5udh6zawjh4LlaseO1CdRCom5c2HJkvbnp07t2Jo44YQ0j4SZFcOhYDW3fn2aQa4y\nKFatSs81NsK4cfCmN6Uxm045JQ0NfuSRMGJEsXWb1QN3NFvNjRiRrqA+66z0OCL1TcydC488As8+\nm/opKmeXk1JL4pRT0qmwb3lLCoshQ+Cww4r7XczqlUPBciPBxIlpueCC9vWbNqUO7BdfhCefTFdd\nX3stbNjQ8eenToVTT00jxU6enJbXvz71Ybhj2ywfPnxkfcYrr6R5q1esSIei7rkntSxefrnjdkOH\nwrHHwh/8Qboae+RIOOYYGD063fd1FWZ7cp+CDRhbt6b5JJ55Ji1PPw3z58MDD6QO70pSCoyjj04h\nMXp0Cozp01OAHHJIIb+CWeHcp2ADxpAh6Yv9mGM6rt+xAzZvTi2Lxx+HNWvSfNYPPpjCY+5cWL06\njf9UMnw4jBnTvhx5ZLqA7+ij03Af48al1oYPT1m9cihYv9XUlK6HaG5OV113Zdeu1Mk9f34Kj5Ur\n25clS9LwHhs3dvyZIUNgwoS0jBuXWhtjxrS3PEqPR42CQf4XZAOMP9I2oDU2wkknpaUrEemsqBde\naG9pvPBC+/LYY+m02s6HqSC1Jg4/vGNgvO516Syq8ePT+s2b01lZxxyTzqZqKHpWdLMeOBSsrknt\nZzZVE5E6vleuTAGxalXH+6XHCxbA8uV7tjwq32v06HQG1ahRKVAOO6x9OfzwjsvIkSlQHCRWSw4F\nsx5I7Yeppk7tefv161MrY9WqdCbUq6/CE0/A2rXpTKpnnkkd5w8/nNZt2lT9tRoa0vsOH546yUvL\n8OFpoqQjj0yn6G7dmg6nVR7iGjkytXAOPji1YNxPYr3hUDA7wEaMaB99tmTGjOrbb98O69al8Fi7\nNt2uWZNuS/c3b4YtW9qXFStSqKxcmQYq7MnBB6cg2b07XQ9Sujiwubn67eDB6fDbiBEd1zc0wLZt\nKZyGDUuv6yFMBg6HglnBDjqo/X/3e2vnzhQoQ4akcKk8pLVmTXrtzZtTv8nmzam1cOihqWWxbl0K\noXXr0oRLpcebN+99HYMHp3AohUTlUrkO4KWXUrhMnJjCpLExBU1jY1oGDWq/1uS119LPNTe3h1Nz\nc3p+48Z0aK+5OdW+dWv7NLO7dqXXsr3nUDDrxwYNSv0TkL4oDzusd4e4urNjR/qS3bEjhc769e3h\nsXZt+iIePDi1WDZuTIe/Nm5sX0qP165Nh9Eqn4f0xf3qq+nnD4Rhw9oPwY0fn1533bp09tjQoWkf\njRmTgjMitZZ27+54v6EBjjoqbb9uXerTGT48/f47d6Ztm5rSctBB7belZcSI9Povv5weH3lk+j1f\ney2F88SJaf3y5e3bTJ2aai+9rpTep3TpWOX9gw9Or18LDgUz66CpKfVTHGilL7mGhnS7dm36H/2u\nXemLuXS7Y0cKECmFz6ZN6Yt6/fp0u25dOgTW3Nw+vtbYsemLdu7c9AU9cmTqt9m2LbWgVqxI9xsa\n0us2NHRcduxI17ds3Zped+3a9IVe2h/Q9RlotTRuHHzqU3D55fm+j0PBzGpCau/sLp3O21eVWhGV\nh6AiUnBt354CYseOdH/79vbDbmPHpvUvv5xaBYMHp9/z2WdTi6OyBfHUUymESq9X0nk/SSkkn3wy\nnTCQN4eCmVkn0p59ElI6FNXVBYsTJ3Z8/IY3dHx8xhl7/sxpp+1PhfnxGdBmZlaWayhIOlvSE5KW\nSrqii+cl6ars+UWSTs6zHjMz615uoSCpEfgecA5wLHChpGM7bXYOMCVbZgPfz6seMzPrWZ4thenA\n0oh4JiK2Az8BZnbaZiZwXSQPAM2SjsixJjMz60aeoTAWeLHi8bJs3d5uY2ZmNdIvOpolzZbUJqlt\n9erVRZdjZjZg5RkKLwHjKx6Py9bt7TZExDUR0RoRrS15XFVjZmZAvqHwEDBF0iRJBwGzgJs7bXMz\ncFF2FtKpwPqIWJ5jTWZm1o3cLl6LiJ2SPgHcBjQCP4yIxZIuyZ6/GrgFmAEsBbYAH+npdefNm/eK\npOf3oaRRwCv78HN5c117r6/W5rr2Tl+tC/pubftT11G92UhRGnFpgJPU1ptJq2vNde29vlqb69o7\nfbUu6Lu11aKuftHRbGZmteFQMDOzsnoKhWuKLqAK17X3+mptrmvv9NW6oO/WlntdddOnYGZmPaun\nloKZmfVgwIdCTyO11riW8ZLulvSYpMWSLsvWf0XSS5IWZEs307znVttzkh7J3r8tW3e4pDskPZXd\nHlbjmqZW7JMFkjZImlPE/pL0Q0mrJD1asa7q/pH0hewz94SkdxdQ2zckPZ6NPnyjpOZs/URJWyv2\n3dU1rqvq365W+6xKXT+tqOk5SQuy9bXcX9W+H2r7OYuIAbuQro94GpgMHAQsBI4tsJ4jgJOz+8OB\nJ0kjyH4F+EzB++o5YFSndf8IXJHdvwL4h4L/litI51rXfH8BbwdOBh7taf9kf9OFwGBgUvYZbKxx\nbe8CBmX3/6GitomV2xWwz7r829Vyn3VVV6fnvwV8uYD9Ve37oaafs4HeUujNSK01ExHLI2J+dn8j\nsIS+PQDgTODa7P61wJ8UWMuZwNMRsS8XLu63iLgPeLXT6mr7Zybwk4jYFhHPki7OnF7L2iLi9ojY\nmT18gDSETE1V2WfV1GyfdVeXJAHnAzfk8d7d6eb7oaafs4EeCn12FFZJE4FpwNxs1Sezpv4Pa32Y\nJhPAnZLmSZqdrRsT7cOOrADGFFBXySw6/kMten9B9f3T1z53FwO3VjyelB0KuVfS2wqop6u/XV/Z\nZ28DVkbEUxXrar6/On0/1PRzNtBDoU+SNAz4JTAnIjaQJheaDJwELCc1X2vtrRFxEmnio0slvb3y\nyUjt1UJOVVMaO+tc4OfZqr6wvzoocv90R9IXgZ3A9dmq5cCE7G99OfBjSYfWsKQ+97fr5EI6/uej\n5vuri++Hslp8zgZ6KPRqFNZaktRE+oNfHxG/AoiIlRGxKyJ2A/9GjocaqomIl7LbVcCNWQ0rlU16\nlN2uqnVdmXOA+RGxMqux8P2VqbZ/+sTnTtL/Bt4DfDD7MiE71LAmuz+PdBz6DVVf5ADr5m9X+D6T\nNAh4H/DT0rpa76+uvh+o8edsoIdCb0ZqrZnseOUPgCUR8e2K9ZWzzb0XeLTzz+Zc11BJw0v3SZ2U\nj5L21YezzT4M/Ect66rQ4X9vRe+vCtX2z83ALEmDJU0iTTf7YC0Lk3Q28Dng3IjYUrG+RWmqXCRN\nzmp7poZ1VfvbFb7PgLOAxyNiWWlFLfdXte8Hav05q0WvepELaRTWJ0kJ/8WCa3krqem3CFiQLTOA\nfwceydbfDBxR47omk85iWAgsLu0nYCRwF/AUcCdweAH7bCiwBhhRsa7m+4sUSsuBHaRjtx/tbv8A\nX8w+c08A5xRQ21LS8ebS5+zqbNs/zf7GC4D5wB/XuK6qf7ta7bOu6srW/wi4pNO2tdxf1b4favo5\n8xXNZmZWNtAPH5mZ2V5wKJiZWZlDwczMyhwKZmZW5lAwM7Myh4JZziSdIem/iq7DrDccCmZmVuZQ\nMMtI+jNJD2aDn/2rpEZJmyR9Jxvf/i5JLdm2J0l6QO3zFRyWrT9a0p2SFkqaL+n12csPk/QLpTkO\nrs+uXkXS17Px8xdJ+mZBv7pZmUPBDJB0DHABcHqkwc92AR8kXVHdFhHHAfcCf539yHXA5yPiBNIV\nuqX11wPfi4gTgdNIV85CGvFyDmkM/MnA6ZJGkoZ6OC57na/l+1ua9cyhYJacCfwv4KFs1q0zSV/e\nu2kfIO3/AW+VNAJojoh7s/XXAm/Pxo8aGxE3AkTEa9E+7tCDEbEs0kBwC0iTt6wHXgN+IOl9QHmM\nIrOiOBTMEgHXRsRJ2TI1Ir7SxXb7Oi7Mtor7u0izou0kjRL6C9Jopr/ex9c2O2AcCmbJXcB5kkZD\neV7co0j/Rs7LtvkA8NuIWA+srZhw5UPAvZFmy1om6U+y1xgs6ZBqb5iNmz8iIm4BPgWcmMcvZrY3\nBhVdgFlfEBGPSfor4HZJDaQRNC8FNgPTs+dWkfodIA1hfHX2pf8M8JFs/YeAf5X0t9lrvL+btx0O\n/Iekg0ktlcsP8K9lttc8SqpZNyRtiohhRddhVis+fGRmZmVuKZiZWZlbCmZmVuZQMDOzMoeCmZmV\nORTMzKzMoWBmZmUOBTMzK/v/C/C/MBeK4eoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c80bfb4400>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqvw30Gp9p1T8FnkAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c80d8c0630>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    " \n",
    "    \n",
    "    # the point where curve is smooth is overfitting\n",
    "val_loss=[]\n",
    "train_loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "np.random.seed(seed)\n",
    "num_of_epochs=200\n",
    "def model_define():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,activation='relu',input_shape=(4,)))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model\n",
    "\n",
    "skf=KFold(n_splits=10,shuffle=True, random_state=seed)\n",
    "skf.get_n_splits(X,encoded_Y)\n",
    "for train_index , test_index in skf.split(X, encoded_Y):\n",
    "    model=model_define()\n",
    "    history=model.fit(X[train_index],dummy_y[train_index],epochs=num_of_epochs,batch_size=5,verbose=1,\n",
    "                     validation_data=(X[test_index],dummy_y[test_index]))\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    train_loss.append(history.history['loss'])\n",
    "    acc.append(history.history['acc'])\n",
    "    val_acc.append(history.history['val_acc'])\n",
    "\n",
    "print('Accuracy is found to be {}'.format(np.mean(np.mean(val_acc,axis=0))))\n",
    "train_acc=np.mean(acc,axis=0)\n",
    "val_acc=np.mean(val_acc,axis=0)\n",
    "val_loss=np.mean(val_loss,axis=0)\n",
    "train_loss=np.mean(train_loss,axis=0)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1,num_of_epochs+1),val_loss,'b',label='val_loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"val loss\")\n",
    "plt.show()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1,num_of_epochs+1),val_acc,'b',label='val_acc')\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"val acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nkXoKBRERqff/AYaEjlv4MdL0AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c8059fbba8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1,num_of_epochs+1),train_acc,'b',label='train_acc')\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"train acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 51ms/step - loss: 1.2204 - acc: 0.3333 - val_loss: 1.2972 - val_acc: 0.3333\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1142 - acc: 0.4741 - val_loss: 1.2083 - val_acc: 0.4667\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0352 - acc: 0.6815 - val_loss: 1.1471 - val_acc: 0.4667\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9966 - acc: 0.6815 - val_loss: 1.1018 - val_acc: 0.4667\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9662 - acc: 0.6815 - val_loss: 1.0726 - val_acc: 0.4667\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9362 - acc: 0.6815 - val_loss: 1.0365 - val_acc: 0.4667\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9079 - acc: 0.6815 - val_loss: 1.0033 - val_acc: 0.4667\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8792 - acc: 0.6815 - val_loss: 0.9790 - val_acc: 0.5333\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8515 - acc: 0.6815 - val_loss: 0.9500 - val_acc: 0.5333\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8254 - acc: 0.6815 - val_loss: 0.9262 - val_acc: 0.5333\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7947 - acc: 0.6815 - val_loss: 0.8990 - val_acc: 0.5333\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7687 - acc: 0.6815 - val_loss: 0.8637 - val_acc: 0.5333\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7407 - acc: 0.6815 - val_loss: 0.8414 - val_acc: 0.5333\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7164 - acc: 0.6815 - val_loss: 0.8166 - val_acc: 0.5333\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6923 - acc: 0.6815 - val_loss: 0.7866 - val_acc: 0.5333\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6688 - acc: 0.6815 - val_loss: 0.7650 - val_acc: 0.5333\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6475 - acc: 0.6815 - val_loss: 0.7424 - val_acc: 0.5333\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6280 - acc: 0.6815 - val_loss: 0.7218 - val_acc: 0.5333\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6118 - acc: 0.6963 - val_loss: 0.6929 - val_acc: 0.6000\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5926 - acc: 0.6815 - val_loss: 0.6809 - val_acc: 0.5333\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5778 - acc: 0.6815 - val_loss: 0.6686 - val_acc: 0.5333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5635 - acc: 0.7111 - val_loss: 0.6411 - val_acc: 0.6000\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5498 - acc: 0.6963 - val_loss: 0.6395 - val_acc: 0.5333\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5386 - acc: 0.7185 - val_loss: 0.6095 - val_acc: 0.6667\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5259 - acc: 0.7111 - val_loss: 0.6084 - val_acc: 0.6000\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5135 - acc: 0.7185 - val_loss: 0.5925 - val_acc: 0.6000\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5038 - acc: 0.7259 - val_loss: 0.5768 - val_acc: 0.6667\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4950 - acc: 0.7630 - val_loss: 0.5694 - val_acc: 0.6667\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4872 - acc: 0.7407 - val_loss: 0.5674 - val_acc: 0.6000\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4776 - acc: 0.7704 - val_loss: 0.5450 - val_acc: 0.8000\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4716 - acc: 0.7556 - val_loss: 0.5412 - val_acc: 0.8000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4633 - acc: 0.7704 - val_loss: 0.5324 - val_acc: 0.8000\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4555 - acc: 0.7926 - val_loss: 0.5169 - val_acc: 0.8667\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4489 - acc: 0.8815 - val_loss: 0.5078 - val_acc: 0.8667\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4432 - acc: 0.7926 - val_loss: 0.5124 - val_acc: 0.8000\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4380 - acc: 0.8667 - val_loss: 0.4957 - val_acc: 0.8667\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4310 - acc: 0.8444 - val_loss: 0.5051 - val_acc: 0.8000\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4272 - acc: 0.8889 - val_loss: 0.4816 - val_acc: 0.8667\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4194 - acc: 0.8444 - val_loss: 0.4901 - val_acc: 0.8000\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4165 - acc: 0.8741 - val_loss: 0.4720 - val_acc: 0.8667\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4082 - acc: 0.8667 - val_loss: 0.4742 - val_acc: 0.8667\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4060 - acc: 0.8741 - val_loss: 0.4589 - val_acc: 0.8667\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3990 - acc: 0.8815 - val_loss: 0.4607 - val_acc: 0.8667\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3942 - acc: 0.8889 - val_loss: 0.4562 - val_acc: 0.8667\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3881 - acc: 0.9185 - val_loss: 0.4407 - val_acc: 0.9333\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3843 - acc: 0.9407 - val_loss: 0.4333 - val_acc: 0.9333\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3799 - acc: 0.9407 - val_loss: 0.4397 - val_acc: 0.8667\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3755 - acc: 0.9407 - val_loss: 0.4320 - val_acc: 0.8667\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3704 - acc: 0.9407 - val_loss: 0.4287 - val_acc: 0.8667\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3679 - acc: 0.9407 - val_loss: 0.4101 - val_acc: 0.9333\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3642 - acc: 0.9333 - val_loss: 0.4195 - val_acc: 0.9333\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3579 - acc: 0.9407 - val_loss: 0.4136 - val_acc: 0.9333\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3525 - acc: 0.9407 - val_loss: 0.4004 - val_acc: 0.9333\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3491 - acc: 0.9481 - val_loss: 0.3928 - val_acc: 0.9333\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3458 - acc: 0.9407 - val_loss: 0.3983 - val_acc: 0.9333\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3397 - acc: 0.9481 - val_loss: 0.3903 - val_acc: 0.9333\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.3333 - acc: 0.958 - 0s 2ms/step - loss: 0.3360 - acc: 0.9556 - val_loss: 0.3891 - val_acc: 0.9333\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3320 - acc: 0.9481 - val_loss: 0.3872 - val_acc: 0.9333\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3276 - acc: 0.9556 - val_loss: 0.3774 - val_acc: 0.9333\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3245 - acc: 0.9556 - val_loss: 0.3736 - val_acc: 0.9333\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3217 - acc: 0.9481 - val_loss: 0.3710 - val_acc: 0.9333\n",
      "Epoch 62/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3158 - acc: 0.9704 - val_loss: 0.3568 - val_acc: 0.9333\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3119 - acc: 0.9630 - val_loss: 0.3614 - val_acc: 0.9333\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3093 - acc: 0.9704 - val_loss: 0.3595 - val_acc: 0.9333\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3075 - acc: 0.9407 - val_loss: 0.3534 - val_acc: 0.9333\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3025 - acc: 0.9556 - val_loss: 0.3455 - val_acc: 0.9333\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2960 - acc: 0.9630 - val_loss: 0.3535 - val_acc: 0.9333\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2951 - acc: 0.9630 - val_loss: 0.3371 - val_acc: 0.9333\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2907 - acc: 0.9630 - val_loss: 0.3359 - val_acc: 0.9333\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2892 - acc: 0.9630 - val_loss: 0.3296 - val_acc: 0.9333\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2822 - acc: 0.9556 - val_loss: 0.3482 - val_acc: 0.9333\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2785 - acc: 0.9556 - val_loss: 0.3228 - val_acc: 0.9333\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2778 - acc: 0.9630 - val_loss: 0.3187 - val_acc: 0.9333\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2721 - acc: 0.9704 - val_loss: 0.3172 - val_acc: 0.9333\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2693 - acc: 0.9630 - val_loss: 0.3189 - val_acc: 0.9333\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2667 - acc: 0.9704 - val_loss: 0.3241 - val_acc: 0.9333\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2636 - acc: 0.9704 - val_loss: 0.3059 - val_acc: 0.9333\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2608 - acc: 0.9704 - val_loss: 0.3035 - val_acc: 0.9333\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2560 - acc: 0.9704 - val_loss: 0.3014 - val_acc: 0.9333\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2548 - acc: 0.9630 - val_loss: 0.3151 - val_acc: 0.9333\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2500 - acc: 0.9704 - val_loss: 0.2919 - val_acc: 0.9333\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2463 - acc: 0.9704 - val_loss: 0.2959 - val_acc: 0.9333\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2462 - acc: 0.9704 - val_loss: 0.3012 - val_acc: 0.9333\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2424 - acc: 0.9630 - val_loss: 0.2815 - val_acc: 0.9333\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2390 - acc: 0.9704 - val_loss: 0.2775 - val_acc: 1.0000\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2363 - acc: 0.9704 - val_loss: 0.2833 - val_acc: 0.9333\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2337 - acc: 0.9704 - val_loss: 0.2769 - val_acc: 0.9333\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2323 - acc: 0.9704 - val_loss: 0.2802 - val_acc: 0.9333\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2290 - acc: 0.9704 - val_loss: 0.2655 - val_acc: 1.0000\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2260 - acc: 0.9704 - val_loss: 0.2663 - val_acc: 0.9333\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 54ms/step - loss: 1.6593 - acc: 0.3111 - val_loss: 1.0892 - val_acc: 0.5333\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.3626 - acc: 0.3111 - val_loss: 0.9249 - val_acc: 0.5333\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1841 - acc: 0.3111 - val_loss: 0.8521 - val_acc: 0.5333\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0800 - acc: 0.3111 - val_loss: 0.8267 - val_acc: 0.5333\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0152 - acc: 0.3111 - val_loss: 0.8148 - val_acc: 0.5333\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9772 - acc: 0.3185 - val_loss: 0.8102 - val_acc: 0.5333\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9393 - acc: 0.3333 - val_loss: 0.8005 - val_acc: 0.5333\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9193 - acc: 0.3185 - val_loss: 0.7967 - val_acc: 0.5333\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8972 - acc: 0.4296 - val_loss: 0.7949 - val_acc: 0.6000\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8827 - acc: 0.5407 - val_loss: 0.7909 - val_acc: 0.6667\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8714 - acc: 0.6296 - val_loss: 0.7803 - val_acc: 0.6667\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8539 - acc: 0.6667 - val_loss: 0.7752 - val_acc: 0.6667\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8406 - acc: 0.6667 - val_loss: 0.7706 - val_acc: 0.6667\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8282 - acc: 0.6963 - val_loss: 0.7629 - val_acc: 0.6667\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8165 - acc: 0.6815 - val_loss: 0.7593 - val_acc: 0.6667\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8048 - acc: 0.6963 - val_loss: 0.7547 - val_acc: 0.6667\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7934 - acc: 0.6963 - val_loss: 0.7449 - val_acc: 0.6667\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7830 - acc: 0.7037 - val_loss: 0.7410 - val_acc: 0.6667\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7730 - acc: 0.7037 - val_loss: 0.7379 - val_acc: 0.6667\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7642 - acc: 0.6963 - val_loss: 0.7289 - val_acc: 0.6667\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7536 - acc: 0.6963 - val_loss: 0.7256 - val_acc: 0.7333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7438 - acc: 0.7037 - val_loss: 0.7205 - val_acc: 0.6667\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7368 - acc: 0.6963 - val_loss: 0.7142 - val_acc: 0.6667\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7259 - acc: 0.7185 - val_loss: 0.7143 - val_acc: 0.6667\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7176 - acc: 0.7333 - val_loss: 0.7077 - val_acc: 0.6667\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7064 - acc: 0.7333 - val_loss: 0.7003 - val_acc: 0.6667\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7006 - acc: 0.7037 - val_loss: 0.6964 - val_acc: 0.6667\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6928 - acc: 0.7556 - val_loss: 0.6971 - val_acc: 0.6667\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6815 - acc: 0.7259 - val_loss: 0.6891 - val_acc: 0.6667\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6764 - acc: 0.7185 - val_loss: 0.6870 - val_acc: 0.6667\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6664 - acc: 0.7185 - val_loss: 0.6782 - val_acc: 0.6667\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6560 - acc: 0.7185 - val_loss: 0.6777 - val_acc: 0.6667\n",
      "Epoch 33/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6501 - acc: 0.7185 - val_loss: 0.6705 - val_acc: 0.7333\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6413 - acc: 0.7556 - val_loss: 0.6706 - val_acc: 0.6667\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6326 - acc: 0.7259 - val_loss: 0.6652 - val_acc: 0.6667\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6249 - acc: 0.7333 - val_loss: 0.6577 - val_acc: 0.6667\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6162 - acc: 0.7556 - val_loss: 0.6572 - val_acc: 0.6667\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6106 - acc: 0.7407 - val_loss: 0.6540 - val_acc: 0.6667\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6009 - acc: 0.7407 - val_loss: 0.6462 - val_acc: 0.7333\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5940 - acc: 0.7333 - val_loss: 0.6436 - val_acc: 0.7333\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5832 - acc: 0.7778 - val_loss: 0.6449 - val_acc: 0.7333\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5822 - acc: 0.7704 - val_loss: 0.6498 - val_acc: 0.7333\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5678 - acc: 0.7704 - val_loss: 0.6312 - val_acc: 0.7333\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5612 - acc: 0.7704 - val_loss: 0.6277 - val_acc: 0.7333\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5540 - acc: 0.7852 - val_loss: 0.6266 - val_acc: 0.7333\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5478 - acc: 0.7630 - val_loss: 0.6207 - val_acc: 0.7333\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5409 - acc: 0.7407 - val_loss: 0.6146 - val_acc: 0.7333\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5322 - acc: 0.7926 - val_loss: 0.6206 - val_acc: 0.8000\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5262 - acc: 0.8148 - val_loss: 0.6186 - val_acc: 0.8000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5195 - acc: 0.8296 - val_loss: 0.6100 - val_acc: 0.7333\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5154 - acc: 0.7926 - val_loss: 0.6066 - val_acc: 0.8000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5064 - acc: 0.8148 - val_loss: 0.5967 - val_acc: 0.8000\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5002 - acc: 0.8074 - val_loss: 0.5928 - val_acc: 0.8000\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4942 - acc: 0.8148 - val_loss: 0.5914 - val_acc: 0.7333\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4899 - acc: 0.8296 - val_loss: 0.5884 - val_acc: 0.7333\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4848 - acc: 0.7852 - val_loss: 0.5813 - val_acc: 0.8000\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4776 - acc: 0.8444 - val_loss: 0.5853 - val_acc: 0.8000\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4725 - acc: 0.8370 - val_loss: 0.5840 - val_acc: 0.8000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4681 - acc: 0.8444 - val_loss: 0.5717 - val_acc: 0.8667\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4618 - acc: 0.8370 - val_loss: 0.5736 - val_acc: 0.8000\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4583 - acc: 0.8667 - val_loss: 0.5704 - val_acc: 0.8000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4541 - acc: 0.8593 - val_loss: 0.5623 - val_acc: 0.8000\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4481 - acc: 0.8519 - val_loss: 0.5619 - val_acc: 0.8000\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4441 - acc: 0.8593 - val_loss: 0.5580 - val_acc: 0.8000\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4418 - acc: 0.8370 - val_loss: 0.5577 - val_acc: 0.8000\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4381 - acc: 0.8667 - val_loss: 0.5456 - val_acc: 0.8667\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4326 - acc: 0.8741 - val_loss: 0.5568 - val_acc: 0.8000\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4286 - acc: 0.8741 - val_loss: 0.5475 - val_acc: 0.8000\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4241 - acc: 0.8593 - val_loss: 0.5452 - val_acc: 0.8000\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4190 - acc: 0.8815 - val_loss: 0.5400 - val_acc: 0.8000\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4177 - acc: 0.8963 - val_loss: 0.5379 - val_acc: 0.8000\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4129 - acc: 0.8667 - val_loss: 0.5314 - val_acc: 0.8667\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4097 - acc: 0.8815 - val_loss: 0.5345 - val_acc: 0.8000\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4053 - acc: 0.8815 - val_loss: 0.5275 - val_acc: 0.8000\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4025 - acc: 0.8963 - val_loss: 0.5195 - val_acc: 0.8667\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4036 - acc: 0.9185 - val_loss: 0.5370 - val_acc: 0.8667\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3963 - acc: 0.8815 - val_loss: 0.5094 - val_acc: 0.8667\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3912 - acc: 0.9111 - val_loss: 0.5171 - val_acc: 0.8000\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3894 - acc: 0.9333 - val_loss: 0.5123 - val_acc: 0.8667\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3855 - acc: 0.8741 - val_loss: 0.5048 - val_acc: 0.8667\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3810 - acc: 0.9259 - val_loss: 0.5062 - val_acc: 0.8667\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3787 - acc: 0.9407 - val_loss: 0.5032 - val_acc: 0.8667\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3755 - acc: 0.9407 - val_loss: 0.4951 - val_acc: 0.8667\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3728 - acc: 0.9556 - val_loss: 0.4996 - val_acc: 0.9333\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3689 - acc: 0.9481 - val_loss: 0.4942 - val_acc: 0.8667\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3657 - acc: 0.9333 - val_loss: 0.4905 - val_acc: 0.8667\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3683 - acc: 0.9407 - val_loss: 0.4929 - val_acc: 0.8667\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3592 - acc: 0.9333 - val_loss: 0.4761 - val_acc: 0.8667\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3575 - acc: 0.9185 - val_loss: 0.4875 - val_acc: 0.9333\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3538 - acc: 0.9704 - val_loss: 0.4850 - val_acc: 0.8667\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 50ms/step - loss: 3.6534 - acc: 0.3407 - val_loss: 3.6733 - val_acc: 0.2667\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.7373 - acc: 0.3407 - val_loss: 2.7485 - val_acc: 0.2667\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.9931 - acc: 0.4000 - val_loss: 1.8937 - val_acc: 0.5333\n",
      "Epoch 4/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 1.3757 - acc: 0.6741 - val_loss: 1.3055 - val_acc: 0.6000\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9750 - acc: 0.6741 - val_loss: 0.8997 - val_acc: 0.6000\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7457 - acc: 0.6741 - val_loss: 0.6894 - val_acc: 0.6000\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6492 - acc: 0.6667 - val_loss: 0.6018 - val_acc: 0.6667\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6042 - acc: 0.7556 - val_loss: 0.5687 - val_acc: 1.0000\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5751 - acc: 0.8889 - val_loss: 0.5339 - val_acc: 1.0000\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5534 - acc: 0.7852 - val_loss: 0.5088 - val_acc: 1.0000\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5337 - acc: 0.8519 - val_loss: 0.4936 - val_acc: 1.0000\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5180 - acc: 0.8741 - val_loss: 0.4793 - val_acc: 1.0000\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5047 - acc: 0.9037 - val_loss: 0.4660 - val_acc: 1.0000\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4869 - acc: 0.9185 - val_loss: 0.4493 - val_acc: 1.0000\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4736 - acc: 0.9259 - val_loss: 0.4384 - val_acc: 1.0000\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4640 - acc: 0.9556 - val_loss: 0.4362 - val_acc: 1.0000\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4499 - acc: 0.9333 - val_loss: 0.4122 - val_acc: 1.0000\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4387 - acc: 0.9481 - val_loss: 0.4080 - val_acc: 1.0000\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4287 - acc: 0.9259 - val_loss: 0.3917 - val_acc: 1.0000\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4178 - acc: 0.9556 - val_loss: 0.3911 - val_acc: 1.0000\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4076 - acc: 0.9556 - val_loss: 0.3678 - val_acc: 1.0000\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3990 - acc: 0.9259 - val_loss: 0.3679 - val_acc: 1.0000\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3890 - acc: 0.9556 - val_loss: 0.3572 - val_acc: 1.0000\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3784 - acc: 0.9630 - val_loss: 0.3557 - val_acc: 1.0000\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3714 - acc: 0.9630 - val_loss: 0.3377 - val_acc: 1.0000\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3634 - acc: 0.9630 - val_loss: 0.3382 - val_acc: 1.0000\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3554 - acc: 0.9704 - val_loss: 0.3276 - val_acc: 1.0000\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3499 - acc: 0.9481 - val_loss: 0.3175 - val_acc: 1.0000\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3419 - acc: 0.9556 - val_loss: 0.3069 - val_acc: 1.0000\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3329 - acc: 0.9704 - val_loss: 0.3039 - val_acc: 1.0000\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3312 - acc: 0.9630 - val_loss: 0.3123 - val_acc: 1.0000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3222 - acc: 0.9630 - val_loss: 0.2872 - val_acc: 1.0000\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3140 - acc: 0.9630 - val_loss: 0.2799 - val_acc: 1.0000\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.9704 - val_loss: 0.2848 - val_acc: 1.0000\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3000 - acc: 0.9704 - val_loss: 0.2719 - val_acc: 1.0000\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2969 - acc: 0.9630 - val_loss: 0.2656 - val_acc: 1.0000\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2890 - acc: 0.9778 - val_loss: 0.2550 - val_acc: 1.0000\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2834 - acc: 0.9704 - val_loss: 0.2511 - val_acc: 1.0000\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2802 - acc: 0.9630 - val_loss: 0.2576 - val_acc: 1.0000\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2735 - acc: 0.9778 - val_loss: 0.2413 - val_acc: 1.0000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2717 - acc: 0.9704 - val_loss: 0.2494 - val_acc: 1.0000\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2628 - acc: 0.9704 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2591 - acc: 0.9704 - val_loss: 0.2333 - val_acc: 1.0000\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2547 - acc: 0.9630 - val_loss: 0.2240 - val_acc: 1.0000\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2499 - acc: 0.9704 - val_loss: 0.2247 - val_acc: 1.0000\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2449 - acc: 0.9704 - val_loss: 0.2130 - val_acc: 1.0000\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2410 - acc: 0.9704 - val_loss: 0.2194 - val_acc: 1.0000\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.9704 - val_loss: 0.2067 - val_acc: 1.0000\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2314 - acc: 0.9704 - val_loss: 0.2099 - val_acc: 1.0000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2286 - acc: 0.9704 - val_loss: 0.2054 - val_acc: 1.0000\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2263 - acc: 0.9704 - val_loss: 0.1923 - val_acc: 1.0000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2204 - acc: 0.9778 - val_loss: 0.1965 - val_acc: 1.0000\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2165 - acc: 0.9778 - val_loss: 0.1928 - val_acc: 1.0000\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2151 - acc: 0.9630 - val_loss: 0.1885 - val_acc: 1.0000\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2089 - acc: 0.9778 - val_loss: 0.1751 - val_acc: 1.0000\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2061 - acc: 0.9778 - val_loss: 0.1794 - val_acc: 1.0000\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2043 - acc: 0.9778 - val_loss: 0.1834 - val_acc: 1.0000\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2012 - acc: 0.9704 - val_loss: 0.1701 - val_acc: 1.0000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1971 - acc: 0.9704 - val_loss: 0.1814 - val_acc: 1.0000\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1950 - acc: 0.9778 - val_loss: 0.1718 - val_acc: 1.0000\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1903 - acc: 0.9778 - val_loss: 0.1599 - val_acc: 1.0000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1876 - acc: 0.9778 - val_loss: 0.1638 - val_acc: 1.0000\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1863 - acc: 0.9704 - val_loss: 0.1566 - val_acc: 1.0000\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1857 - acc: 0.9704 - val_loss: 0.1610 - val_acc: 1.0000\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1800 - acc: 0.9778 - val_loss: 0.1519 - val_acc: 1.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1788 - acc: 0.9778 - val_loss: 0.1554 - val_acc: 1.0000\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1765 - acc: 0.9704 - val_loss: 0.1497 - val_acc: 1.0000\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1748 - acc: 0.9778 - val_loss: 0.1469 - val_acc: 1.0000\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1708 - acc: 0.9778 - val_loss: 0.1472 - val_acc: 1.0000\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1693 - acc: 0.9778 - val_loss: 0.1492 - val_acc: 1.0000\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1677 - acc: 0.9778 - val_loss: 0.1455 - val_acc: 1.0000\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1670 - acc: 0.9630 - val_loss: 0.1325 - val_acc: 1.0000\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1637 - acc: 0.9704 - val_loss: 0.1393 - val_acc: 1.0000\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1604 - acc: 0.9778 - val_loss: 0.1218 - val_acc: 1.0000\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1605 - acc: 0.9704 - val_loss: 0.1366 - val_acc: 1.0000\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1585 - acc: 0.9704 - val_loss: 0.1339 - val_acc: 1.0000\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1573 - acc: 0.9704 - val_loss: 0.1246 - val_acc: 1.0000\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1551 - acc: 0.9704 - val_loss: 0.1285 - val_acc: 1.0000\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1517 - acc: 0.9704 - val_loss: 0.1248 - val_acc: 1.0000\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1495 - acc: 0.9778 - val_loss: 0.1249 - val_acc: 1.0000\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1477 - acc: 0.9704 - val_loss: 0.1239 - val_acc: 1.0000\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1483 - acc: 0.9778 - val_loss: 0.1219 - val_acc: 1.0000\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1442 - acc: 0.9778 - val_loss: 0.1326 - val_acc: 1.0000\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1434 - acc: 0.9778 - val_loss: 0.1155 - val_acc: 1.0000\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1451 - acc: 0.9704 - val_loss: 0.1219 - val_acc: 1.0000\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1419 - acc: 0.9778 - val_loss: 0.1105 - val_acc: 1.0000\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1385 - acc: 0.9704 - val_loss: 0.1101 - val_acc: 1.0000\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1367 - acc: 0.9778 - val_loss: 0.1207 - val_acc: 1.0000\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1381 - acc: 0.9704 - val_loss: 0.1152 - val_acc: 1.0000\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1341 - acc: 0.9778 - val_loss: 0.1018 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 51ms/step - loss: 1.0612 - acc: 0.3259 - val_loss: 0.8961 - val_acc: 0.5333\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9593 - acc: 0.4741 - val_loss: 0.8530 - val_acc: 0.6667\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8937 - acc: 0.6519 - val_loss: 0.8025 - val_acc: 0.8667\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8461 - acc: 0.7037 - val_loss: 0.7677 - val_acc: 0.6667\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8126 - acc: 0.6815 - val_loss: 0.7397 - val_acc: 0.8000\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7817 - acc: 0.7333 - val_loss: 0.7090 - val_acc: 0.9333\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7519 - acc: 0.7481 - val_loss: 0.6759 - val_acc: 1.0000\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7223 - acc: 0.7926 - val_loss: 0.6450 - val_acc: 1.0000\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6931 - acc: 0.7778 - val_loss: 0.6190 - val_acc: 1.0000\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6688 - acc: 0.7704 - val_loss: 0.5898 - val_acc: 1.0000\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6417 - acc: 0.8222 - val_loss: 0.5616 - val_acc: 1.0000\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6184 - acc: 0.8296 - val_loss: 0.5383 - val_acc: 1.0000\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5956 - acc: 0.8370 - val_loss: 0.5123 - val_acc: 1.0000\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5753 - acc: 0.8444 - val_loss: 0.4906 - val_acc: 1.0000\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5572 - acc: 0.8667 - val_loss: 0.4728 - val_acc: 1.0000\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5391 - acc: 0.8370 - val_loss: 0.4524 - val_acc: 1.0000\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5238 - acc: 0.8667 - val_loss: 0.4320 - val_acc: 1.0000\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5076 - acc: 0.8593 - val_loss: 0.4167 - val_acc: 1.0000\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4951 - acc: 0.8593 - val_loss: 0.4006 - val_acc: 1.0000\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4825 - acc: 0.8593 - val_loss: 0.3807 - val_acc: 1.0000\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4689 - acc: 0.9333 - val_loss: 0.3692 - val_acc: 1.0000\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4561 - acc: 0.8667 - val_loss: 0.3565 - val_acc: 1.0000\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4471 - acc: 0.9037 - val_loss: 0.3433 - val_acc: 1.0000\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4331 - acc: 0.9037 - val_loss: 0.3254 - val_acc: 1.0000\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4223 - acc: 0.9259 - val_loss: 0.3196 - val_acc: 1.0000\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4115 - acc: 0.9259 - val_loss: 0.3051 - val_acc: 1.0000\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4034 - acc: 0.9333 - val_loss: 0.2961 - val_acc: 1.0000\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3930 - acc: 0.9333 - val_loss: 0.2853 - val_acc: 1.0000\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3838 - acc: 0.9259 - val_loss: 0.2756 - val_acc: 1.0000\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3749 - acc: 0.9481 - val_loss: 0.2648 - val_acc: 1.0000\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3696 - acc: 0.9333 - val_loss: 0.2588 - val_acc: 1.0000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3614 - acc: 0.9407 - val_loss: 0.2490 - val_acc: 1.0000\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3508 - acc: 0.9481 - val_loss: 0.2390 - val_acc: 1.0000\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3446 - acc: 0.9407 - val_loss: 0.2322 - val_acc: 1.0000\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3375 - acc: 0.9407 - val_loss: 0.2233 - val_acc: 1.0000\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3300 - acc: 0.9481 - val_loss: 0.2183 - val_acc: 1.0000\n",
      "Epoch 37/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3224 - acc: 0.9556 - val_loss: 0.2081 - val_acc: 1.0000\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3200 - acc: 0.9407 - val_loss: 0.2026 - val_acc: 1.0000\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3095 - acc: 0.9630 - val_loss: 0.1954 - val_acc: 1.0000\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3031 - acc: 0.9630 - val_loss: 0.1887 - val_acc: 1.0000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2968 - acc: 0.9630 - val_loss: 0.1832 - val_acc: 1.0000\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2913 - acc: 0.9630 - val_loss: 0.1768 - val_acc: 1.0000\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2864 - acc: 0.9630 - val_loss: 0.1714 - val_acc: 1.0000\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2794 - acc: 0.9556 - val_loss: 0.1658 - val_acc: 1.0000\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2803 - acc: 0.9481 - val_loss: 0.1626 - val_acc: 1.0000\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2746 - acc: 0.9556 - val_loss: 0.1556 - val_acc: 1.0000\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2675 - acc: 0.9630 - val_loss: 0.1516 - val_acc: 1.0000\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2596 - acc: 0.9704 - val_loss: 0.1483 - val_acc: 1.0000\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2547 - acc: 0.9704 - val_loss: 0.1434 - val_acc: 1.0000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2493 - acc: 0.9704 - val_loss: 0.1382 - val_acc: 1.0000\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2448 - acc: 0.9630 - val_loss: 0.1338 - val_acc: 1.0000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2425 - acc: 0.9630 - val_loss: 0.1320 - val_acc: 1.0000\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2369 - acc: 0.9630 - val_loss: 0.1261 - val_acc: 1.0000\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2320 - acc: 0.9704 - val_loss: 0.1227 - val_acc: 1.0000\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2308 - acc: 0.9630 - val_loss: 0.1200 - val_acc: 1.0000\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2347 - acc: 0.9481 - val_loss: 0.1160 - val_acc: 1.0000\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2220 - acc: 0.9630 - val_loss: 0.1132 - val_acc: 1.0000\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2178 - acc: 0.9704 - val_loss: 0.1091 - val_acc: 1.0000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2159 - acc: 0.9704 - val_loss: 0.1079 - val_acc: 1.0000\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2143 - acc: 0.960 - 0s 1ms/step - loss: 0.2147 - acc: 0.9630 - val_loss: 0.1032 - val_acc: 1.0000\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2107 - acc: 0.9704 - val_loss: 0.1007 - val_acc: 1.0000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2040 - acc: 0.9704 - val_loss: 0.0978 - val_acc: 1.0000\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2027 - acc: 0.9704 - val_loss: 0.0953 - val_acc: 1.0000\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1992 - acc: 0.9630 - val_loss: 0.0927 - val_acc: 1.0000\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1958 - acc: 0.9704 - val_loss: 0.0903 - val_acc: 1.0000\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1934 - acc: 0.9704 - val_loss: 0.0877 - val_acc: 1.0000\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1926 - acc: 0.9556 - val_loss: 0.0870 - val_acc: 1.0000\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1915 - acc: 0.9704 - val_loss: 0.0832 - val_acc: 1.0000\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1875 - acc: 0.9704 - val_loss: 0.0812 - val_acc: 1.0000\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1832 - acc: 0.9704 - val_loss: 0.0790 - val_acc: 1.0000\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1858 - acc: 0.9704 - val_loss: 0.0783 - val_acc: 1.0000\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1778 - acc: 0.9704 - val_loss: 0.0752 - val_acc: 1.0000\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1755 - acc: 0.9704 - val_loss: 0.0733 - val_acc: 1.0000\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1746 - acc: 0.9778 - val_loss: 0.0715 - val_acc: 1.0000\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1726 - acc: 0.9778 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1698 - acc: 0.9778 - val_loss: 0.0683 - val_acc: 1.0000\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1693 - acc: 0.9704 - val_loss: 0.0665 - val_acc: 1.0000\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1652 - acc: 0.9778 - val_loss: 0.0650 - val_acc: 1.0000\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1633 - acc: 0.9778 - val_loss: 0.0635 - val_acc: 1.0000\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1681 - acc: 0.9481 - val_loss: 0.0620 - val_acc: 1.0000\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1655 - acc: 0.9630 - val_loss: 0.0608 - val_acc: 1.0000\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1580 - acc: 0.9778 - val_loss: 0.0592 - val_acc: 1.0000\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1565 - acc: 0.9704 - val_loss: 0.0581 - val_acc: 1.0000\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1544 - acc: 0.9704 - val_loss: 0.0567 - val_acc: 1.0000\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1544 - acc: 0.9556 - val_loss: 0.0554 - val_acc: 1.0000\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.1561 - acc: 0.968 - 0s 1ms/step - loss: 0.1540 - acc: 0.9704 - val_loss: 0.0545 - val_acc: 1.0000\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1500 - acc: 0.9778 - val_loss: 0.0534 - val_acc: 1.0000\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1522 - acc: 0.9630 - val_loss: 0.0523 - val_acc: 1.0000\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1461 - acc: 0.9778 - val_loss: 0.0508 - val_acc: 1.0000\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1479 - acc: 0.9778 - val_loss: 0.0498 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 54ms/step - loss: 4.3683 - acc: 0.3259 - val_loss: 3.6641 - val_acc: 0.4000\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.5894 - acc: 0.3259 - val_loss: 3.0418 - val_acc: 0.4000\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 2.9646 - acc: 0.3259 - val_loss: 2.5302 - val_acc: 0.4000\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.4747 - acc: 0.3259 - val_loss: 2.1337 - val_acc: 0.4000\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.0959 - acc: 0.3259 - val_loss: 1.8599 - val_acc: 0.4000\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 1.8826 - acc: 0.307 - 0s 1ms/step - loss: 1.8387 - acc: 0.3259 - val_loss: 1.6560 - val_acc: 0.4000\n",
      "Epoch 7/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 1.6454 - acc: 0.3259 - val_loss: 1.5309 - val_acc: 0.4000\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.5216 - acc: 0.3259 - val_loss: 1.4199 - val_acc: 0.4000\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4136 - acc: 0.3259 - val_loss: 1.3516 - val_acc: 0.4000\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.3413 - acc: 0.2593 - val_loss: 1.2939 - val_acc: 0.2667\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2841 - acc: 0.0000e+00 - val_loss: 1.2524 - val_acc: 0.0000e+00\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2411 - acc: 0.0074 - val_loss: 1.2202 - val_acc: 0.0000e+00\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2112 - acc: 0.0741 - val_loss: 1.1984 - val_acc: 0.1333\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1895 - acc: 0.2222 - val_loss: 1.1848 - val_acc: 0.2000\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1759 - acc: 0.3333 - val_loss: 1.1740 - val_acc: 0.2667\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1672 - acc: 0.3259 - val_loss: 1.1658 - val_acc: 0.2667\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1569 - acc: 0.2667 - val_loss: 1.1619 - val_acc: 0.2667\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1520 - acc: 0.1704 - val_loss: 1.1590 - val_acc: 0.1333\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1488 - acc: 0.2222 - val_loss: 1.1571 - val_acc: 0.1333\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1428 - acc: 0.1704 - val_loss: 1.1512 - val_acc: 0.3333\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1391 - acc: 0.3333 - val_loss: 1.1484 - val_acc: 0.3333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1349 - acc: 0.3259 - val_loss: 1.1430 - val_acc: 0.3333\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1318 - acc: 0.3185 - val_loss: 1.1404 - val_acc: 0.3333\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1279 - acc: 0.3259 - val_loss: 1.1369 - val_acc: 0.3333\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1237 - acc: 0.3333 - val_loss: 1.1331 - val_acc: 0.3333\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1203 - acc: 0.3333 - val_loss: 1.1275 - val_acc: 0.3333\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1185 - acc: 0.3333 - val_loss: 1.1276 - val_acc: 0.3333\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1137 - acc: 0.3333 - val_loss: 1.1224 - val_acc: 0.3333\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1121 - acc: 0.3333 - val_loss: 1.1153 - val_acc: 0.3333\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1068 - acc: 0.3333 - val_loss: 1.1129 - val_acc: 0.3333\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.1018 - acc: 0.3333 - val_loss: 1.1091 - val_acc: 0.3333\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0986 - acc: 0.3333 - val_loss: 1.1067 - val_acc: 0.3333\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0959 - acc: 0.3333 - val_loss: 1.0992 - val_acc: 0.3333\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0915 - acc: 0.3333 - val_loss: 1.0957 - val_acc: 0.3333\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0861 - acc: 0.3333 - val_loss: 1.0892 - val_acc: 0.3333\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0816 - acc: 0.3333 - val_loss: 1.0864 - val_acc: 0.3333\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0787 - acc: 0.3333 - val_loss: 1.0827 - val_acc: 0.3333\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0731 - acc: 0.3333 - val_loss: 1.0731 - val_acc: 0.3333\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.0685 - acc: 0.3333 - val_loss: 1.0714 - val_acc: 0.3333\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0626 - acc: 0.3333 - val_loss: 1.0641 - val_acc: 0.3333\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0571 - acc: 0.3333 - val_loss: 1.0577 - val_acc: 0.3333\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0524 - acc: 0.3333 - val_loss: 1.0514 - val_acc: 0.3333\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0466 - acc: 0.3333 - val_loss: 1.0434 - val_acc: 0.3333\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0406 - acc: 0.3333 - val_loss: 1.0375 - val_acc: 0.3333\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0350 - acc: 0.3333 - val_loss: 1.0324 - val_acc: 0.3333\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0284 - acc: 0.3333 - val_loss: 1.0224 - val_acc: 0.3333\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0215 - acc: 0.3333 - val_loss: 1.0145 - val_acc: 0.3333\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0136 - acc: 0.3333 - val_loss: 1.0067 - val_acc: 0.4667\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0082 - acc: 0.3333 - val_loss: 1.0006 - val_acc: 0.3333\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9990 - acc: 0.4222 - val_loss: 0.9868 - val_acc: 0.4667\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9914 - acc: 0.5481 - val_loss: 0.9784 - val_acc: 0.4667\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9821 - acc: 0.4741 - val_loss: 0.9699 - val_acc: 0.5333\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9732 - acc: 0.5185 - val_loss: 0.9586 - val_acc: 0.7333\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9635 - acc: 0.6519 - val_loss: 0.9445 - val_acc: 0.7333\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9535 - acc: 0.6519 - val_loss: 0.9343 - val_acc: 0.7333\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9440 - acc: 0.6593 - val_loss: 0.9215 - val_acc: 0.7333\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9337 - acc: 0.6593 - val_loss: 0.9103 - val_acc: 0.7333\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9222 - acc: 0.6593 - val_loss: 0.8943 - val_acc: 0.7333\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9091 - acc: 0.6593 - val_loss: 0.8822 - val_acc: 0.7333\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8974 - acc: 0.6593 - val_loss: 0.8660 - val_acc: 0.7333\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 3ms/step - loss: 0.8848 - acc: 0.6593 - val_loss: 0.8526 - val_acc: 0.7333\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8720 - acc: 0.6593 - val_loss: 0.8380 - val_acc: 0.7333\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8602 - acc: 0.6593 - val_loss: 0.8216 - val_acc: 0.7333\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8454 - acc: 0.6593 - val_loss: 0.8058 - val_acc: 0.7333\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8326 - acc: 0.6593 - val_loss: 0.7919 - val_acc: 0.7333\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8187 - acc: 0.6593 - val_loss: 0.7754 - val_acc: 0.7333\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8038 - acc: 0.6593 - val_loss: 0.7596 - val_acc: 0.7333\n",
      "Epoch 68/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7909 - acc: 0.6667 - val_loss: 0.7419 - val_acc: 0.7333\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7790 - acc: 0.6593 - val_loss: 0.7231 - val_acc: 0.7333\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7614 - acc: 0.6667 - val_loss: 0.7100 - val_acc: 0.7333\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7489 - acc: 0.6741 - val_loss: 0.6965 - val_acc: 0.7333\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7347 - acc: 0.6741 - val_loss: 0.6799 - val_acc: 0.7333\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7209 - acc: 0.6741 - val_loss: 0.6655 - val_acc: 0.7333\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7069 - acc: 0.6741 - val_loss: 0.6509 - val_acc: 0.7333\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6932 - acc: 0.6963 - val_loss: 0.6346 - val_acc: 0.7333\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6808 - acc: 0.6963 - val_loss: 0.6188 - val_acc: 0.7333\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6685 - acc: 0.6963 - val_loss: 0.6088 - val_acc: 0.7333\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6549 - acc: 0.6963 - val_loss: 0.5949 - val_acc: 0.7333\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6439 - acc: 0.6963 - val_loss: 0.5807 - val_acc: 0.7333\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6318 - acc: 0.6963 - val_loss: 0.5690 - val_acc: 0.7333\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6216 - acc: 0.7259 - val_loss: 0.5579 - val_acc: 0.7333\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6095 - acc: 0.7111 - val_loss: 0.5461 - val_acc: 0.7333\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6004 - acc: 0.7704 - val_loss: 0.5365 - val_acc: 0.7333\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5893 - acc: 0.7407 - val_loss: 0.5239 - val_acc: 0.7333\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5799 - acc: 0.7111 - val_loss: 0.5135 - val_acc: 0.7333\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5694 - acc: 0.7185 - val_loss: 0.5056 - val_acc: 0.7333\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5625 - acc: 0.8370 - val_loss: 0.4987 - val_acc: 0.9333\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5531 - acc: 0.8000 - val_loss: 0.4879 - val_acc: 0.7333\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5445 - acc: 0.7852 - val_loss: 0.4788 - val_acc: 0.7333\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5358 - acc: 0.8444 - val_loss: 0.4722 - val_acc: 0.8667\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 8s 58ms/step - loss: 4.2140 - acc: 0.3333 - val_loss: 3.3495 - val_acc: 0.3333\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.3312 - acc: 0.3333 - val_loss: 2.5633 - val_acc: 0.3333\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.6636 - acc: 0.3481 - val_loss: 2.0266 - val_acc: 0.3333\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.1830 - acc: 0.4222 - val_loss: 1.6751 - val_acc: 0.6000\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.8122 - acc: 0.5704 - val_loss: 1.3864 - val_acc: 0.6667\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4730 - acc: 0.6000 - val_loss: 1.1252 - val_acc: 0.6667\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1733 - acc: 0.6074 - val_loss: 0.9018 - val_acc: 0.6667\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.9330 - acc: 0.6444 - val_loss: 0.7769 - val_acc: 0.7333\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.8111 - acc: 0.7259 - val_loss: 0.7190 - val_acc: 0.8000\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7510 - acc: 0.8222 - val_loss: 0.6913 - val_acc: 0.9333\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7167 - acc: 0.8444 - val_loss: 0.6624 - val_acc: 0.8667\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6907 - acc: 0.8444 - val_loss: 0.6318 - val_acc: 0.8667\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6687 - acc: 0.8222 - val_loss: 0.6201 - val_acc: 0.8667\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6395 - acc: 0.8444 - val_loss: 0.5873 - val_acc: 0.9333\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6213 - acc: 0.8444 - val_loss: 0.5640 - val_acc: 0.8667\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6009 - acc: 0.8593 - val_loss: 0.5474 - val_acc: 0.9333\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5855 - acc: 0.8370 - val_loss: 0.5337 - val_acc: 0.9333\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5666 - acc: 0.8593 - val_loss: 0.5116 - val_acc: 0.9333\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5542 - acc: 0.8370 - val_loss: 0.4992 - val_acc: 0.9333\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5396 - acc: 0.8519 - val_loss: 0.4921 - val_acc: 0.8667\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5264 - acc: 0.8593 - val_loss: 0.4704 - val_acc: 0.9333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5135 - acc: 0.8519 - val_loss: 0.4591 - val_acc: 1.0000\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5036 - acc: 0.8815 - val_loss: 0.4552 - val_acc: 0.9333\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4929 - acc: 0.8593 - val_loss: 0.4368 - val_acc: 1.0000\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4873 - acc: 0.8593 - val_loss: 0.4314 - val_acc: 1.0000\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4801 - acc: 0.8667 - val_loss: 0.4262 - val_acc: 0.9333\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4709 - acc: 0.8444 - val_loss: 0.4070 - val_acc: 0.9333\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4564 - acc: 0.8741 - val_loss: 0.4038 - val_acc: 1.0000\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4501 - acc: 0.8815 - val_loss: 0.3973 - val_acc: 1.0000\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4445 - acc: 0.8667 - val_loss: 0.3943 - val_acc: 1.0000\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4381 - acc: 0.8667 - val_loss: 0.3824 - val_acc: 1.0000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4348 - acc: 0.869 - 0s 1ms/step - loss: 0.4305 - acc: 0.8741 - val_loss: 0.3810 - val_acc: 1.0000\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4251 - acc: 0.8889 - val_loss: 0.3734 - val_acc: 1.0000\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4185 - acc: 0.8667 - val_loss: 0.3642 - val_acc: 1.0000\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4143 - acc: 0.8593 - val_loss: 0.3609 - val_acc: 1.0000\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4091 - acc: 0.8889 - val_loss: 0.3582 - val_acc: 1.0000\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4029 - acc: 0.8963 - val_loss: 0.3484 - val_acc: 1.0000\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3986 - acc: 0.8741 - val_loss: 0.3435 - val_acc: 1.0000\n",
      "Epoch 39/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - ETA: 0s - loss: 0.3788 - acc: 0.884 - 0s 1ms/step - loss: 0.3930 - acc: 0.8963 - val_loss: 0.3385 - val_acc: 1.0000\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3884 - acc: 0.8889 - val_loss: 0.3345 - val_acc: 1.0000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3836 - acc: 0.8815 - val_loss: 0.3332 - val_acc: 1.0000\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3815 - acc: 0.8667 - val_loss: 0.3234 - val_acc: 1.0000\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3767 - acc: 0.8963 - val_loss: 0.3207 - val_acc: 1.0000\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3709 - acc: 0.8963 - val_loss: 0.3222 - val_acc: 1.0000\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3708 - acc: 0.8741 - val_loss: 0.3103 - val_acc: 1.0000\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3676 - acc: 0.8815 - val_loss: 0.3076 - val_acc: 1.0000\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3631 - acc: 0.8963 - val_loss: 0.3089 - val_acc: 1.0000\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3595 - acc: 0.9111 - val_loss: 0.2976 - val_acc: 1.0000\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3553 - acc: 0.8889 - val_loss: 0.2960 - val_acc: 1.0000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3504 - acc: 0.9111 - val_loss: 0.2949 - val_acc: 1.0000\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3458 - acc: 0.9111 - val_loss: 0.2903 - val_acc: 1.0000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3444 - acc: 0.8963 - val_loss: 0.2881 - val_acc: 1.0000\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3419 - acc: 0.8963 - val_loss: 0.2841 - val_acc: 1.0000\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3402 - acc: 0.9111 - val_loss: 0.2806 - val_acc: 1.0000\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3413 - acc: 0.8963 - val_loss: 0.2737 - val_acc: 1.0000\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3293 - acc: 0.9185 - val_loss: 0.2757 - val_acc: 1.0000\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3260 - acc: 0.9185 - val_loss: 0.2702 - val_acc: 1.0000\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3242 - acc: 0.9037 - val_loss: 0.2618 - val_acc: 1.0000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3219 - acc: 0.9111 - val_loss: 0.2600 - val_acc: 1.0000\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3212 - acc: 0.9111 - val_loss: 0.2589 - val_acc: 1.0000\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3222 - acc: 0.9037 - val_loss: 0.2564 - val_acc: 1.0000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3094 - acc: 0.9111 - val_loss: 0.2483 - val_acc: 1.0000\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3108 - acc: 0.9259 - val_loss: 0.2475 - val_acc: 1.0000\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3075 - acc: 0.9185 - val_loss: 0.2450 - val_acc: 1.0000\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3060 - acc: 0.9185 - val_loss: 0.2383 - val_acc: 1.0000\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3022 - acc: 0.9111 - val_loss: 0.2403 - val_acc: 1.0000\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3020 - acc: 0.9259 - val_loss: 0.2393 - val_acc: 1.0000\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2947 - acc: 0.9259 - val_loss: 0.2344 - val_acc: 1.0000\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2916 - acc: 0.9333 - val_loss: 0.2280 - val_acc: 1.0000\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2914 - acc: 0.9333 - val_loss: 0.2281 - val_acc: 1.0000\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2867 - acc: 0.9333 - val_loss: 0.2236 - val_acc: 1.0000\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2841 - acc: 0.9259 - val_loss: 0.2194 - val_acc: 1.0000\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2836 - acc: 0.9259 - val_loss: 0.2195 - val_acc: 1.0000\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2799 - acc: 0.9185 - val_loss: 0.2202 - val_acc: 1.0000\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2760 - acc: 0.9333 - val_loss: 0.2127 - val_acc: 1.0000\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2779 - acc: 0.9185 - val_loss: 0.2108 - val_acc: 1.0000\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2726 - acc: 0.9333 - val_loss: 0.2104 - val_acc: 1.0000\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2701 - acc: 0.9259 - val_loss: 0.2077 - val_acc: 1.0000\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2663 - acc: 0.9259 - val_loss: 0.2002 - val_acc: 1.0000\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2653 - acc: 0.9259 - val_loss: 0.1992 - val_acc: 1.0000\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2628 - acc: 0.9333 - val_loss: 0.1976 - val_acc: 1.0000\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2597 - acc: 0.9333 - val_loss: 0.1924 - val_acc: 1.0000\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2567 - acc: 0.9333 - val_loss: 0.1917 - val_acc: 1.0000\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2582 - acc: 0.9481 - val_loss: 0.1888 - val_acc: 1.0000\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2595 - acc: 0.9407 - val_loss: 0.1843 - val_acc: 1.0000\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2518 - acc: 0.9407 - val_loss: 0.1847 - val_acc: 1.0000\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2481 - acc: 0.9407 - val_loss: 0.1825 - val_acc: 1.0000\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2471 - acc: 0.9407 - val_loss: 0.1782 - val_acc: 1.0000\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2459 - acc: 0.9333 - val_loss: 0.1772 - val_acc: 1.0000\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2421 - acc: 0.9333 - val_loss: 0.1729 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 51ms/step - loss: 4.1172 - acc: 0.3259 - val_loss: 3.0338 - val_acc: 0.4000\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.7580 - acc: 0.3259 - val_loss: 1.9010 - val_acc: 0.4000\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 1.5838 - acc: 0.3259 - val_loss: 1.1321 - val_acc: 0.4000\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0526 - acc: 0.4222 - val_loss: 0.8922 - val_acc: 0.4667\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9184 - acc: 0.5556 - val_loss: 0.8086 - val_acc: 0.5333\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8476 - acc: 0.5778 - val_loss: 0.7433 - val_acc: 0.5333\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7929 - acc: 0.6000 - val_loss: 0.6887 - val_acc: 0.6667\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7469 - acc: 0.6074 - val_loss: 0.6422 - val_acc: 0.7333\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7080 - acc: 0.5926 - val_loss: 0.6069 - val_acc: 0.7333\n",
      "Epoch 10/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6766 - acc: 0.5926 - val_loss: 0.5711 - val_acc: 0.7333\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6496 - acc: 0.6296 - val_loss: 0.5439 - val_acc: 0.7333\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6247 - acc: 0.6519 - val_loss: 0.5149 - val_acc: 0.8000\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6027 - acc: 0.6667 - val_loss: 0.4957 - val_acc: 0.8000\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5857 - acc: 0.6963 - val_loss: 0.4740 - val_acc: 0.8667\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5666 - acc: 0.7185 - val_loss: 0.4523 - val_acc: 0.8000\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5497 - acc: 0.7185 - val_loss: 0.4351 - val_acc: 0.8667\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5332 - acc: 0.7333 - val_loss: 0.4190 - val_acc: 0.8667\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5194 - acc: 0.7407 - val_loss: 0.4008 - val_acc: 0.8667\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5086 - acc: 0.7630 - val_loss: 0.3900 - val_acc: 0.8667\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4950 - acc: 0.7778 - val_loss: 0.3761 - val_acc: 1.0000\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4874 - acc: 0.7778 - val_loss: 0.3622 - val_acc: 0.9333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4705 - acc: 0.8222 - val_loss: 0.3486 - val_acc: 1.0000\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4616 - acc: 0.8296 - val_loss: 0.3381 - val_acc: 1.0000\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4502 - acc: 0.8444 - val_loss: 0.3271 - val_acc: 1.0000\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4458 - acc: 0.8296 - val_loss: 0.3158 - val_acc: 1.0000\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4315 - acc: 0.8593 - val_loss: 0.3077 - val_acc: 1.0000\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4247 - acc: 0.8519 - val_loss: 0.2983 - val_acc: 1.0000\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4151 - acc: 0.8519 - val_loss: 0.2872 - val_acc: 1.0000\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4074 - acc: 0.8741 - val_loss: 0.2769 - val_acc: 1.0000\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3989 - acc: 0.8519 - val_loss: 0.2683 - val_acc: 1.0000\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3906 - acc: 0.8593 - val_loss: 0.2579 - val_acc: 1.0000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3858 - acc: 0.8963 - val_loss: 0.2496 - val_acc: 1.0000\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3777 - acc: 0.8667 - val_loss: 0.2440 - val_acc: 1.0000\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3695 - acc: 0.9037 - val_loss: 0.2353 - val_acc: 1.0000\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3623 - acc: 0.8667 - val_loss: 0.2257 - val_acc: 1.0000\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3571 - acc: 0.8889 - val_loss: 0.2189 - val_acc: 1.0000\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3514 - acc: 0.9037 - val_loss: 0.2134 - val_acc: 1.0000\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3411 - acc: 0.8889 - val_loss: 0.2051 - val_acc: 1.0000\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3399 - acc: 0.8815 - val_loss: 0.1991 - val_acc: 1.0000\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3318 - acc: 0.9111 - val_loss: 0.1926 - val_acc: 1.0000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3295 - acc: 0.8963 - val_loss: 0.1878 - val_acc: 1.0000\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3213 - acc: 0.8963 - val_loss: 0.1809 - val_acc: 1.0000\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3124 - acc: 0.9037 - val_loss: 0.1748 - val_acc: 1.0000\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2919 - acc: 0.918 - 0s 2ms/step - loss: 0.3091 - acc: 0.9259 - val_loss: 0.1720 - val_acc: 1.0000\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3042 - acc: 0.9185 - val_loss: 0.1651 - val_acc: 1.0000\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2977 - acc: 0.9037 - val_loss: 0.1594 - val_acc: 1.0000\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2936 - acc: 0.9259 - val_loss: 0.1548 - val_acc: 1.0000\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2970 - acc: 0.9111 - val_loss: 0.1494 - val_acc: 1.0000\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2915 - acc: 0.9407 - val_loss: 0.1454 - val_acc: 1.0000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2803 - acc: 0.9185 - val_loss: 0.1407 - val_acc: 1.0000\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2757 - acc: 0.9407 - val_loss: 0.1394 - val_acc: 1.0000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2708 - acc: 0.9407 - val_loss: 0.1324 - val_acc: 1.0000\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2668 - acc: 0.9407 - val_loss: 0.1298 - val_acc: 1.0000\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2617 - acc: 0.9259 - val_loss: 0.1253 - val_acc: 1.0000\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2541 - acc: 0.923 - 0s 1ms/step - loss: 0.2609 - acc: 0.9185 - val_loss: 0.1206 - val_acc: 1.0000\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2553 - acc: 0.9259 - val_loss: 0.1184 - val_acc: 1.0000\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2531 - acc: 0.9333 - val_loss: 0.1134 - val_acc: 1.0000\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2482 - acc: 0.9407 - val_loss: 0.1097 - val_acc: 1.0000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.9407 - val_loss: 0.1084 - val_acc: 1.0000\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2397 - acc: 0.9333 - val_loss: 0.1035 - val_acc: 1.0000\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2356 - acc: 0.9407 - val_loss: 0.1019 - val_acc: 1.0000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2355 - acc: 0.9333 - val_loss: 0.0988 - val_acc: 1.0000\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2306 - acc: 0.9333 - val_loss: 0.0942 - val_acc: 1.0000\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2257 - acc: 0.9481 - val_loss: 0.0928 - val_acc: 1.0000\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2240 - acc: 0.9481 - val_loss: 0.0907 - val_acc: 1.0000\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2291 - acc: 0.9333 - val_loss: 0.0879 - val_acc: 1.0000\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2235 - acc: 0.9556 - val_loss: 0.0866 - val_acc: 1.0000\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2165 - acc: 0.9481 - val_loss: 0.0829 - val_acc: 1.0000\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2183 - acc: 0.9333 - val_loss: 0.0805 - val_acc: 1.0000\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2144 - acc: 0.9556 - val_loss: 0.0810 - val_acc: 1.0000\n",
      "Epoch 71/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2082 - acc: 0.9407 - val_loss: 0.0761 - val_acc: 1.0000\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2059 - acc: 0.9481 - val_loss: 0.0741 - val_acc: 1.0000\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2051 - acc: 0.9556 - val_loss: 0.0732 - val_acc: 1.0000\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2008 - acc: 0.9481 - val_loss: 0.0705 - val_acc: 1.0000\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2008 - acc: 0.9333 - val_loss: 0.0690 - val_acc: 1.0000\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1953 - acc: 0.9481 - val_loss: 0.0675 - val_acc: 1.0000\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1944 - acc: 0.9481 - val_loss: 0.0646 - val_acc: 1.0000\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1907 - acc: 0.9481 - val_loss: 0.0634 - val_acc: 1.0000\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1952 - acc: 0.9407 - val_loss: 0.0630 - val_acc: 1.0000\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1908 - acc: 0.9630 - val_loss: 0.0605 - val_acc: 1.0000\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1866 - acc: 0.9481 - val_loss: 0.0584 - val_acc: 1.0000\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1857 - acc: 0.9556 - val_loss: 0.0570 - val_acc: 1.0000\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1808 - acc: 0.9481 - val_loss: 0.0563 - val_acc: 1.0000\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1808 - acc: 0.9481 - val_loss: 0.0540 - val_acc: 1.0000\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1768 - acc: 0.9481 - val_loss: 0.0530 - val_acc: 1.0000\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1782 - acc: 0.9556 - val_loss: 0.0509 - val_acc: 1.0000\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1754 - acc: 0.9481 - val_loss: 0.0510 - val_acc: 1.0000\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1744 - acc: 0.9481 - val_loss: 0.0491 - val_acc: 1.0000\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1710 - acc: 0.9481 - val_loss: 0.0483 - val_acc: 1.0000\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1719 - acc: 0.9556 - val_loss: 0.0479 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 8s 56ms/step - loss: 4.4866 - acc: 0.3333 - val_loss: 3.7932 - val_acc: 0.3333\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 3.3866 - acc: 0.3333 - val_loss: 2.7187 - val_acc: 0.3333\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 2.3773 - acc: 0.3333 - val_loss: 1.7771 - val_acc: 0.3333\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.6226 - acc: 0.3111 - val_loss: 1.3529 - val_acc: 0.2000\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.4060 - acc: 0.1037 - val_loss: 1.2287 - val_acc: 0.2000\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2962 - acc: 0.0593 - val_loss: 1.1473 - val_acc: 0.1333\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.2238 - acc: 0.1111 - val_loss: 1.0782 - val_acc: 0.2000\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.1458 - acc: 0.0741 - val_loss: 1.0203 - val_acc: 0.2000\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0853 - acc: 0.0741 - val_loss: 0.9737 - val_acc: 0.2000\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0381 - acc: 0.0815 - val_loss: 0.9307 - val_acc: 0.2000\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9926 - acc: 0.0815 - val_loss: 0.8916 - val_acc: 0.2667\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9535 - acc: 0.0963 - val_loss: 0.8589 - val_acc: 0.2667\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9178 - acc: 0.2074 - val_loss: 0.8288 - val_acc: 0.4667\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8882 - acc: 0.4222 - val_loss: 0.8012 - val_acc: 0.6000\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8598 - acc: 0.4815 - val_loss: 0.7752 - val_acc: 0.6667\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8300 - acc: 0.4667 - val_loss: 0.7502 - val_acc: 0.6667\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8026 - acc: 0.4889 - val_loss: 0.7280 - val_acc: 0.6000\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7820 - acc: 0.5333 - val_loss: 0.7093 - val_acc: 0.7333\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7583 - acc: 0.5407 - val_loss: 0.6898 - val_acc: 0.7333\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7372 - acc: 0.5333 - val_loss: 0.6714 - val_acc: 0.6667\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7180 - acc: 0.5704 - val_loss: 0.6556 - val_acc: 0.7333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7041 - acc: 0.6148 - val_loss: 0.6405 - val_acc: 0.7333\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6818 - acc: 0.5852 - val_loss: 0.6260 - val_acc: 0.8000\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6683 - acc: 0.6074 - val_loss: 0.6129 - val_acc: 0.8000\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6547 - acc: 0.6148 - val_loss: 0.6009 - val_acc: 0.7333\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6415 - acc: 0.6370 - val_loss: 0.5918 - val_acc: 0.7333\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6282 - acc: 0.6741 - val_loss: 0.5788 - val_acc: 0.7333\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6164 - acc: 0.6593 - val_loss: 0.5698 - val_acc: 0.7333\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6085 - acc: 0.6593 - val_loss: 0.5587 - val_acc: 0.8000\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5937 - acc: 0.7037 - val_loss: 0.5499 - val_acc: 0.7333\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5841 - acc: 0.7111 - val_loss: 0.5411 - val_acc: 0.8000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5744 - acc: 0.7481 - val_loss: 0.5338 - val_acc: 0.7333\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5700 - acc: 0.7185 - val_loss: 0.5251 - val_acc: 0.8667\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5582 - acc: 0.7259 - val_loss: 0.5184 - val_acc: 0.7333\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5483 - acc: 0.7704 - val_loss: 0.5122 - val_acc: 0.7333\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5404 - acc: 0.7556 - val_loss: 0.5055 - val_acc: 0.7333\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5304 - acc: 0.7926 - val_loss: 0.4981 - val_acc: 0.8000\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5231 - acc: 0.8074 - val_loss: 0.4921 - val_acc: 0.8000\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5174 - acc: 0.8000 - val_loss: 0.4862 - val_acc: 0.8667\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5097 - acc: 0.7926 - val_loss: 0.4803 - val_acc: 0.8000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5041 - acc: 0.8444 - val_loss: 0.4753 - val_acc: 0.8667\n",
      "Epoch 42/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4963 - acc: 0.8222 - val_loss: 0.4729 - val_acc: 0.7333\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4935 - acc: 0.8296 - val_loss: 0.4647 - val_acc: 0.8667\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4857 - acc: 0.7852 - val_loss: 0.4613 - val_acc: 0.7333\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4774 - acc: 0.8519 - val_loss: 0.4549 - val_acc: 0.8667\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4724 - acc: 0.8296 - val_loss: 0.4500 - val_acc: 0.8667\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4664 - acc: 0.8741 - val_loss: 0.4470 - val_acc: 0.8667\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4622 - acc: 0.8889 - val_loss: 0.4423 - val_acc: 0.8667\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4591 - acc: 0.8370 - val_loss: 0.4413 - val_acc: 0.7333\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4508 - acc: 0.8370 - val_loss: 0.4340 - val_acc: 0.8667\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4447 - acc: 0.9407 - val_loss: 0.4285 - val_acc: 0.9333\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4408 - acc: 0.9037 - val_loss: 0.4265 - val_acc: 0.8667\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4357 - acc: 0.9185 - val_loss: 0.4203 - val_acc: 0.9333\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4318 - acc: 0.9111 - val_loss: 0.4189 - val_acc: 0.8667\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4265 - acc: 0.9407 - val_loss: 0.4143 - val_acc: 0.8667\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4268 - acc: 0.8593 - val_loss: 0.4096 - val_acc: 0.9333\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4171 - acc: 0.9185 - val_loss: 0.4071 - val_acc: 0.8667\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4138 - acc: 0.9259 - val_loss: 0.4028 - val_acc: 0.9333\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4128 - acc: 0.9556 - val_loss: 0.4002 - val_acc: 0.8667\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4091 - acc: 0.8370 - val_loss: 0.4009 - val_acc: 0.8667\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4050 - acc: 0.9481 - val_loss: 0.3926 - val_acc: 0.9333\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3968 - acc: 0.9407 - val_loss: 0.3905 - val_acc: 0.9333\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3923 - acc: 0.9259 - val_loss: 0.3899 - val_acc: 0.8667\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3894 - acc: 0.9185 - val_loss: 0.3828 - val_acc: 0.9333\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3900 - acc: 0.9333 - val_loss: 0.3802 - val_acc: 0.9333\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3785 - acc: 0.9481 - val_loss: 0.3818 - val_acc: 0.8667\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3763 - acc: 0.9407 - val_loss: 0.3776 - val_acc: 0.8667\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3734 - acc: 0.9407 - val_loss: 0.3707 - val_acc: 0.9333\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3696 - acc: 0.9630 - val_loss: 0.3708 - val_acc: 0.9333\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3652 - acc: 0.9481 - val_loss: 0.3651 - val_acc: 0.9333\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3619 - acc: 0.9556 - val_loss: 0.3622 - val_acc: 0.9333\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3605 - acc: 0.9407 - val_loss: 0.3668 - val_acc: 0.8667\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3569 - acc: 0.9630 - val_loss: 0.3589 - val_acc: 0.9333\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3526 - acc: 0.9630 - val_loss: 0.3585 - val_acc: 0.9333\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3483 - acc: 0.9630 - val_loss: 0.3537 - val_acc: 0.9333\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3453 - acc: 0.9704 - val_loss: 0.3490 - val_acc: 0.9333\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3423 - acc: 0.9481 - val_loss: 0.3507 - val_acc: 0.9333\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3368 - acc: 0.9481 - val_loss: 0.3456 - val_acc: 0.9333\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3350 - acc: 0.9778 - val_loss: 0.3446 - val_acc: 0.9333\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3312 - acc: 0.9630 - val_loss: 0.3403 - val_acc: 0.9333\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3321 - acc: 0.9630 - val_loss: 0.3350 - val_acc: 0.9333\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3244 - acc: 0.9704 - val_loss: 0.3367 - val_acc: 0.9333\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3233 - acc: 0.9778 - val_loss: 0.3312 - val_acc: 0.9333\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3183 - acc: 0.9556 - val_loss: 0.3332 - val_acc: 0.9333\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3189 - acc: 0.9926 - val_loss: 0.3305 - val_acc: 0.9333\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3166 - acc: 0.9481 - val_loss: 0.3260 - val_acc: 0.9333\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3137 - acc: 0.9630 - val_loss: 0.3242 - val_acc: 0.9333\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3070 - acc: 0.9704 - val_loss: 0.3214 - val_acc: 0.9333\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3049 - acc: 0.9630 - val_loss: 0.3214 - val_acc: 0.9333\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2885 - acc: 0.976 - 0s 1ms/step - loss: 0.2998 - acc: 0.9704 - val_loss: 0.3146 - val_acc: 0.9333\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 7s 51ms/step - loss: 1.1457 - acc: 0.6741 - val_loss: 1.2953 - val_acc: 0.5333\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0280 - acc: 0.6815 - val_loss: 1.1340 - val_acc: 0.5333\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.9089 - acc: 0.6815 - val_loss: 0.9955 - val_acc: 0.5333\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8090 - acc: 0.6815 - val_loss: 0.8746 - val_acc: 0.5333\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.7336 - acc: 0.6815 - val_loss: 0.7895 - val_acc: 0.5333\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6762 - acc: 0.6815 - val_loss: 0.7201 - val_acc: 0.5333\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6342 - acc: 0.6963 - val_loss: 0.6614 - val_acc: 0.6000\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6011 - acc: 0.7111 - val_loss: 0.6341 - val_acc: 0.6000\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5797 - acc: 0.7481 - val_loss: 0.6087 - val_acc: 0.7333\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5603 - acc: 0.7333 - val_loss: 0.6027 - val_acc: 0.6000\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5456 - acc: 0.7111 - val_loss: 0.5885 - val_acc: 0.6000\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5319 - acc: 0.7185 - val_loss: 0.5768 - val_acc: 0.6000\n",
      "Epoch 13/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5198 - acc: 0.7704 - val_loss: 0.5551 - val_acc: 0.7333\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5083 - acc: 0.8074 - val_loss: 0.5412 - val_acc: 0.7333\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4980 - acc: 0.7481 - val_loss: 0.5370 - val_acc: 0.7333\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4874 - acc: 0.8222 - val_loss: 0.5229 - val_acc: 0.7333\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4825 - acc: 0.8593 - val_loss: 0.5040 - val_acc: 0.8667\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4693 - acc: 0.8148 - val_loss: 0.5079 - val_acc: 0.7333\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4639 - acc: 0.8148 - val_loss: 0.4924 - val_acc: 0.8667\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4552 - acc: 0.8667 - val_loss: 0.4872 - val_acc: 0.8667\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4489 - acc: 0.7926 - val_loss: 0.4809 - val_acc: 0.8667\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.4365 - acc: 0.883 - 0s 1ms/step - loss: 0.4411 - acc: 0.8889 - val_loss: 0.4696 - val_acc: 0.8667\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4339 - acc: 0.8889 - val_loss: 0.4614 - val_acc: 0.8667\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4281 - acc: 0.9037 - val_loss: 0.4528 - val_acc: 0.8667\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4220 - acc: 0.9037 - val_loss: 0.4426 - val_acc: 0.9333\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4152 - acc: 0.9111 - val_loss: 0.4428 - val_acc: 0.8667\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4104 - acc: 0.8815 - val_loss: 0.4373 - val_acc: 0.8667\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4048 - acc: 0.9037 - val_loss: 0.4260 - val_acc: 0.9333\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3987 - acc: 0.9259 - val_loss: 0.4192 - val_acc: 0.9333\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3935 - acc: 0.9111 - val_loss: 0.4144 - val_acc: 0.9333\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3889 - acc: 0.9259 - val_loss: 0.4078 - val_acc: 0.9333\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3839 - acc: 0.9333 - val_loss: 0.4016 - val_acc: 0.9333\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3781 - acc: 0.9185 - val_loss: 0.3992 - val_acc: 0.9333\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3736 - acc: 0.9407 - val_loss: 0.3939 - val_acc: 0.9333\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3688 - acc: 0.9185 - val_loss: 0.3944 - val_acc: 0.9333\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3644 - acc: 0.9481 - val_loss: 0.3755 - val_acc: 1.0000\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3605 - acc: 0.9481 - val_loss: 0.3864 - val_acc: 0.9333\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3563 - acc: 0.9481 - val_loss: 0.3702 - val_acc: 0.9333\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3504 - acc: 0.9556 - val_loss: 0.3722 - val_acc: 0.9333\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3453 - acc: 0.9556 - val_loss: 0.3604 - val_acc: 1.0000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3399 - acc: 0.9630 - val_loss: 0.3585 - val_acc: 0.9333\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3372 - acc: 0.9481 - val_loss: 0.3549 - val_acc: 0.9333\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3334 - acc: 0.9704 - val_loss: 0.3453 - val_acc: 1.0000\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3277 - acc: 0.9630 - val_loss: 0.3386 - val_acc: 1.0000\n",
      "Epoch 45/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3235 - acc: 0.9630 - val_loss: 0.3368 - val_acc: 1.0000\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3186 - acc: 0.9630 - val_loss: 0.3353 - val_acc: 1.0000\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3231 - acc: 0.9259 - val_loss: 0.3347 - val_acc: 0.9333\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3129 - acc: 0.9556 - val_loss: 0.3203 - val_acc: 1.0000\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3071 - acc: 0.9704 - val_loss: 0.3207 - val_acc: 1.0000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3033 - acc: 0.9630 - val_loss: 0.3185 - val_acc: 1.0000\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2991 - acc: 0.9630 - val_loss: 0.3110 - val_acc: 1.0000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2954 - acc: 0.9630 - val_loss: 0.3054 - val_acc: 1.0000\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2919 - acc: 0.9630 - val_loss: 0.3044 - val_acc: 1.0000\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2893 - acc: 0.9556 - val_loss: 0.3001 - val_acc: 1.0000\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2840 - acc: 0.9630 - val_loss: 0.2955 - val_acc: 1.0000\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2803 - acc: 0.9630 - val_loss: 0.2927 - val_acc: 1.0000\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2775 - acc: 0.9556 - val_loss: 0.2828 - val_acc: 1.0000\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2737 - acc: 0.9630 - val_loss: 0.2853 - val_acc: 1.0000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2728 - acc: 0.9630 - val_loss: 0.2833 - val_acc: 1.0000\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2670 - acc: 0.9630 - val_loss: 0.2774 - val_acc: 1.0000\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2635 - acc: 0.9704 - val_loss: 0.2706 - val_acc: 1.0000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2605 - acc: 0.9556 - val_loss: 0.2740 - val_acc: 1.0000\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2571 - acc: 0.9630 - val_loss: 0.2664 - val_acc: 1.0000\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2520 - acc: 0.9704 - val_loss: 0.2639 - val_acc: 1.0000\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2489 - acc: 0.9630 - val_loss: 0.2583 - val_acc: 1.0000\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2459 - acc: 0.965 - 0s 2ms/step - loss: 0.2470 - acc: 0.9704 - val_loss: 0.2580 - val_acc: 1.0000\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2436 - acc: 0.9630 - val_loss: 0.2494 - val_acc: 1.0000\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2400 - acc: 0.9778 - val_loss: 0.2493 - val_acc: 1.0000\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2367 - acc: 0.9704 - val_loss: 0.2471 - val_acc: 1.0000\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2344 - acc: 0.9630 - val_loss: 0.2478 - val_acc: 1.0000\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2315 - acc: 0.9630 - val_loss: 0.2393 - val_acc: 1.0000\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2282 - acc: 0.9778 - val_loss: 0.2370 - val_acc: 1.0000\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2253 - acc: 0.9704 - val_loss: 0.2335 - val_acc: 1.0000\n",
      "Epoch 74/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2290 - acc: 0.9630 - val_loss: 0.2374 - val_acc: 1.0000\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2262 - acc: 0.9481 - val_loss: 0.2247 - val_acc: 1.0000\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2187 - acc: 0.9630 - val_loss: 0.2279 - val_acc: 1.0000\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2179 - acc: 0.9630 - val_loss: 0.2223 - val_acc: 1.0000\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2122 - acc: 0.9778 - val_loss: 0.2212 - val_acc: 1.0000\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2118 - acc: 0.9704 - val_loss: 0.2155 - val_acc: 1.0000\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2095 - acc: 0.9556 - val_loss: 0.2156 - val_acc: 1.0000\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2052 - acc: 0.9630 - val_loss: 0.2146 - val_acc: 1.0000\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2015 - acc: 0.9778 - val_loss: 0.2097 - val_acc: 1.0000\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1996 - acc: 0.9704 - val_loss: 0.2066 - val_acc: 1.0000\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1991 - acc: 0.9778 - val_loss: 0.2046 - val_acc: 1.0000\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1951 - acc: 0.9704 - val_loss: 0.2029 - val_acc: 1.0000\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1932 - acc: 0.9704 - val_loss: 0.2012 - val_acc: 1.0000\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.1931 - acc: 0.9704 - val_loss: 0.1972 - val_acc: 1.0000\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1903 - acc: 0.9778 - val_loss: 0.1976 - val_acc: 1.0000\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1876 - acc: 0.9778 - val_loss: 0.1945 - val_acc: 1.0000\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.1842 - acc: 0.9778 - val_loss: 0.1930 - val_acc: 1.0000\n",
      "Train on 135 samples, validate on 15 samples\n",
      "Epoch 1/90\n",
      "135/135 [==============================] - 11s 83ms/step - loss: 2.4538 - acc: 0.3259 - val_loss: 1.9832 - val_acc: 0.4000\n",
      "Epoch 2/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.8533 - acc: 0.3259 - val_loss: 1.5110 - val_acc: 0.4000\n",
      "Epoch 3/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.3895 - acc: 0.3259 - val_loss: 1.1466 - val_acc: 0.4000\n",
      "Epoch 4/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 1.0546 - acc: 0.5481 - val_loss: 0.9135 - val_acc: 0.6667\n",
      "Epoch 5/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.8522 - acc: 0.6667 - val_loss: 0.7962 - val_acc: 0.6667\n",
      "Epoch 6/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.7488 - acc: 0.6741 - val_loss: 0.7462 - val_acc: 0.6667\n",
      "Epoch 7/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6951 - acc: 0.6667 - val_loss: 0.7226 - val_acc: 0.6667\n",
      "Epoch 8/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.6659 - acc: 0.6889 - val_loss: 0.7067 - val_acc: 0.6667\n",
      "Epoch 9/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6435 - acc: 0.7111 - val_loss: 0.6907 - val_acc: 0.6667\n",
      "Epoch 10/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6236 - acc: 0.7407 - val_loss: 0.6777 - val_acc: 0.6667\n",
      "Epoch 11/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.6074 - acc: 0.7704 - val_loss: 0.6652 - val_acc: 0.7333\n",
      "Epoch 12/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5947 - acc: 0.7852 - val_loss: 0.6548 - val_acc: 0.8000\n",
      "Epoch 13/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5811 - acc: 0.7333 - val_loss: 0.6388 - val_acc: 0.7333\n",
      "Epoch 14/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5686 - acc: 0.8296 - val_loss: 0.6297 - val_acc: 0.7333\n",
      "Epoch 15/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5565 - acc: 0.8074 - val_loss: 0.6200 - val_acc: 0.7333\n",
      "Epoch 16/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5431 - acc: 0.8222 - val_loss: 0.6083 - val_acc: 0.7333\n",
      "Epoch 17/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5334 - acc: 0.8148 - val_loss: 0.5996 - val_acc: 0.7333\n",
      "Epoch 18/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5248 - acc: 0.8222 - val_loss: 0.5897 - val_acc: 0.8000\n",
      "Epoch 19/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.5157 - acc: 0.7556 - val_loss: 0.5813 - val_acc: 0.7333\n",
      "Epoch 20/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.5048 - acc: 0.8148 - val_loss: 0.5781 - val_acc: 0.7333\n",
      "Epoch 21/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4984 - acc: 0.8593 - val_loss: 0.5682 - val_acc: 0.7333\n",
      "Epoch 22/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4908 - acc: 0.8593 - val_loss: 0.5630 - val_acc: 0.8000\n",
      "Epoch 23/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4848 - acc: 0.8741 - val_loss: 0.5507 - val_acc: 0.8000\n",
      "Epoch 24/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4779 - acc: 0.8815 - val_loss: 0.5490 - val_acc: 0.8000\n",
      "Epoch 25/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4712 - acc: 0.8519 - val_loss: 0.5389 - val_acc: 0.8000\n",
      "Epoch 26/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4653 - acc: 0.8889 - val_loss: 0.5372 - val_acc: 0.8667\n",
      "Epoch 27/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4571 - acc: 0.8815 - val_loss: 0.5271 - val_acc: 0.8000\n",
      "Epoch 28/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4525 - acc: 0.8815 - val_loss: 0.5241 - val_acc: 0.7333\n",
      "Epoch 29/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4468 - acc: 0.8963 - val_loss: 0.5215 - val_acc: 0.8667\n",
      "Epoch 30/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4389 - acc: 0.9111 - val_loss: 0.5129 - val_acc: 0.7333\n",
      "Epoch 31/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4345 - acc: 0.8741 - val_loss: 0.5073 - val_acc: 0.8000\n",
      "Epoch 32/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4292 - acc: 0.8963 - val_loss: 0.5050 - val_acc: 0.8000\n",
      "Epoch 33/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4247 - acc: 0.9185 - val_loss: 0.5004 - val_acc: 0.8000\n",
      "Epoch 34/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4196 - acc: 0.9037 - val_loss: 0.4938 - val_acc: 0.8667\n",
      "Epoch 35/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4153 - acc: 0.9111 - val_loss: 0.4928 - val_acc: 0.8667\n",
      "Epoch 36/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.4136 - acc: 0.8963 - val_loss: 0.4847 - val_acc: 0.8667\n",
      "Epoch 37/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4071 - acc: 0.9185 - val_loss: 0.4848 - val_acc: 0.8667\n",
      "Epoch 38/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.4015 - acc: 0.9333 - val_loss: 0.4760 - val_acc: 0.8667\n",
      "Epoch 39/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3972 - acc: 0.9259 - val_loss: 0.4747 - val_acc: 0.8000\n",
      "Epoch 40/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3927 - acc: 0.9259 - val_loss: 0.4709 - val_acc: 0.8000\n",
      "Epoch 41/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3949 - acc: 0.8815 - val_loss: 0.4641 - val_acc: 0.8667\n",
      "Epoch 42/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3911 - acc: 0.9407 - val_loss: 0.4650 - val_acc: 0.8667\n",
      "Epoch 43/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3809 - acc: 0.9259 - val_loss: 0.4574 - val_acc: 0.8667\n",
      "Epoch 44/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3775 - acc: 0.9185 - val_loss: 0.4573 - val_acc: 0.8667\n",
      "Epoch 45/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3719 - acc: 0.9333 - val_loss: 0.4507 - val_acc: 0.8667\n",
      "Epoch 46/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3695 - acc: 0.9333 - val_loss: 0.4486 - val_acc: 0.8667\n",
      "Epoch 47/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3653 - acc: 0.9407 - val_loss: 0.4478 - val_acc: 0.8667\n",
      "Epoch 48/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3633 - acc: 0.9333 - val_loss: 0.4396 - val_acc: 0.8667\n",
      "Epoch 49/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3579 - acc: 0.9481 - val_loss: 0.4394 - val_acc: 0.8000\n",
      "Epoch 50/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3551 - acc: 0.9407 - val_loss: 0.4361 - val_acc: 0.8000\n",
      "Epoch 51/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3505 - acc: 0.9630 - val_loss: 0.4334 - val_acc: 0.8000\n",
      "Epoch 52/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3497 - acc: 0.9481 - val_loss: 0.4308 - val_acc: 0.8667\n",
      "Epoch 53/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3445 - acc: 0.9407 - val_loss: 0.4253 - val_acc: 0.8667\n",
      "Epoch 54/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3401 - acc: 0.9481 - val_loss: 0.4238 - val_acc: 0.8000\n",
      "Epoch 55/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3377 - acc: 0.9778 - val_loss: 0.4188 - val_acc: 0.8667\n",
      "Epoch 56/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3332 - acc: 0.9481 - val_loss: 0.4147 - val_acc: 0.8667\n",
      "Epoch 57/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3303 - acc: 0.9333 - val_loss: 0.4120 - val_acc: 0.8667\n",
      "Epoch 58/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3270 - acc: 0.9630 - val_loss: 0.4119 - val_acc: 0.8000\n",
      "Epoch 59/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3242 - acc: 0.9852 - val_loss: 0.4091 - val_acc: 0.8667\n",
      "Epoch 60/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3241 - acc: 0.9556 - val_loss: 0.4028 - val_acc: 0.8667\n",
      "Epoch 61/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3163 - acc: 0.9704 - val_loss: 0.4066 - val_acc: 0.8000\n",
      "Epoch 62/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3174 - acc: 0.9556 - val_loss: 0.3984 - val_acc: 0.8667\n",
      "Epoch 63/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3118 - acc: 0.9778 - val_loss: 0.3971 - val_acc: 0.8667\n",
      "Epoch 64/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3076 - acc: 0.9778 - val_loss: 0.3940 - val_acc: 0.8667\n",
      "Epoch 65/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.3057 - acc: 0.9630 - val_loss: 0.3910 - val_acc: 0.8667\n",
      "Epoch 66/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.3021 - acc: 0.9778 - val_loss: 0.3900 - val_acc: 0.8667\n",
      "Epoch 67/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2996 - acc: 0.9852 - val_loss: 0.3840 - val_acc: 0.8667\n",
      "Epoch 68/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2975 - acc: 0.9704 - val_loss: 0.3828 - val_acc: 0.8667\n",
      "Epoch 69/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2919 - acc: 0.9852 - val_loss: 0.3786 - val_acc: 0.8667\n",
      "Epoch 70/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2909 - acc: 0.9852 - val_loss: 0.3780 - val_acc: 0.8667\n",
      "Epoch 71/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2889 - acc: 0.9852 - val_loss: 0.3734 - val_acc: 0.8667\n",
      "Epoch 72/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2837 - acc: 0.9852 - val_loss: 0.3745 - val_acc: 0.8667\n",
      "Epoch 73/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2829 - acc: 0.9778 - val_loss: 0.3711 - val_acc: 0.9333\n",
      "Epoch 74/90\n",
      "135/135 [==============================] - ETA: 0s - loss: 0.2807 - acc: 0.992 - 0s 1ms/step - loss: 0.2785 - acc: 0.9852 - val_loss: 0.3680 - val_acc: 0.8667\n",
      "Epoch 75/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2766 - acc: 0.9778 - val_loss: 0.3658 - val_acc: 0.8667\n",
      "Epoch 76/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2726 - acc: 0.9926 - val_loss: 0.3607 - val_acc: 0.8667\n",
      "Epoch 77/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2719 - acc: 0.9704 - val_loss: 0.3580 - val_acc: 0.8667\n",
      "Epoch 78/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2670 - acc: 0.9926 - val_loss: 0.3580 - val_acc: 0.8667\n",
      "Epoch 79/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2649 - acc: 0.9852 - val_loss: 0.3548 - val_acc: 0.8667\n",
      "Epoch 80/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2616 - acc: 0.9926 - val_loss: 0.3521 - val_acc: 0.8667\n",
      "Epoch 81/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2596 - acc: 0.9926 - val_loss: 0.3517 - val_acc: 0.9333\n",
      "Epoch 82/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2604 - acc: 0.9778 - val_loss: 0.3466 - val_acc: 0.8667\n",
      "Epoch 83/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2534 - acc: 0.9926 - val_loss: 0.3470 - val_acc: 0.8667\n",
      "Epoch 84/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2516 - acc: 0.9926 - val_loss: 0.3435 - val_acc: 0.8667\n",
      "Epoch 85/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2549 - acc: 0.9704 - val_loss: 0.3398 - val_acc: 0.8667\n",
      "Epoch 86/90\n",
      "135/135 [==============================] - 0s 2ms/step - loss: 0.2510 - acc: 0.9778 - val_loss: 0.3411 - val_acc: 0.9333\n",
      "Epoch 87/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2455 - acc: 0.9852 - val_loss: 0.3358 - val_acc: 0.8667\n",
      "Epoch 88/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2419 - acc: 0.9852 - val_loss: 0.3341 - val_acc: 0.8667\n",
      "Epoch 89/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2412 - acc: 0.9778 - val_loss: 0.3325 - val_acc: 0.8667\n",
      "Epoch 90/90\n",
      "135/135 [==============================] - 0s 1ms/step - loss: 0.2369 - acc: 0.9852 - val_loss: 0.3292 - val_acc: 0.8667\n",
      "Accuracy is found to be 0.83207407799032\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c8133e8b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAIABJREFUeJzt3Xl8lPW1x/HPEQQFEVBQWxChaFG0gBoRBRW1Vui1Ll2s\ngHVrS6kLar2u7a169bpUa7Ve16uo1SguLYqtBK1aFhU1KLJZFEEEqohaVtlizv3jTJIhJGFYnjyT\nzPf9es1rMs/8ZnLyKHPmtzy/Y+6OiIgIwDZpByAiIvlDSUFERCopKYiISCUlBRERqaSkICIilZQU\nRESkkpKCiIhUUlIQEZFKSgoiIlKpadoBbKp27dp5586d0w5DRKRBmTx58mfu3n5j7RpcUujcuTOl\npaVphyEi0qCY2bxc2mn4SEREKikpiIhIJSUFERGppKQgIiKVlBRERKSSkoKIiFRSUhARkUpKCiIi\nKVm1Cv70J1i9Ou1IqigpiIik5D//E04/Hf7wh7QjqaKkICKSgr/+Fe68E1q0gFtvjV5DdZ9/Dh9/\nXHVbtiz5uJQURETq2aJFcNZZ0LMnjBoFn34KI0as3+aPf4R27eDrX6+6XXdd8rE1uL2PREQaMvdI\nCMuXQ3ExdO8OhxwCN90EQ4fCttvClCkxtHTMMfCDH1S9tlev5ONTUhARyUFZGfz+9/GhftFF8eFd\nm6efhocfhvLyDZ9buhRefhluvx323TeOXXEFfO97MHJkJIHBg6OX8NhjsPPOyfw9tVFSEBHZiNmz\n4dRT4fXX4/HTT8Mjj8Cee67fbvlyuOCCGArq2BF22qnm9zv3XDjnnKrH//Ef8K1vwQ03wGuvwbvv\nwvPP139CACUFEWng3nkH9t4bmjdf/3h5ObzySs0TuADt28P++294fMkSePPN6BEAzJoFl18ePYOR\nI8EMhg2LoZzrrovfDdEDuPxymDsXfv1r+O1voVmz3P4GM7jsMhgyBGbOhAsvjKGjVLh7g7odeOCB\nLiKyZIn7kCHu4N6jh/u0aVXPffSRe//+8Vxdt7POcl+2rOp1JSXuu+22YbujjnKfP7+q3fz5cax6\nuz32cB8/fvP+nnXr3Lt1c+/Z033Vqs17j7oApZ7DZ6x6CiLS4IwfDz/5CSxcCL/8JTz1FBQVwY03\nwq67xrGysljy2bNnze/xt7/FcM24cXDfffCXv1SN848YAa1bR7vmzaNHsU3WWs2OHeGFF+Dtt2HN\nmjhmBj16QMuWm/c3NW0KkybBdtvFLS3mFX2kBqKoqMhVeU0K1ejR8H//Fx9gdU10Tp8eQxzDh8PJ\nJ9fdbvhw6Ns3hjtqe88vvoghjdWr44Nzl12qnps7N8bHZ82q+bVNmsRqm4svjp8rPPss/OY3sGJF\n7fHVxB0+/BC+8Y0Y1+/TJ5Z4/vSn8UEPceyRR6Br17rfa8KESC7zMjXJzj8frr8ett9+02JqCMxs\nsrsXbbSdkoJIw9GvX4yTP/QQnHZazW1Wr4aDDooPfIh2t98OO+5Y1aa8PNbBX3ZZJIIVK+KbdnEx\nfPOb67/fiy/GVbeLFsWHeuvW8U36u9+NFTbnnhvfko87bv1v0xX+9S946SU47LDY0qF9+1i9c889\nsRzzgAM2/Tx06hTj9zvsUHXMHR54AP797/hwb5rjOMjSpfC730H//imO49cDJQWRRubDD6FLl/gA\n3nvv+NCv6UP4wgvjCtnRo6G0FK69Nj5Ehw2r+qY+diz8/e+xDPK++2I45he/iIRywQXQtm20mz07\nPry7dYuE0bx5TIZOnRof5m+9VfVh37lzzXG7x7f2c86J2Nu3hzlzYh3+NddsOEEsycg1KaQ+cbyp\nN000S6H6n/+Jyczrr4/7UaM2bDN2bDx33nlVx1591b1r1/UnRFu2dL/7bvfy8qp2Cxa4f+c767cz\nc//lL91Xrqxqt3q1+0UXubdo4X7dde5lZbnFP3eu++GHu3fq5P7SS5t1CmQLkONEs3oKIg2AO+y3\nX6x7f/nl+Oberl1MTJpFm88+i7XuO+8cSyqzx8XLy+HLL6seN2tW+3LJlSurlmM2aVL7+Hp5ec09\nlY39He6b/jrZcrn2FPSfRqQBmDo11q8PGRJj5ZdcAm+8EQkCYphn4MCYEC4u3vCDfJttYvy94lbX\n+vmWLava1TXhujkf7GZKCPlO/3lEGoDi4kgGP/xhPD79dNhtt7h46v7740KqDz6Axx+vfQmmSC4S\nTQpmNsDMZpnZbDO7rIbn25rZKDObamZvmNl+ScYj0hCVl8ceOAMGxJARxDr2X/0qVgb97Gdw8MHR\nmzjxxHRjlYYvsaRgZk2AO4CBQHdgkJl1r9bsCmCKu/cATgNuSyoekYZq/HhYsCCGjrINGwbf+U5s\n0vbCC3FBlciWSvKK5t7AbHefA2BmI4ETgJlZbboDNwC4+z/NrLOZ7eruixKMS6RBKS6O8f3jj1//\neKtWsbRUZGtKcvioAzA/6/GCzLFs7wDfBzCz3sAegL7viBDDRjffHBeq/eAHUaFLJGlpTzTfALQx\nsynAecDbwFfVG5nZUDMrNbPSxYsX13eMIvVu/nz49rdja4jvfQ9uuSXtiKRQJDl8tBDYPetxx8yx\nSu6+DDgTwMwMmAvMqf5G7n4vcC/EdQoJxSuSF954A449NjZ0GzECzjij6loEkaQlmRTeBPYysy5E\nMjgFGJzdwMzaAF+6+1rgZ8D4TKIQKUjLl8OgQbG/0IsvbnxDN5GtLbGk4O5lZnYuMBZoAoxw9xlm\nNizz/N3APsBDZubADOCnScUjkraFC+Hjj2PjudoMHx57HI0fr4Qg6Ui0noK7Pwc8V+3Y3Vk/vwZ8\ns/rrRBqjYcNi7/7PPqv5iuInn4QHH4T/+q/YylokDWlPNIsUhM8+g5KSGB565ZUNn1+wIHYp7d07\nkoJIWpQUROrBE0/ExLEZjBmz4fPnnQdr18Y1CXUVzxFJmpKCSD0oLo4yj/37b5gUFi2K2gfDh8Oe\ne6YSnkgl1WgW2UIPPwyvv171uHPnKHRTUdBm7lx49dXYvK5ih9MFC6q2pXjiibhQrfo2FiJpUFIQ\n2QLz5kX94e22iwpi5eVRDrK8PD78ITazg1hqumJFHC8piY3sIHoRPXtGT0IkbRo+EsnB2rWwZs2G\nx2++OeYJZs6MyeTPP48tKX7zmyhV6R4f+n37Rg9i332jh1BSEq+fPTt6GeolSL5QUhDJwYknQo8e\nsXqowqefRn3jU0+F3TPX7pvBvffCLrvA4MHw2mtVxXEqnh8wIHY1XbcOHn00jg0aVP9/k0hNlBRE\nNmLSpJgcfu+9mAyucNtt0Xu49NL12++0UxSyf++92LeoaVP40Y+qnh84EJYti4RRXAyHH65tryV/\nKCmIEHMAd9wBZ58dS0ezXX99fNBfeGFcXPbkk/Ghfscd8P3vR73k6o46Ci66KMpjZhfHATj66EgU\n114biUNDR5JPNNEsBe/jj+HMM6tqE+y2G/z2t/Hz9OmxXPTKK+HXv44Lz4YOhZ/8BJYuhcsvr/19\nr7022pxxxvrHW7eGQw+NIaRmzapKbIrkA/UUJK9Nmxbr+JPy9NPwrW/FXkN33RXf2v/7v2PICODG\nG6OQ/XnnxUVlxcUxF3D77XDMMXDggbW/d/PmMb9w6KEbPjdwYNx/97vQtu3W/7tENpeSguStVaug\nX78oOVnTyp8tsWJFLAk96STYY49YKTRsWAwJdewYk8fTpsVy0qFDYeed43V77hltmjffsu0oTjgh\nhpB+qi0gJc8oKUjeevbZGLufOhWuuGLrve+kSdCrV9QquPzymPDde+94rnXruBht7lw47DDYZhv4\n1a/Wf/3pp8fS08MO2/wY9tkHFi+G447b/PcQSYKSguSt4mL42tfiG/wtt8Df/15728svjw/pmTPX\nP/7BB3DkkdCmTdXt0ENjMnncuLjKuPqOpYcdFklo6VI47bSaVwa1bLnlf1+bNlv+HiJbm7k3rEJm\nRUVFXlpamnYYkrAvvogJ3/POg2uuibH7il5DxVBOhWefjaL2TZvG7aab4JxzYqXQ8OFxbMiQuIcY\nw7/ggugV1GbdupgPOPlkaN8+sT9TpN6Y2WR3r6OaR6adkoLko3vuiR7C5MlwwAHw9ttw8MExQfvk\nk1Xf7j/5JCaKO3aEZ56J14wZA126xBBQ//5xzcDuu9f560QavVyTgoaPJC89+miM8++/fzzef//o\nAYweDX36wLvvxhYSZ54Zk8bFxdCpE/ztbzERvGYN/O53UdJSCUEkd0oKkrp169a/YOyjj2KJ6ODB\n6xesP//86A3Mnx+9h5NPjj2Ebr4ZunePNmZxAdrChXDxxTFRLCK50z8ZSdW6dXDEEVGPeNy4OFax\nq+jgwRu2P/74WCp65JHw1FOxzv/ss+svXpHGTlc0S6quuiqWhH796/FBf8klMQTUp0/thet32y3a\nvPBCtMvuTYjIllFPQVIzfnzsK/TTn8KsWXEx2Y03xtYSG9sPyCwuattxx/qJVaRQKClIKpYsif2D\nunaFW2+FHXaIJaCjRkU9Am0SJ5IODR9JvVi5MuYMKlZA338//OtfUaZyhx2q2p14YtxEJB1KCpK4\nsjI49tjYYTTbddfBQQelE5OI1ExJQRJ3/fWREG67DQ45JI61aKGaxCL5SElBNuqGG2ITudtv3/QL\nwSZNgquvjjmC7KplIpKfNNEsdfrkk1g2+swzUaN45MjcX7t8eSSDjh3jKmMRyX+JJgUzG2Bms8xs\ntpldVsPzrc3sWTN7x8xmmNmZScYjm+7WW+MCs5KS2HZi0KCqqmN1+eqr2JTuww9jK+q6Np8TkfyR\nWFIwsybAHcBAoDswyMy6V2t2DjDT3XsC/YHfm1m1jYwlLUuWwJ13RtH5Y4+FCRNiKOixx6LXMH58\nza+bNy9qFD/8cBSi2ZK6AyJSv5LsKfQGZrv7HHdfC4wETqjWxoFWZmbADsAXQLWy6VJfysvXf3zH\nHTEEdFmmj9e0adQunjgxSlP27x91Bz7/PBLIkiWxMV3PnlHJ7MEHo7axiDQcSSaFDsD8rMcLMsey\n/S+wD/AvYBpwvrtX+2iS+vC738Euu8Djj8fjL7+MoaOBA6NKWbY+fWIr67POipVF7dpFjYK2baOM\n5b77wjvvRIUybUEh0rCkvfroWGAKcBTQFXjBzCa4+7LsRmY2FBgK0KlTp3oPsrFbtiw+3FetglNO\niX2FunWDzz6LimY1adUK7rsv2k+fXnW8Xbs41jTt/7NEZLMk+U93IZC9gLFj5li2M4EbPCr9zDaz\nucDewBvZjdz9XuBeiCI7iUVcoO65J4Z+Xn0Vxo6Fa6+NieK+fTc+H/Dtb8dNRBqHJIeP3gT2MrMu\nmcnjU4DR1dp8BBwNYGa7At2AOQnGJNWsXh31j48+Oi4su+qqmDM46qgYUhKRwpJYT8Hdy8zsXGAs\n0AQY4e4zzGxY5vm7gWuAB81sGmDApe7+WVIxyYYeeiiuRXjkkapjffpExTIRKTyq0VzAyspi7mDn\nneH11zUpLNKY5VqjWdOBBezJJ2HOnChnqYQgIqBtLgrWunWxS+k++8AJ1a8eEZGCpZ5CgbrqqlhK\nOmqUituLSBV9HBSgijKYZ52lgjYisj4lhQKTXQbzttvSjkZE8o2GjwrM2WfDwoVR9Ca7DKaICCgp\nFJTi4tjh9Jpr4OCD045GRPKRho8KxNy50Uvo27dq11MRkeqUFApAWVnMI0BcuazN6kSkNvp4KAA3\n3BBzCI88Ap07px2NiOQz9RQauddfj2sSBg2KeskiInVRUmjEVqyIojcdOkRZTRGRjdHwUSN2/vmx\nt9E//gFt2qQdjYg0BOopNHBlZVEU58wzYfHiquN//jOMGBErjTZWKEdEpIJ6Cg3Y7NkxPPT669Ck\nCZSUwAMPwH77wc9/DkVFMZ8gIpIr9RQaqAcfhF69YNYsGDkS3nor6iMPHAiHHgpr1sTFattum3ak\nItKQKCk0QH/7WwwXHXQQTJ0KP/4x9OgBb74JF1wACxbA7bfDN7+ZdqQi0tCo8loDs2hRJIDddoM3\n3oDmzTdss2KF9jUSkfWp8loj5B7bXS9bBi+9VHNCACUEEdl8SgoNyJ13wnPPxdDQvvumHY2INEZK\nCnnsiSdingCgvDySwsCBcM456cYlIo2XkkKeWr0azjgjrkOoWEHUtWtce2CWamgi0ohtdPWRmZ1k\nZq2zHrcxMxVxTNi4cbBqFTzzDKxcGbfp02OCWUQkKbksSb3S3ZdWPHD3JcCVyYUkEBeiNW8ORxyR\ndiQiUkhySQo1tdGwU8LGjIH+/aFFi7QjEZFCkktSKDWzW8ysa+Z2CzA56cAK2dy5caXygAFpRyIi\nhSaXpHAesBZ4HBgJrAa0/iVBJSVxP3BgunGISOHZ6DCQu68ENquqr5kNAG4DmgD3ufsN1Z6/GKgo\n/dIU2Ado7+5fbM7vayzGjIkKadqmQkTqWy6rj14wszZZj9ua2dgcXtcEuAMYCHQHBplZ9+w27n6T\nu/dy917A5cC4Qk8Ia9bE1coDB2rpqYjUv1yGj9plVhwB4O7/BnbJ4XW9gdnuPsfd1xJDTyfU0X4Q\n8FgO79uoTZwYy081dCQiacglKZSbWaeKB2a2B5DLLnodgPlZjxdkjm3AzFoAA4A/5/C+jVpJCTRr\nBkcemXYkIlKIclla+mtgopmNAww4DBi6leP4HvBKbUNHZja04nd26tSppiaNxpgxUSlNm9qJSBo2\n2lNw9xLgAKpWHx3o7hudUwAWArtnPe6YOVaTU6hj6Mjd73X3Incvat++fQ6/umGaPx9mzNBSVBFJ\nT65Fdr4CPgWWAd3N7PAcXvMmsJeZdTGzZsQH/+jqjTJbaBwBPJNjLI3Wiy/G/bHHphuHiBSujQ4f\nmdnPgPOJb/pTgD7Aa8BRdb3O3cvM7FxgLLEkdYS7zzCzYZnn7840PQl4PrP0taBNnAht22pbbBFJ\nTy5zCucDBwGT3P1IM9sbuC6XN3f354Dnqh27u9rjB4EHc3m/xm7CBOjbF7ZRkVQRSUkuHz+r3X01\ngJk1d/d/At2SDavwfPopvPdeTDKLiKQll57CgszFa08DL5jZv4F5yYZVeCZOjHslBRFJUy7bXJyU\n+fEqM3sZaA2UJBpVAZowAbbbDg48MO1IRKSQbdIW2O4+LqlACt3EiXDwwXHhmohIWjSlmQdWrIC3\n34Z+/dKOREQKnZJCHpg0Cb76SvMJIpI+JYUElJfD4MFw9dWwbt3G20+YEMtQDzkk+dhEROpS65yC\nmS2n5o3vDHB33zGxqBq4V1+FxzKbdjz3HDzyCOy1V+3tJ06Enj1hR51REUlZrT0Fd2/l7jvWcGul\nhFC34mLYfnt44AF4/33o1Qv+9Kea265bF8NHGjoSkXyQ8/CRme1iZp0qbkkG1ZCtXQtPPAEnnABn\nnAFTp0JREZx1FsyZs2H7t9+GL7/UJLOI5IdcKq8db2bvA3OBccCHwJiE42qwxo6FL76AIZkiox07\nwqOPxpzBTTdt2H7ChLhXUhCRfJBLT+EaYhO899y9C3A0MCnRqBqwRx+FnXdef6fTDh3g9NNjOOmT\nT6qOl5fDqFHQtSt87Wv1H6uISHW5JIV17v45sI2ZbePuLwNFCcfVIC1fDs88AyefDNtuu/5zl1wS\n8wd/+EPVsT/+EV55BS6+uH7jFBGpTS5JYYmZ7QCMB4rN7Dag4Le5rsnTT8OqVVVDR9n22gt+9CO4\n6y5YsiTmGi69FI4/HoZu7Tp2IiKbKZekcALwJXAhsefRB0T5TKmmuBj22KP26w0uuyx6E7//fVzH\nsNNOcN99YFa/cYqI1CaXvY9+ATzu7guBhxKOp8FatAheeCG+/ddWD6FXLxg4EK69Nh6PGQONuLqo\niDRAufQUWgHPm9kEMzvXzHZNOqiG6NlnY+J40KC6211xRdwPH65azCKSf3LZOvtq4Goz6wH8GBhn\nZgvc/duJR9eATJkCrVrBfvvV3a5fvyim07Vr/cQlIrIpNmXr7E+BT4DPgV2SCafhmjYtEkIu8wN1\nbXkhIpKmXC5eO9vM/gG8COwM/NzdeyQdWEPiHquJeuisiEgDl0tPYXfgAnefknQwDdXChbHM9Fvf\nSjsSEZEtk8ucwuX1EUhDNnVq3KunICINneopbAXTpsX9xiaZRUTynZLCVjBtWmx817Zt2pGIiGwZ\nJYWtQJPMItJYKClsoXXr4J//1CSziDQOSgpbaNasSAzqKYhIY5BoUjCzAWY2y8xmm9lltbTpb2ZT\nzGyGmY1LMp4kVKw8Uk9BRBqDTbmieZOYWRPgDuAYYAHwppmNdveZWW3aAHcCA9z9IzNrcFdKT5sW\ntRO6dUs7EhGRLZdkT6E3MNvd57j7WmAksQ13tsHAX9z9IwB3/zTBeBIxdSrsvTc0a5Z2JCIiWy7J\npNABmJ/1eEHmWLZvAm3N7B9mNtnMTkswnkRMm6ahIxFpPBIbPtqE338gUfd5e+A1M5vk7u9lNzKz\nocBQgE6dOtV7kLVZsgTmz9cks4g0Hkn2FBYS+yZV6Jg5lm0BMNbdV7r7Z0TJz57V38jd73X3Incv\nap9HVWkqrmRWT0FEGoskk8KbwF5m1sXMmgGnAKOrtXkG6GdmTc2sBXAw8G6CMW1VFUlBPQURaSwS\nGz5y9zIzOxcYCzQBRrj7DDMblnn+bnd/18xKgKlAOXCfu09PKqatbdo0aNMGOlSfKRERaaDM3dOO\nYZMUFRV5aWlp2mEAcOih0LQpjB+fdiQiInUzs8nuXrSxdrqieTOtWQNvvQW9e6cdiYjI1qOksJlK\nSyMx9OuXdiQiIluPksJmmjAh7vv2TTcOEZGtSUlhM02cGFcy59EKWRGRLaaksBnKy+GVV+Cww9KO\nRERk61JS2AwzZsTVzJpPEJHGRklhM1TMJ6inICKNjZLCZpgwIS5Y69w57UhERLYuJYVN5B5JoV8/\nMEs7GhGRrUtJYRPNmwcLF2roSEQaJyWFTTRxYtxrkllEGiMlhU00YQK0bg377Zd2JCIiW5+Swiaa\nODE2wmvSJO1IRES2PiWFTbBoEcycqfkEEWm8lBRy9Npr0UPYZhsYODDtaEREkqGksBHr1sGVV8bE\ncnk5jBsHvXqlHZWISDISq7zWWJx/Ptx1F5x2GvzxjzHJLCLSWCkp1OHLL+HhhyMhPPRQ2tGIiCRP\nw0d1ePZZWLECzjgj7UhEROqHkkIdiotjj6Mjjkg7EhGR+qGkUIvPP4cxY2DQoFhxJCJSCPRxV4un\nnoKyMhg8OO1IRETqj5JCLYqLYZ99tPxURAqLkkIN5s2LPY6GDNH22CJSWJQUavDYY3GvoSMRKTRK\nCjUoLo4tLbp0STsSEZH6paRQzaxZMH06nHJK2pGIiNQ/JYVqSkri/rjj0o1DRCQNiSYFMxtgZrPM\nbLaZXVbD8/3NbKmZTcncfptkPLkYMwa6ddPQkYgUpsT2PjKzJsAdwDHAAuBNMxvt7jOrNZ3g7nnx\nvXzVqtgFddiwtCMREUlHkj2F3sBsd5/j7muBkcAJCf6+LfaPf8Dq1TBgQNqRiIikI8mk0AGYn/V4\nQeZYdYea2VQzG2Nm+9b0RmY21MxKzax08eLFScQKxNDR9ttrryMRKVxpTzS/BXRy9x7A7cDTNTVy\n93vdvcjdi9q3b59YMCUl0L8/bLddYr9CRCSvJZkUFgK7Zz3umDlWyd2XufuKzM/PAduaWbsEY6rV\nBx/A+++r1KaIFLYkk8KbwF5m1sXMmgGnAKOzG5jZbmaxkYSZ9c7E83mCMdWqYimq5hNEpJAltvrI\n3cvM7FxgLNAEGOHuM8xsWOb5u4EfAr80szJgFXCKu3tSMdVlzBjo2hX22iuN3y4ikh8SLceZGRJ6\nrtqxu7N+/l/gf5OMIRerV8NLL8FZZ6UdiYhIutKeaM4LEybENQqaTxCRQqekALz4IjRtGiuPREQK\nmZICUFoKPXpAy5ZpRyIikq6CTwrukRSKitKOREQkfQWfFD74AJYuVVIQEQElBSZPjnslBRERJQVK\nS6F5c9i3xl2XREQKi5JCKfTsCc2apR2JiEj6CjoplJfH8JGGjkREQkEnhfffh+XL4cAD045ERCQ/\nFHRSKC2Ne/UURERCwSeF7baD7t3TjkREJD8UdFKYPBn23z+2uBARkQJOCl99BW+9paEjEZFsBZsU\nZs2ClSuVFEREshVsUtAks4jIhgo6KbRsCd26pR2JiEj+KOikcMAB0KRJ2pGIiOSPgkwKX3wRSeGQ\nQ9KOREQkvxRkUvjzn2HdOvjxj9OOREQkvxRkUigujrmE/fdPOxIRkfxScElh/nwYNw6GDAGztKMR\nEckvBZcUHnss7gcPTjcOEZF8VHBJobgY+vSBrl3TjkREJP8UVFKYPh2mTlUvQUSkNgWVFB59NK5L\n0KojEZGaFUxSKC+PpHDMMbDLLmlHIyKSnxJNCmY2wMxmmdlsM7usjnYHmVmZmf0wqVhefRXmzdPQ\nkYhIXRJLCmbWBLgDGAh0BwaZ2QblbDLtbgSeTyqW+D1w7LFw4olJ/hYRkYYtyZ5Cb2C2u89x97XA\nSOCEGtqdB/wZ+DTBWOjbF0pKoFWrJH+LiEjDlmRS6ADMz3q8IHOskpl1AE4C7qrrjcxsqJmVmlnp\n4sWLt3qgIiIS0p5ovhW41N3L62rk7ve6e5G7F7Vv376eQhMRKTxJVideCOye9bhj5li2ImCkxX4T\n7YDvmlmZuz+dYFwiIlKLJJPCm8BeZtaFSAanAOut/XH3LhU/m9mDwF+VEERE0pNYUnD3MjM7FxgL\nNAFGuPsMMxuWef7upH63iIhsniR7Crj7c8Bz1Y7VmAzc/YwkYxERkY1Le6JZRETyiJKCiIhUMndP\nO4ZNYmaLgXmb8JJ2wGcJhdMQ6XxsSOdkfTofG2oM52QPd9/omv4GlxQ2lZmVuntR2nHkC52PDemc\nrE/nY0OFdE40fCQiIpWUFEREpFIhJIV70w4gz+h8bEjnZH06HxsqmHPS6OcUREQkd4XQUxARkRw1\n2qSQa9W3xszMdjezl81sppnNMLPzM8d3MrMXzOz9zH3btGOtT2bWxMzeNrO/Zh4X+vloY2ZPmdk/\nzexdMztD1NN5AAAEVklEQVSkkM+JmV2Y+fcy3cweM7PtCul8NMqkkGvVtwJQBlzk7t2BPsA5mfNw\nGfCiu+8FvJh5XEjOB97Nelzo5+M2oMTd9wZ6EuemIM9JpsbLcKDI3fcj9m07hQI6H40yKZB71bdG\nzd0/dve3Mj8vJ/6xdyDOxUOZZg8BBVOk1Mw6Av8B3Jd1uJDPR2vgcOB+AHdf6+5LKOBzQuwJt72Z\nNQVaAP+igM5HY00KG636VmjMrDOwP/A6sKu7f5x56hNg15TCSsOtwCVAdmGnQj4fXYDFwAOZIbX7\nzKwlBXpO3H0hcDPwEfAxsNTdn6eAzkdjTQqSxcx2IOpgX+Duy7Kf81h+VhBL0MzsOOBTd59cW5tC\nOh8ZTYEDgLvcfX9gJdWGRgrpnGTmCk4gkuXXgZZmdmp2m8Z+PhprUsil6ltBMLNtiYRQ7O5/yRxe\nZGZfyzz/NeDTtOKrZ32B483sQ2JI8Sgze4TCPR8QvegF7v565vFTRJIo1HPybWCuuy9293XAX4BD\nKaDz0ViTQmXVNzNrRkwUjU45pnpnUef0fuBdd78l66nRwOmZn08Hnqnv2NLg7pe7e0d370z8P/GS\nu59KgZ4PAHf/BJhvZt0yh44GZlK45+QjoI+Ztcj8+zmamIsrmPPRaC9eM7PvEuPHFVXf/iflkOqd\nmfUDJgDTqBpDv4KYV3gC6ETsOHuyu3+RSpApMbP+wH+6+3FmtjMFfD7MrBcx8d4MmAOcSXxhLMhz\nYmZXAz8mVu+9DfwM2IECOR+NNimIiMima6zDRyIishmUFEREpJKSgoiIVFJSEBGRSkoKIiJSSUlB\nJGFm1r9iR1aRfKekICIilZQURDLM7FQze8PMppjZPZm6CyvM7A+Z/fVfNLP2mba9zGySmU01s1EV\n++ub2Z5m9ncze8fM3jKzrpm33yGrZkFx5mpZzOyGTL2LqWZ2c0p/ukglJQURwMz2Ia5i7evuvYCv\ngCFAS6DU3fcFxgFXZl7yJ+BSd+9BXDFecbwYuMPdexJ75lTsrLk/cAFR3+MbQN/MldQnAftm3ufa\nZP9KkY1TUhAJRwMHAm+a2ZTM428Q24M8nmnzCNAvU4OgjbuPyxx/CDjczFoBHdx9FIC7r3b3LzNt\n3nD3Be5eDkwBOgNLgdXA/Wb2faCirUhqlBREggEPuXuvzK2bu19VQ7vN3RdmTdbPXwFN3b2MKAj1\nFHAcULKZ7y2y1SgpiIQXgR+a2S5QWbd5D+LfyA8zbQYDE919KfBvMzssc/wnwLhMdbsFZnZi5j2a\nm1mL2n5hps5Fa3d/DriQKIUpkqqmaQcgkg/cfaaZ/QZ43sy2AdYB5xBFZ3pnnvuUmHeA2D757syH\nfsXOohAJ4h4z++/Me/yojl/bCnjGzLYjeiq/2sp/lsgm0y6pInUwsxXuvkPacYjUFw0fiYhIJfUU\nRESkknoKIiJSSUlBREQqKSmIiEglJQUREamkpCAiIpWUFEREpNL/A5uHI59g+5zJAAAAAElFTkSu\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c80e1dfb38>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEKCAYAAAD9xUlFAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ncBJPijEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x2c80d980390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_loss=[]\n",
    "train_loss=[]\n",
    "acc=[]\n",
    "val_acc=[]\n",
    "np.random.seed(seed)\n",
    "num_of_epochs=90\n",
    "def model_define():\n",
    "    model=Sequential()\n",
    "    model.add(Dense(8,activation='relu',input_shape=(4,)))\n",
    "    model.add(Dense(3,activation='softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=[\"accuracy\"])\n",
    "    return model\n",
    "skf=KFold(n_splits=10,shuffle=True, random_state=seed)\n",
    "skf.get_n_splits(X,encoded_Y)\n",
    "for train_index , test_index in skf.split(X, encoded_Y):\n",
    "    model=model_define()\n",
    "    history=model.fit(X[train_index],dummy_y[train_index],epochs=num_of_epochs,batch_size=5,verbose=1,\n",
    "                     validation_data=(X[test_index],dummy_y[test_index]))\n",
    "    val_loss.append(history.history['val_loss'])\n",
    "    train_loss.append(history.history['loss'])\n",
    "    acc.append(history.history['acc'])\n",
    "    val_acc.append(history.history['val_acc'])\n",
    "    \n",
    "print('Accuracy is found to be {}'.format(np.mean(np.mean(val_acc,axis=0))))\n",
    "train_acc=np.mean(acc,axis=0)\n",
    "val_acc=np.mean(val_acc,axis=0)\n",
    "val_loss=np.mean(val_loss,axis=0)\n",
    "train_loss=np.mean(train_loss,axis=0)\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1,num_of_epochs+1),val_loss,'b',label='val_loss')\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"val loss\")\n",
    "plt.show()\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1,num_of_epochs+1),val_acc,'b',label='val_acc')\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"val acc\")\n",
    "plt.show()\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "plt.plot(np.arange(1,num_of_epochs+1),train_acc,'b',label='train_acc')\n",
    "\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"train acc\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#larger model\n",
    "def create_larger():\n",
    "\t# create model\n",
    "    model=Sequential()\n",
    "    model.add(Dense(16, activation='relu', input_shape=(4,)))\n",
    "    model.add(Dense(8, activation='relu'))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 96.00% (5.33%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_larger, epochs=210, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, dummy_y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#functional api\n",
    "\n",
    "# baseline model\n",
    "def create_baseline():\n",
    "\t# create model, write code below\n",
    "    import keras\n",
    "    from keras import layers\n",
    "    \n",
    "    inputs=keras.Input(shape=(4,))\n",
    "    x=layers.Dense(8, activation='relu')(inputs)\n",
    "  #  x=layers.Dense(8, activation='relu')(x)\n",
    "    outputs=layers.Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model=keras.Model(inputs, outputs)\n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 97.33% (4.42%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_smaller():\n",
    "\t# create model\n",
    "    inputs=keras.Input(shape=(4,))\n",
    "    x=Dense(4, activation='relu')(inputs)\n",
    "   # x=Dense(4, activation='relu')(x)\n",
    "    outputs=Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 94.67% (7.18%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_smaller, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_larger():\n",
    "\t# create model\n",
    "    inputs=keras.Input(shape=(4,))\n",
    "    x=Dense(16, activation='relu')(inputs)\n",
    "    x=Dense(8, activation='relu')(x)\n",
    "    #x=Dense(8, activation='relu')(x)\n",
    "    outputs=Dense(3, activation='softmax')(x)\n",
    "    \n",
    "    model=keras.Model(inputs,outputs)\n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 96.67% (4.47%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_larger, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#model subclassing\n",
    "# baseline model\n",
    "import tensorflow as tf\n",
    "def create_baseline():\n",
    "\t# create model, write code below\n",
    "    from keras import layers\n",
    "    \n",
    "    class MyModel(tf.keras.Model):\n",
    "    \n",
    "        def __init__(self,num_classes=3):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.dense1=layers.Dense(8, activation='relu')\n",
    "            #self.dense2=layers.Dense(8, activation='relu')\n",
    "            self.dense3=layers.Dense(num_classes, activation='softmax')\n",
    "            \n",
    "        def call(self,inputs):\n",
    "            x= self.dense1(inputs)\n",
    "            return self.dense3(x)\n",
    "    \n",
    "    model=MyModel(num_classes=3)\n",
    "    \n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 37.33% (13.73%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "def create_smaller():\n",
    "\t# create model, write code below\n",
    "    from keras import layers\n",
    "    \n",
    "    class MyModel(tf.keras.Model):\n",
    "    \n",
    "        def __init__(self,num_classes=3):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.dense1=layers.Dense(4, activation='relu')\n",
    "          #  self.dense2=layers.Dense(4, activation='relu')\n",
    "            self.dense3=layers.Dense(num_classes, activation='softmax')\n",
    "            \n",
    "        def call(self,inputs):\n",
    "            x= self.dense1(inputs)\n",
    "        \n",
    "            return self.dense3(x)\n",
    "    \n",
    "    model=MyModel(num_classes=3)\n",
    "    \n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 32.67% (5.54%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_smaller, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_larger():\n",
    "\t# create model, write code below\n",
    "    from keras import layers\n",
    "    \n",
    "    class MyModel(tf.keras.Model):\n",
    "    \n",
    "        def __init__(self,num_classes=3):\n",
    "            super(MyModel, self).__init__()\n",
    "            self.num_classes = num_classes\n",
    "            self.dense1=layers.Dense(16, activation='relu')\n",
    "            self.dense2=layers.Dense(8, activation='relu')\n",
    "           # self.dense2=layers.Dense(8, activation='relu')\n",
    "            self.dense3=layers.Dense(num_classes, activation='softmax')\n",
    "            \n",
    "        def call(self,inputs):\n",
    "            x= self.dense1(inputs)\n",
    "            x=self.dense2(x)\n",
    "            return self.dense3(x)\n",
    "    \n",
    "    model=MyModel(num_classes=3)\n",
    "    \n",
    "\t# Compile model, write code below\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results: 35.33% (17.40%)\n"
     ]
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=create_larger, epochs=200, batch_size=5, verbose=0)\n",
    "kfold = KFold(n_splits=10, shuffle=True, random_state=seed)\n",
    "results = cross_val_score(estimator, X, encoded_Y, cv=kfold)\n",
    "print(\"Results: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "processing fold # 0\n",
      "processing fold # 1\n",
      "processing fold # 2\n",
      "processing fold # 3\n",
      "processing fold # 4\n",
      "processing fold # 5\n",
      "processing fold # 6\n",
      "processing fold # 7\n",
      "processing fold # 8\n",
      "processing fold # 9\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import numpy as np\n",
    "k=10\n",
    "num_val_samples = len(X) // k\n",
    "num_epochs = 200\n",
    "val_loss=[]\n",
    "val_acc=[]\n",
    "for i in range(k):\n",
    "    print('processing fold #', i)\n",
    "    val_data = X[i * num_val_samples: (i + 1) * num_val_samples]\n",
    "    val_targets = encoded_Y[i* num_val_samples: (i + 1) * num_val_samples]\n",
    "    \n",
    "    partial_train_data = np.concatenate([X[:i * num_val_samples],\n",
    "                                         X[(i + 1) * num_val_samples:]],axis=0)\n",
    "    partial_train_targets = np.concatenate([encoded_Y[:i*num_val_samples],\n",
    "                                            encoded_Y[(i + 1) * num_val_samples:]],axis=0)\n",
    "    \n",
    "    model=create_baseline()\n",
    "    history=model.fit(partial_train_data,partial_train_targets,shuffle=True,epochs=10,\n",
    "                      batch_size=5,verbose=0)\n",
    "    sys=model.evaluate(val_data,val_targets,verbose=0)\n",
    "    val_loss.append(sys[0])\n",
    "    val_acc.append(sys[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.153080320358276\n"
     ]
    }
   ],
   "source": [
    "print(np.mean(val_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5933333337306976"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(val_acc)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "1.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    print(val_acc[i])\n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
